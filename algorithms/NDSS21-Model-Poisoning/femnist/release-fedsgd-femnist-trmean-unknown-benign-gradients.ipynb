{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The notebook contains\n",
    "### Code for _Trimmed-mean_ aggregation algorithm, *when gradient updates of benign clients are unknown to adversary*\n",
    "### Evaluation of all of the attacks (Fang, LIE, and our SOTA AGR-tailored and AGR-agnstic) on Trimmed-mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import json\n",
    "import argparse, os, sys, csv, shutil, time, random, operator, pickle, ast, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.optim import Optimizer\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "sys.path.insert(0,'./../utils/')\n",
    "from logger import *\n",
    "from eval import *\n",
    "from misc import *\n",
    "\n",
    "from femnist_normal_train import *\n",
    "from femnist_util import *\n",
    "from adam import Adam\n",
    "from sgd import SGD\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the FEMNIST dataset; we use [LEAF framework](https://leaf.cmu.edu/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_tr_data = []\n",
    "user_tr_labels = []\n",
    "\n",
    "for i in range(34):\n",
    "    f = '/mnt/nfs/work1/amir/vshejwalkar/leaf/data/femnist/data/train/all_data_%d_niid_0_keep_0_train_9.json'%i\n",
    "    with open(f, 'r') as myfile:\n",
    "        data=myfile.read()\n",
    "    obj = json.loads(data)\n",
    "    \n",
    "    for user in obj['users']:\n",
    "        user_tr_data.append(obj['user_data'][user]['x'])\n",
    "        user_tr_labels.append(obj['user_data'][user]['y'])\n",
    "\n",
    "user_te_data = []\n",
    "user_te_labels = []\n",
    "\n",
    "for i in range(34):\n",
    "    f = '/mnt/nfs/work1/amir/vshejwalkar/leaf/data/femnist/data/test/all_data_%d_niid_0_keep_0_test_9.json'%i\n",
    "    with open(f, 'r') as myfile:\n",
    "        data=myfile.read()\n",
    "    obj = json.loads(data)\n",
    "    \n",
    "    for user in obj['users']:\n",
    "        user_te_data.append(obj['user_data'][user]['x'])\n",
    "        user_te_labels.append(obj['user_data'][user]['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of FL clients are  244\n"
     ]
    }
   ],
   "source": [
    "user_tr_data_tensors=[]\n",
    "user_tr_label_tensors=[]\n",
    "\n",
    "for i in range(len(user_tr_data)):\n",
    "    \n",
    "    user_tr_data_tensor=torch.from_numpy(np.array(user_tr_data[i])).type(torch.FloatTensor)\n",
    "    user_tr_label_tensor=torch.from_numpy(np.array(user_tr_labels[i])).type(torch.LongTensor)\n",
    "\n",
    "    user_tr_data_tensors.append(user_tr_data_tensor)\n",
    "    user_tr_label_tensors.append(user_tr_label_tensor)\n",
    "    \n",
    "#     print('user %d tr len %d'%(i,len(user_tr_data_tensor)))\n",
    "print(\"number of FL clients are \", len(user_tr_data_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_data = np.concatenate(user_te_data, 0)\n",
    "te_labels = np.concatenate(user_te_labels)\n",
    "te_len = len(te_labels)\n",
    "\n",
    "te_data_tensor = torch.from_numpy(te_data[:(te_len//2)]).type(torch.FloatTensor)\n",
    "te_label_tensor = torch.from_numpy(te_labels[:(te_len//2)]).type(torch.LongTensor)\n",
    "\n",
    "val_data_tensor = torch.from_numpy(te_data[(te_len//2):]).type(torch.FloatTensor)\n",
    "val_label_tensor = torch.from_numpy(te_labels[(te_len//2):]).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture for FEMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mnist_conv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(mnist_conv, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 16, 5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5, padding=2)\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 512)\n",
    "        self.fc2 = nn.Linear(512, 62)\n",
    "\n",
    "    def forward(self, x, noise=torch.Tensor()):\n",
    "        x = x.reshape(-1, 1, 28, 28)\n",
    "\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, 32 * 7 * 7)  # reshape Variable\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.fill_(0)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tr_mean(all_updates, n_attackers):\n",
    "    sorted_updates = torch.sort(all_updates, 0)[0]\n",
    "    out = torch.mean(sorted_updates[n_attackers:-n_attackers], 0) if n_attackers else torch.mean(sorted_updates,0)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for (Full-knowledge) Fang attack on Trimmed-mean\n",
    "\n",
    "### Note that the Fang attacks on Trimmed-mean and Median are the same "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fang_attack_trmean_partial(all_updates, n_attackers):\n",
    "\n",
    "    model_re = torch.mean(all_updates, 0)\n",
    "    model_std = torch.std(all_updates, 0)\n",
    "    deviation = torch.sign(model_re)\n",
    "    \n",
    "    max_vector_low = model_re + 3 * model_std \n",
    "    max_vector_hig = model_re + 4 * model_std\n",
    "    min_vector_low = model_re - 4 * model_std\n",
    "    min_vector_hig = model_re - 3 * model_std\n",
    "\n",
    "    max_range = torch.cat((max_vector_low[:,None], max_vector_hig[:,None]), dim=1)\n",
    "    min_range = torch.cat((min_vector_low[:,None], min_vector_hig[:,None]), dim=1)\n",
    "\n",
    "    rand = torch.from_numpy(np.random.uniform(0, 1, [len(deviation), n_attackers])).type(torch.FloatTensor).cuda()\n",
    "\n",
    "    max_rand = torch.stack([max_range[:, 0]] * rand.shape[1]).T + rand * torch.stack([max_range[:, 1] - max_range[:, 0]] * rand.shape[1]).T\n",
    "    min_rand = torch.stack([min_range[:, 0]] * rand.shape[1]).T + rand * torch.stack([min_range[:, 1] - min_range[:, 0]] * rand.shape[1]).T\n",
    "\n",
    "    mal_vec = (torch.stack([(deviation > 0).type(torch.FloatTensor)] * max_rand.shape[1]).T.cuda() * max_rand + torch.stack(\n",
    "        [(deviation > 0).type(torch.FloatTensor)] * min_rand.shape[1]).T.cuda() * min_rand).T\n",
    "\n",
    "    return mal_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation for Full-knolwledge Fang attack on Trimmed-mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vshejwalkar/NDSS21-Model-Poisoning/femnist/adam.py:76: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729138878/work/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  exp_avg.mul_(beta1).add_(1 - beta1, grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trmean: at fang n_at 14 e 0 | val loss 3.9637 val acc 4.7261 best val_acc 4.726112 te_acc 5.251236\n",
      "trmean: at fang n_at 11 e 20 | val loss 3.7232 val acc 9.6633 best val_acc 16.675247 te_acc 18.317545\n",
      "trmean: at fang n_at 12 e 40 | val loss 3.6013 val acc 25.7619 best val_acc 26.714374 te_acc 29.553645\n",
      "trmean: at fang n_at 11 e 60 | val loss 3.2126 val acc 32.2204 best val_acc 32.601421 te_acc 36.732908\n",
      "trmean: at fang n_at 12 e 80 | val loss 2.7087 val acc 36.2464 best val_acc 36.442030 te_acc 41.047158\n",
      "trmean: at fang n_at 17 e 100 | val loss 2.2837 val acc 41.3509 best val_acc 41.350906 te_acc 45.696046\n",
      "trmean: at fang n_at 19 e 120 | val loss 2.0236 val acc 45.8145 best val_acc 46.373044 te_acc 49.822385\n",
      "trmean: at fang n_at 16 e 140 | val loss 1.8586 val acc 50.5354 best val_acc 50.535420 te_acc 53.554881\n",
      "trmean: at fang n_at 14 e 160 | val loss 1.7640 val acc 51.5059 best val_acc 53.058072 te_acc 55.683690\n",
      "trmean: at fang n_at 13 e 180 | val loss 1.6202 val acc 55.9051 best val_acc 55.905066 te_acc 58.291289\n",
      "trmean: at fang n_at 14 e 200 | val loss 1.5211 val acc 59.3518 best val_acc 59.351833 te_acc 61.241248\n",
      "trmean: at fang n_at 10 e 220 | val loss 1.4294 val acc 60.7496 best val_acc 61.792113 te_acc 63.169275\n",
      "trmean: at fang n_at 8 e 240 | val loss 1.3270 val acc 62.9530 best val_acc 63.941516 te_acc 65.218287\n",
      "trmean: at fang n_at 11 e 260 | val loss 1.2620 val acc 65.7074 best val_acc 65.707372 te_acc 66.814250\n",
      "trmean: at fang n_at 14 e 280 | val loss 1.1964 val acc 66.5362 best val_acc 66.652080 te_acc 67.655993\n",
      "trmean: at fang n_at 15 e 300 | val loss 1.1662 val acc 66.4848 best val_acc 67.661141 te_acc 68.719110\n",
      "trmean: at fang n_at 7 e 320 | val loss 1.1342 val acc 68.0215 best val_acc 68.021520 te_acc 69.192751\n",
      "trmean: at fang n_at 11 e 340 | val loss 1.1120 val acc 68.3819 best val_acc 68.909596 te_acc 69.905787\n",
      "trmean: at fang n_at 12 e 360 | val loss 1.0571 val acc 69.1516 best val_acc 69.684411 te_acc 70.708917\n",
      "trmean: at fang n_at 11 e 380 | val loss 1.0501 val acc 70.4026 best val_acc 70.603377 te_acc 71.615012\n",
      "trmean: at fang n_at 11 e 400 | val loss 1.0025 val acc 71.0281 best val_acc 71.244337 te_acc 72.106672\n",
      "trmean: at fang n_at 11 e 420 | val loss 0.9820 val acc 70.7964 best val_acc 71.563530 te_acc 72.366660\n",
      "trmean: at fang n_at 11 e 440 | val loss 0.9617 val acc 72.2843 best val_acc 72.438736 te_acc 73.249588\n",
      "trmean: at fang n_at 12 e 460 | val loss 0.9621 val acc 71.8106 best val_acc 72.745058 te_acc 73.293348\n",
      "trmean: at fang n_at 7 e 480 | val loss 0.9356 val acc 72.5391 best val_acc 72.963859 te_acc 73.694914\n",
      "trmean: at fang n_at 10 e 500 | val loss 0.9093 val acc 73.2959 best val_acc 73.416907 te_acc 74.050144\n",
      "trmean: at fang n_at 10 e 520 | val loss 0.9069 val acc 73.3860 best val_acc 73.808175 te_acc 74.606157\n",
      "trmean: at fang n_at 12 e 540 | val loss 0.8749 val acc 74.1660 best val_acc 74.165980 te_acc 74.685956\n",
      "trmean: at fang n_at 10 e 560 | val loss 0.8691 val acc 73.9498 best val_acc 74.737438 te_acc 74.927924\n",
      "trmean: at fang n_at 8 e 580 | val loss 0.8919 val acc 72.6627 best val_acc 74.737438 te_acc 74.927924\n",
      "trmean: at fang n_at 7 e 600 | val loss 0.8705 val acc 74.0965 best val_acc 74.956240 te_acc 75.640960\n",
      "trmean: at fang n_at 6 e 620 | val loss 0.8566 val acc 74.4131 best val_acc 75.370675 te_acc 75.900947\n",
      "trmean: at fang n_at 10 e 640 | val loss 0.8327 val acc 74.8430 best val_acc 75.478789 te_acc 75.908670\n",
      "trmean: at fang n_at 14 e 660 | val loss 0.8328 val acc 74.8481 best val_acc 75.478789 te_acc 75.908670\n",
      "trmean: at fang n_at 12 e 680 | val loss 0.8166 val acc 75.4299 best val_acc 75.707887 te_acc 75.998764\n",
      "trmean: at fang n_at 7 e 700 | val loss 0.8249 val acc 74.8816 best val_acc 75.988468 te_acc 76.428645\n",
      "trmean: at fang n_at 12 e 720 | val loss 0.8461 val acc 75.0154 best val_acc 76.047673 te_acc 76.637150\n",
      "trmean: at fang n_at 17 e 740 | val loss 0.7956 val acc 75.7568 best val_acc 76.196973 te_acc 76.819914\n",
      "trmean: at fang n_at 19 e 760 | val loss 0.8373 val acc 75.0232 best val_acc 76.196973 te_acc 76.819914\n",
      "trmean: at fang n_at 14 e 780 | val loss 0.8527 val acc 74.2046 best val_acc 76.251030 te_acc 76.595964\n",
      "trmean: at fang n_at 13 e 800 | val loss 0.7896 val acc 76.0631 best val_acc 76.258752 te_acc 76.722096\n",
      "trmean: at fang n_at 8 e 820 | val loss 0.8004 val acc 75.6152 best val_acc 76.294790 te_acc 76.850803\n",
      "trmean: at fang n_at 14 e 840 | val loss 0.7891 val acc 75.9215 best val_acc 76.889415 te_acc 77.193163\n",
      "trmean: at fang n_at 11 e 860 | val loss 0.7721 val acc 76.4286 best val_acc 76.889415 te_acc 77.193163\n",
      "trmean: at fang n_at 11 e 880 | val loss 0.7885 val acc 75.7903 best val_acc 76.889415 te_acc 77.193163\n",
      "trmean: at fang n_at 17 e 900 | val loss 0.7700 val acc 76.6346 best val_acc 76.889415 te_acc 77.193163\n",
      "trmean: at fang n_at 11 e 920 | val loss 0.7985 val acc 75.6023 best val_acc 77.056734 te_acc 77.409390\n",
      "trmean: at fang n_at 11 e 940 | val loss 0.7928 val acc 75.8778 best val_acc 77.056734 te_acc 77.409390\n",
      "trmean: at fang n_at 14 e 960 | val loss 0.7911 val acc 75.9653 best val_acc 77.314147 te_acc 77.736306\n",
      "trmean: at fang n_at 18 e 980 | val loss 0.7596 val acc 76.9255 best val_acc 77.314147 te_acc 77.736306\n",
      "trmean: at fang n_at 9 e 1000 | val loss 0.8300 val acc 75.6461 best val_acc 77.538097 te_acc 77.985997\n",
      "trmean: at fang n_at 12 e 1020 | val loss 0.7640 val acc 77.4326 best val_acc 77.538097 te_acc 77.985997\n",
      "trmean: at fang n_at 15 e 1040 | val loss 0.7523 val acc 77.1185 best val_acc 77.538097 te_acc 77.985997\n",
      "trmean: at fang n_at 11 e 1060 | val loss 0.7932 val acc 75.9910 best val_acc 77.955107 te_acc 78.094110\n",
      "trmean: at fang n_at 13 e 1080 | val loss 0.7528 val acc 77.5896 best val_acc 77.955107 te_acc 78.094110\n",
      "trmean: at fang n_at 16 e 1100 | val loss 0.7649 val acc 76.3180 best val_acc 77.955107 te_acc 78.094110\n",
      "trmean: at fang n_at 10 e 1120 | val loss 0.7369 val acc 77.3450 best val_acc 77.955107 te_acc 78.094110\n",
      "trmean: at fang n_at 13 e 1140 | val loss 0.7671 val acc 77.0439 best val_acc 77.955107 te_acc 78.094110\n",
      "trmean: at fang n_at 18 e 1160 | val loss 0.7405 val acc 77.2112 best val_acc 77.955107 te_acc 78.094110\n",
      "trmean: at fang n_at 16 e 1180 | val loss 0.7097 val acc 78.1276 best val_acc 78.215095 te_acc 78.315486\n",
      "trmean: at fang n_at 11 e 1200 | val loss 0.7455 val acc 76.6886 best val_acc 78.297467 te_acc 78.444193\n",
      "trmean: at fang n_at 17 e 1220 | val loss 0.7166 val acc 77.8547 best val_acc 78.297467 te_acc 78.444193\n",
      "trmean: at fang n_at 9 e 1240 | val loss 0.7649 val acc 76.3772 best val_acc 78.379839 te_acc 78.585770\n",
      "trmean: at fang n_at 15 e 1260 | val loss 0.7300 val acc 77.7749 best val_acc 78.379839 te_acc 78.585770\n",
      "trmean: at fang n_at 9 e 1280 | val loss 0.7415 val acc 77.5844 best val_acc 78.379839 te_acc 78.585770\n",
      "trmean: at fang n_at 11 e 1300 | val loss 0.7256 val acc 77.9062 best val_acc 78.379839 te_acc 78.585770\n",
      "trmean: at fang n_at 10 e 1320 | val loss 0.7289 val acc 77.6102 best val_acc 78.379839 te_acc 78.585770\n",
      "trmean: at fang n_at 13 e 1340 | val loss 0.7240 val acc 77.8315 best val_acc 78.379839 te_acc 78.585770\n",
      "trmean: at fang n_at 13 e 1360 | val loss 0.7499 val acc 76.9641 best val_acc 78.403007 te_acc 78.176483\n",
      "trmean: at fang n_at 10 e 1380 | val loss 0.7911 val acc 75.1133 best val_acc 78.403007 te_acc 78.176483\n",
      "trmean: at fang n_at 11 e 1400 | val loss 0.7291 val acc 77.1237 best val_acc 78.403007 te_acc 78.176483\n",
      "trmean: at fang n_at 15 e 1420 | val loss 0.7136 val acc 78.5008 best val_acc 78.500824 te_acc 78.709329\n",
      "trmean: at fang n_at 11 e 1440 | val loss 0.6960 val acc 78.2846 best val_acc 78.500824 te_acc 78.709329\n",
      "trmean: at fang n_at 8 e 1460 | val loss 0.7094 val acc 78.1585 best val_acc 78.760811 te_acc 79.193266\n",
      "trmean: at fang n_at 12 e 1480 | val loss 0.7038 val acc 78.2872 best val_acc 78.760811 te_acc 79.193266\n",
      "trmean: at fang n_at 11 e 1499 | val loss 0.7105 val acc 78.1585 best val_acc 79.025947 te_acc 78.938427\n",
      "trmean: at fang n_at 14 e 1500 | val loss 0.7016 val acc 78.3824 best val_acc 79.025947 te_acc 78.938427\n"
     ]
    }
   ],
   "source": [
    "resume=0\n",
    "nepochs=1500\n",
    "gamma=.1\n",
    "fed_lr=0.001\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "batch_size = 100\n",
    "schedule = [5000]\n",
    "\n",
    "aggregation = 'trmean'\n",
    "chkpt = './' + aggregation\n",
    "\n",
    "at_type='fang'\n",
    "at_fractions = [20]\n",
    "\n",
    "for at_fraction in at_fractions:\n",
    "    epoch_num = 0\n",
    "\n",
    "    fed_model = mnist_conv().cuda()\n",
    "    fed_model.apply(weights_init)\n",
    "    optimizer_fed = Adam(fed_model.parameters(), lr=fed_lr)\n",
    "\n",
    "    best_global_acc=0\n",
    "    best_global_te_acc=0\n",
    "\n",
    "    while epoch_num <= nepochs:\n",
    "        user_grads = []\n",
    "\n",
    "        round_users = np.random.choice(3400, 60)\n",
    "        n_attacker = np.sum(round_users < (34*at_fraction))\n",
    "\n",
    "        at_idx = []\n",
    "        for i in np.sort(round_users):\n",
    "            if i < (34*at_fraction):\n",
    "                at_idx.append(i)\n",
    "                continue\n",
    "\n",
    "            inputs = user_tr_data_tensors[i]\n",
    "            targets = user_tr_label_tensors[i]\n",
    "\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "            outputs = fed_model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            optimizer_fed.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "\n",
    "            param_grad=[]\n",
    "            for param in fed_model.parameters():\n",
    "                param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
    "\n",
    "            user_grads=param_grad[None,:] if len(user_grads)==0 else torch.cat((user_grads,param_grad[None,:]),0)    \n",
    "\n",
    "        if n_attacker > 0:\n",
    "            attacker_grads = []\n",
    "            proxy_n_attackers = max(1, n_attacker**2//60)\n",
    "            for i in at_idx:\n",
    "\n",
    "                inputs = user_tr_data_tensors[i]\n",
    "                targets = user_tr_label_tensors[i]\n",
    "\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "                inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "                outputs = fed_model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                optimizer_fed.zero_grad()\n",
    "                loss.backward(retain_graph=True)\n",
    "\n",
    "                param_grad=[]\n",
    "                for param in fed_model.parameters():\n",
    "                    param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
    "\n",
    "                attacker_grads=param_grad[None,:] if len(attacker_grads)==0 else torch.cat((attacker_grads,param_grad[None,:]),0)\n",
    "\n",
    "            mal_updates = []\n",
    "            if at_type == 'fang':\n",
    "                mal_updates = fang_attack_trmean_partial(attacker_grads, n_attacker)\n",
    "        \n",
    "        if not len(mal_updates):\n",
    "            mal_updates = torch.stack([mal_update] * n_attacker)\n",
    "        malicious_grads = torch.cat((mal_updates, user_grads), 0)\n",
    "            \n",
    "        if not (malicious_grads.shape[0]==60):\n",
    "            print(malicious_grads.shape)\n",
    "            sys.exit()\n",
    "            \n",
    "        agg_grads=tr_mean(malicious_grads, n_attacker)\n",
    "        \n",
    "        start_idx=0\n",
    "\n",
    "        if epoch_num in schedule:\n",
    "            for param_group in optimizer_fed.param_groups:\n",
    "                param_group['lr'] *= gamma\n",
    "                print('New learnin rate ', param_group['lr'])\n",
    "\n",
    "        optimizer_fed.zero_grad()\n",
    "\n",
    "        model_grads=[]\n",
    "\n",
    "        for i, param in enumerate(fed_model.parameters()):\n",
    "            param_=agg_grads[start_idx:start_idx+len(param.data.view(-1))].reshape(param.data.shape)\n",
    "            start_idx=start_idx+len(param.data.view(-1))\n",
    "            param_=param_.cuda()\n",
    "            model_grads.append(param_)\n",
    "\n",
    "        optimizer_fed.step(model_grads)\n",
    "\n",
    "        val_loss, val_acc = test(val_data_tensor,val_label_tensor,fed_model,criterion,use_cuda)\n",
    "        te_loss, te_acc = test(te_data_tensor,te_label_tensor, fed_model, criterion, use_cuda)\n",
    "\n",
    "        is_best = best_global_acc < val_acc\n",
    "\n",
    "        best_global_acc = max(best_global_acc, val_acc)\n",
    "\n",
    "        if is_best:\n",
    "            best_global_te_acc = te_acc\n",
    "\n",
    "        if epoch_num % 20 == 0 or epoch_num == nepochs-1:\n",
    "            print('%s: at %s n_at %d e %d | val loss %.4f val acc %.4f best val_acc %f te_acc %f'%(aggregation, at_type, n_attacker, epoch_num, val_loss, val_acc, best_global_acc,best_global_te_acc))\n",
    "\n",
    "        epoch_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for our SOTA AGR-tailored attack on Trimmed-mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def our_attack_trmean(all_updates, n_attackers, dev_type='sign', threshold=5.0, threshold_diff=1e-5):\n",
    "    \n",
    "    model_re = torch.mean(all_updates, 0)\n",
    "    \n",
    "    if dev_type == 'sign':\n",
    "        deviation = torch.sign(model_re)\n",
    "    elif dev_type == 'unit_vec':\n",
    "        deviation = model_re / torch.norm(model_re)  # unit vector, dir opp to good dir\n",
    "    elif dev_type == 'std':\n",
    "        deviation = torch.std(all_updates, 0)\n",
    "\n",
    "    lamda = torch.Tensor([threshold]).cuda()  # compute_lambda_our(all_updates, model_re, n_attackers)\n",
    "\n",
    "    threshold_diff = threshold_diff\n",
    "    prev_loss = -1\n",
    "    lamda_fail = lamda\n",
    "    lamda_succ = 0\n",
    "\n",
    "    while torch.abs(lamda_succ - lamda) > threshold_diff:\n",
    "        mal_update = (model_re - lamda * deviation)\n",
    "        mal_updates = torch.stack([mal_update] * n_attackers)\n",
    "        mal_updates = torch.cat((mal_updates, all_updates), 0)\n",
    "\n",
    "        agg_grads = torch.median(mal_updates, 0)[0]\n",
    "\n",
    "        loss = torch.norm(agg_grads - model_re)\n",
    "\n",
    "        if prev_loss < loss:\n",
    "            # print('successful lamda is ', lamda)\n",
    "            lamda_succ = lamda\n",
    "            lamda = lamda + lamda_fail / 2\n",
    "        else:\n",
    "            lamda = lamda - lamda_fail / 2\n",
    "\n",
    "        lamda_fail = lamda_fail / 2\n",
    "        prev_loss = loss\n",
    "\n",
    "    mal_update = (model_re - lamda_succ * deviation)\n",
    "    \n",
    "    return mal_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of our SOTA AGR-tailored attack on Trimmed-mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trmean: at our-agr n_at 14 e 0 | val loss 3.9537 val acc 4.7261 best val_acc 4.726112 te_acc 5.243513\n",
      "trmean: at our-agr n_at 11 e 20 | val loss 3.8830 val acc 7.1252 best val_acc 11.405993 te_acc 12.157640\n",
      "trmean: at our-agr n_at 8 e 40 | val loss 3.7386 val acc 26.4029 best val_acc 27.169996 te_acc 30.655375\n",
      "trmean: at our-agr n_at 12 e 60 | val loss 3.4513 val acc 32.2925 best val_acc 32.838241 te_acc 36.918245\n",
      "trmean: at our-agr n_at 14 e 80 | val loss 3.2786 val acc 35.0160 best val_acc 35.015960 te_acc 39.482084\n",
      "trmean: at our-agr n_at 10 e 100 | val loss 2.7051 val acc 37.8527 best val_acc 37.852657 te_acc 42.540157\n",
      "trmean: at our-agr n_at 14 e 120 | val loss 2.5775 val acc 38.3855 best val_acc 40.174526 te_acc 44.849156\n",
      "trmean: at our-agr n_at 14 e 140 | val loss 2.2135 val acc 43.3227 best val_acc 43.322694 te_acc 47.575165\n",
      "trmean: at our-agr n_at 7 e 160 | val loss 2.0701 val acc 46.0307 best val_acc 46.409082 te_acc 50.136429\n",
      "trmean: at our-agr n_at 10 e 180 | val loss 2.3542 val acc 43.8118 best val_acc 46.409082 te_acc 50.136429\n",
      "trmean: at our-agr n_at 9 e 200 | val loss 2.1695 val acc 47.1993 best val_acc 47.199341 te_acc 51.251030\n",
      "trmean: at our-agr n_at 12 e 220 | val loss 2.0709 val acc 48.6177 best val_acc 49.351318 te_acc 52.653933\n",
      "trmean: at our-agr n_at 14 e 240 | val loss 2.2006 val acc 46.2443 best val_acc 49.366763 te_acc 52.623044\n",
      "trmean: at our-agr n_at 7 e 260 | val loss 1.8420 val acc 50.7105 best val_acc 51.511017 te_acc 54.762150\n",
      "trmean: at our-agr n_at 13 e 280 | val loss 1.8564 val acc 51.5599 best val_acc 54.118616 te_acc 57.109761\n",
      "trmean: at our-agr n_at 17 e 300 | val loss 2.0225 val acc 49.1428 best val_acc 54.177821 te_acc 57.477862\n",
      "trmean: at our-agr n_at 8 e 320 | val loss 1.8260 val acc 52.5587 best val_acc 54.177821 te_acc 57.477862\n",
      "trmean: at our-agr n_at 10 e 340 | val loss 1.7355 val acc 54.5794 best val_acc 55.753192 te_acc 58.342772\n",
      "trmean: at our-agr n_at 13 e 360 | val loss 1.8149 val acc 52.5664 best val_acc 55.753192 te_acc 58.342772\n",
      "trmean: at our-agr n_at 8 e 380 | val loss 1.6567 val acc 56.3839 best val_acc 57.071149 te_acc 59.750824\n",
      "trmean: at our-agr n_at 11 e 400 | val loss 1.7618 val acc 54.7699 best val_acc 58.610482 te_acc 60.906610\n",
      "trmean: at our-agr n_at 8 e 420 | val loss 2.0613 val acc 53.0684 best val_acc 58.610482 te_acc 60.906610\n",
      "trmean: at our-agr n_at 16 e 440 | val loss 1.7805 val acc 56.5975 best val_acc 58.888488 te_acc 61.614498\n",
      "trmean: at our-agr n_at 12 e 460 | val loss 1.8677 val acc 54.8522 best val_acc 58.988880 te_acc 61.686573\n",
      "trmean: at our-agr n_at 18 e 480 | val loss 1.7370 val acc 56.1470 best val_acc 59.367278 te_acc 62.185956\n",
      "trmean: at our-agr n_at 15 e 500 | val loss 2.0301 val acc 53.3721 best val_acc 59.367278 te_acc 62.185956\n",
      "trmean: at our-agr n_at 8 e 520 | val loss 1.7325 val acc 57.6066 best val_acc 60.566825 te_acc 63.061161\n",
      "trmean: at our-agr n_at 10 e 540 | val loss 1.5787 val acc 60.0829 best val_acc 60.566825 te_acc 63.061161\n",
      "trmean: at our-agr n_at 9 e 560 | val loss 1.6142 val acc 58.0416 best val_acc 61.122838 te_acc 63.488468\n",
      "trmean: at our-agr n_at 13 e 580 | val loss 1.5762 val acc 60.3094 best val_acc 61.609349 te_acc 64.029036\n",
      "trmean: at our-agr n_at 14 e 600 | val loss 1.4444 val acc 62.0135 best val_acc 63.210461 te_acc 65.213138\n",
      "trmean: at our-agr n_at 18 e 620 | val loss 1.5721 val acc 60.1859 best val_acc 63.210461 te_acc 65.213138\n",
      "trmean: at our-agr n_at 9 e 640 | val loss 1.5198 val acc 60.8809 best val_acc 63.210461 te_acc 65.213138\n",
      "trmean: at our-agr n_at 15 e 660 | val loss 1.6385 val acc 59.5732 best val_acc 63.210461 te_acc 65.213138\n",
      "trmean: at our-agr n_at 11 e 680 | val loss 1.5612 val acc 60.6209 best val_acc 63.210461 te_acc 65.213138\n",
      "trmean: at our-agr n_at 9 e 700 | val loss 1.4897 val acc 62.1087 best val_acc 63.210461 te_acc 65.213138\n",
      "trmean: at our-agr n_at 15 e 720 | val loss 1.7418 val acc 59.5063 best val_acc 63.210461 te_acc 65.213138\n",
      "trmean: at our-agr n_at 11 e 740 | val loss 1.3835 val acc 63.2568 best val_acc 63.411244 te_acc 65.810338\n",
      "trmean: at our-agr n_at 12 e 760 | val loss 1.4938 val acc 62.5952 best val_acc 63.671231 te_acc 66.116660\n",
      "trmean: at our-agr n_at 12 e 780 | val loss 1.4399 val acc 63.7819 best val_acc 63.900329 te_acc 66.577430\n",
      "trmean: at our-agr n_at 10 e 800 | val loss 1.5117 val acc 61.9852 best val_acc 63.900329 te_acc 66.577430\n",
      "trmean: at our-agr n_at 10 e 820 | val loss 1.6385 val acc 59.7843 best val_acc 63.900329 te_acc 66.577430\n",
      "trmean: at our-agr n_at 14 e 840 | val loss 1.6945 val acc 60.5720 best val_acc 65.066413 te_acc 67.228686\n",
      "trmean: at our-agr n_at 7 e 860 | val loss 1.4329 val acc 62.4691 best val_acc 65.946767 te_acc 67.421746\n",
      "trmean: at our-agr n_at 16 e 880 | val loss 1.4175 val acc 64.0419 best val_acc 66.060029 te_acc 67.903110\n",
      "trmean: at our-agr n_at 15 e 900 | val loss 1.3489 val acc 64.4512 best val_acc 66.060029 te_acc 67.903110\n",
      "trmean: at our-agr n_at 5 e 920 | val loss 1.2714 val acc 66.3303 best val_acc 66.330313 te_acc 67.846479\n",
      "trmean: at our-agr n_at 11 e 940 | val loss 1.5295 val acc 63.2800 best val_acc 67.051071 te_acc 68.582681\n",
      "trmean: at our-agr n_at 11 e 960 | val loss 1.3725 val acc 63.7356 best val_acc 67.051071 te_acc 68.582681\n",
      "trmean: at our-agr n_at 8 e 980 | val loss 1.3599 val acc 63.3907 best val_acc 67.051071 te_acc 68.582681\n",
      "trmean: at our-agr n_at 12 e 1000 | val loss 1.3429 val acc 64.8476 best val_acc 67.051071 te_acc 68.582681\n",
      "trmean: at our-agr n_at 12 e 1020 | val loss 1.4837 val acc 64.1964 best val_acc 67.051071 te_acc 68.582681\n",
      "trmean: at our-agr n_at 8 e 1040 | val loss 1.4870 val acc 62.2683 best val_acc 67.051071 te_acc 68.582681\n",
      "trmean: at our-agr n_at 8 e 1060 | val loss 1.3934 val acc 64.0187 best val_acc 67.051071 te_acc 68.582681\n",
      "trmean: at our-agr n_at 10 e 1080 | val loss 1.3436 val acc 63.8952 best val_acc 67.051071 te_acc 68.582681\n",
      "trmean: at our-agr n_at 14 e 1100 | val loss 1.4390 val acc 64.8116 best val_acc 67.051071 te_acc 68.582681\n",
      "trmean: at our-agr n_at 15 e 1120 | val loss 1.4689 val acc 63.0071 best val_acc 67.051071 te_acc 68.582681\n",
      "trmean: at our-agr n_at 12 e 1140 | val loss 1.4011 val acc 63.3392 best val_acc 67.051071 te_acc 68.582681\n",
      "trmean: at our-agr n_at 16 e 1160 | val loss 1.4627 val acc 63.2851 best val_acc 67.051071 te_acc 68.582681\n",
      "trmean: at our-agr n_at 7 e 1180 | val loss 1.2962 val acc 65.9339 best val_acc 67.051071 te_acc 68.582681\n",
      "trmean: at our-agr n_at 10 e 1200 | val loss 1.4369 val acc 63.6326 best val_acc 67.051071 te_acc 68.582681\n",
      "trmean: at our-agr n_at 16 e 1220 | val loss 1.4644 val acc 64.3637 best val_acc 67.051071 te_acc 68.582681\n",
      "trmean: at our-agr n_at 12 e 1240 | val loss 1.4657 val acc 64.2067 best val_acc 67.051071 te_acc 68.582681\n",
      "trmean: at our-agr n_at 17 e 1260 | val loss 1.7639 val acc 60.9401 best val_acc 67.051071 te_acc 68.582681\n",
      "trmean: at our-agr n_at 13 e 1280 | val loss 1.5358 val acc 62.4768 best val_acc 67.051071 te_acc 68.582681\n",
      "trmean: at our-agr n_at 15 e 1300 | val loss 1.9141 val acc 60.7650 best val_acc 67.051071 te_acc 68.582681\n",
      "trmean: at our-agr n_at 11 e 1320 | val loss 1.4569 val acc 63.8360 best val_acc 67.051071 te_acc 68.582681\n",
      "trmean: at our-agr n_at 12 e 1340 | val loss 1.8975 val acc 60.4433 best val_acc 67.051071 te_acc 68.582681\n",
      "trmean: at our-agr n_at 8 e 1360 | val loss 1.4444 val acc 63.3109 best val_acc 67.051071 te_acc 68.582681\n",
      "trmean: at our-agr n_at 12 e 1380 | val loss 1.6868 val acc 62.8681 best val_acc 67.051071 te_acc 68.582681\n",
      "trmean: at our-agr n_at 11 e 1400 | val loss 1.4707 val acc 63.2027 best val_acc 67.051071 te_acc 68.582681\n",
      "trmean: at our-agr n_at 15 e 1420 | val loss 1.7401 val acc 61.7097 best val_acc 67.051071 te_acc 68.582681\n",
      "trmean: at our-agr n_at 11 e 1440 | val loss 1.4834 val acc 64.3843 best val_acc 67.051071 te_acc 68.582681\n",
      "trmean: at our-agr n_at 14 e 1460 | val loss 1.4948 val acc 64.3045 best val_acc 67.051071 te_acc 68.582681\n",
      "trmean: at our-agr n_at 9 e 1480 | val loss 1.4449 val acc 64.9145 best val_acc 67.051071 te_acc 68.582681\n",
      "trmean: at our-agr n_at 11 e 1499 | val loss 1.5172 val acc 61.1074 best val_acc 67.051071 te_acc 68.582681\n",
      "trmean: at our-agr n_at 11 e 1500 | val loss 1.5223 val acc 61.1100 best val_acc 67.051071 te_acc 68.582681\n"
     ]
    }
   ],
   "source": [
    "resume=0\n",
    "nepochs=1500\n",
    "gamma=.1\n",
    "fed_lr=0.001\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "batch_size = 100\n",
    "schedule = [5000]\n",
    "\n",
    "aggregation = 'trmean'\n",
    "chkpt = './' + aggregation\n",
    "\n",
    "at_type='our-agr'\n",
    "at_fractions = [20]\n",
    "\n",
    "for at_fraction in at_fractions:\n",
    "    epoch_num = 0\n",
    "\n",
    "    fed_model = mnist_conv().cuda()\n",
    "    fed_model.apply(weights_init)\n",
    "    optimizer_fed = Adam(fed_model.parameters(), lr=fed_lr)\n",
    "\n",
    "    best_global_acc=0\n",
    "    best_global_te_acc=0\n",
    "\n",
    "    while epoch_num <= nepochs:\n",
    "        user_grads = []\n",
    "\n",
    "        round_users = np.random.choice(3400, 60)\n",
    "        n_attacker = np.sum(round_users < (34*at_fraction))\n",
    "\n",
    "        at_idx = []\n",
    "        for i in np.sort(round_users):\n",
    "            if i < (34*at_fraction):\n",
    "                at_idx.append(i)\n",
    "                continue\n",
    "\n",
    "            inputs = user_tr_data_tensors[i]\n",
    "            targets = user_tr_label_tensors[i]\n",
    "\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "            outputs = fed_model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            optimizer_fed.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "\n",
    "            param_grad=[]\n",
    "            for param in fed_model.parameters():\n",
    "                param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
    "\n",
    "            user_grads=param_grad[None,:] if len(user_grads)==0 else torch.cat((user_grads,param_grad[None,:]),0)    \n",
    "\n",
    "        if n_attacker > 0:\n",
    "            attacker_grads = []\n",
    "            n_attacker_ = max(1, n_attacker**2//60)\n",
    "            for i in at_idx:\n",
    "\n",
    "                inputs = user_tr_data_tensors[i]\n",
    "                targets = user_tr_label_tensors[i]\n",
    "\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "                inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "                outputs = fed_model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                optimizer_fed.zero_grad()\n",
    "                loss.backward(retain_graph=True)\n",
    "\n",
    "                param_grad=[]\n",
    "                for param in fed_model.parameters():\n",
    "                    param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
    "\n",
    "                attacker_grads=param_grad[None,:] if len(attacker_grads)==0 else torch.cat((attacker_grads,param_grad[None,:]),0)\n",
    "\n",
    "            mal_updates = []\n",
    "            if at_type == 'lie':\n",
    "                mal_update = lie_attack(malicious_grads, z)\n",
    "            elif at_type == 'fang':\n",
    "                mal_updates = fang_attack_trmean_partial(attacker_grads, n_attacker)\n",
    "            elif at_type == 'our-agr':\n",
    "                mal_update = our_attack_trmean(attacker_grads, n_attacker_, dev_type='sign', threshold=5.0, threshold_diff=1e-5)\n",
    "            elif at_type == 'min-max':\n",
    "                agg_grads = torch.mean(attacker_grads, 0)\n",
    "                mal_update = our_attack_dist(malicious_grads, agg_grads, n_attacker_, dev_type)\n",
    "            elif at_type == 'min-sum':\n",
    "                agg_grads = torch.mean(malicious_grads, 0)\n",
    "                mal_update = our_attack_score(attacker_grads, agg_grads, n_attacker_, dev_type)\n",
    "                \n",
    "        if not len(mal_updates):\n",
    "            mal_updates = torch.stack([mal_update] * n_attacker)\n",
    "        malicious_grads = torch.cat((mal_updates, user_grads), 0)\n",
    "\n",
    "        if malicious_grads.shape[0] != 60: \n",
    "            print('malicious grads shape ', malicious_grads.shape)\n",
    "            sys.exit()\n",
    "\n",
    "        agg_grads=tr_mean(malicious_grads, n_attacker)\n",
    "\n",
    "        start_idx=0\n",
    "\n",
    "        if epoch_num in schedule:\n",
    "            for param_group in optimizer_fed.param_groups:\n",
    "                param_group['lr'] *= gamma\n",
    "                print('New learnin rate ', param_group['lr'])\n",
    "\n",
    "        optimizer_fed.zero_grad()\n",
    "\n",
    "        model_grads=[]\n",
    "\n",
    "        for i, param in enumerate(fed_model.parameters()):\n",
    "            param_=agg_grads[start_idx:start_idx+len(param.data.view(-1))].reshape(param.data.shape)\n",
    "            start_idx=start_idx+len(param.data.view(-1))\n",
    "            param_=param_.cuda()\n",
    "            model_grads.append(param_)\n",
    "\n",
    "        optimizer_fed.step(model_grads)\n",
    "\n",
    "        val_loss, val_acc = test(val_data_tensor,val_label_tensor,fed_model,criterion,use_cuda)\n",
    "        te_loss, te_acc = test(te_data_tensor,te_label_tensor, fed_model, criterion, use_cuda)\n",
    "\n",
    "        is_best = best_global_acc < val_acc\n",
    "\n",
    "        best_global_acc = max(best_global_acc, val_acc)\n",
    "\n",
    "        if is_best:\n",
    "            best_global_te_acc = te_acc\n",
    "\n",
    "        if epoch_num % 20 == 0 or epoch_num == nepochs-1:\n",
    "            print('%s: at %s n_at %d e %d | val loss %.4f val acc %.4f best val_acc %f te_acc %f'%(aggregation, at_type, n_attacker, epoch_num, val_loss, val_acc, best_global_acc,best_global_te_acc))\n",
    "\n",
    "        epoch_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for our first SOTA AGR-agnostic attack - Min-max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def our_attack_dist(all_updates, model_re, n_attackers, dev_type='unit_vec'):\n",
    "\n",
    "    if dev_type == 'unit_vec':\n",
    "        deviation = model_re / torch.norm(model_re)  # unit vector, dir opp to good dir\n",
    "    elif dev_type == 'sign':\n",
    "        deviation = torch.sign(model_re)\n",
    "    elif dev_type == 'std':\n",
    "        deviation = torch.std(all_updates, 0)\n",
    "\n",
    "    lamda = torch.Tensor([50.0]).float().cuda()\n",
    "    # print(lamda)\n",
    "    threshold_diff = 1e-5\n",
    "    lamda_fail = lamda\n",
    "    lamda_succ = 0\n",
    "    \n",
    "    distances = []\n",
    "    for update in all_updates:\n",
    "        distance = torch.norm((all_updates - update), dim=1) ** 2\n",
    "        distances = distance[None, :] if not len(distances) else torch.cat((distances, distance[None, :]), 0)\n",
    "    \n",
    "    max_distance = torch.max(distances)\n",
    "    del distances\n",
    "\n",
    "    while torch.abs(lamda_succ - lamda) > threshold_diff:\n",
    "        mal_update = (model_re - lamda * deviation)\n",
    "        distance = torch.norm((all_updates - mal_update), dim=1) ** 2\n",
    "        max_d = torch.max(distance)\n",
    "        \n",
    "        if max_d <= max_distance:\n",
    "            # print('successful lamda is ', lamda)\n",
    "            lamda_succ = lamda\n",
    "            lamda = lamda + lamda_fail / 2\n",
    "        else:\n",
    "            lamda = lamda - lamda_fail / 2\n",
    "\n",
    "        lamda_fail = lamda_fail / 2\n",
    "\n",
    "    mal_update = (model_re - lamda_succ * deviation)\n",
    "    \n",
    "    return mal_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trmean: at min-max n_at 11 e 0 | val loss 3.9353 val acc 4.7416 best val_acc 4.741557 te_acc 5.230643\n",
      "trmean: at min-max n_at 10 e 20 | val loss 3.8028 val acc 21.0152 best val_acc 21.071870 te_acc 23.434926\n",
      "trmean: at min-max n_at 12 e 40 | val loss 3.5589 val acc 32.0119 best val_acc 32.444399 te_acc 36.859040\n",
      "trmean: at min-max n_at 11 e 60 | val loss 3.0166 val acc 35.3969 best val_acc 35.860276 te_acc 40.496293\n",
      "trmean: at min-max n_at 12 e 80 | val loss 2.4979 val acc 39.1166 best val_acc 39.116557 te_acc 43.541495\n",
      "trmean: at min-max n_at 13 e 100 | val loss 2.2924 val acc 40.4500 best val_acc 41.613468 te_acc 46.275227\n",
      "trmean: at min-max n_at 8 e 120 | val loss 2.3111 val acc 42.2261 best val_acc 44.728171 te_acc 48.591948\n",
      "trmean: at min-max n_at 13 e 140 | val loss 2.2046 val acc 44.1078 best val_acc 46.331857 te_acc 49.791495\n",
      "trmean: at min-max n_at 16 e 160 | val loss 2.0067 val acc 49.4826 best val_acc 49.482599 te_acc 52.231775\n",
      "trmean: at min-max n_at 12 e 180 | val loss 2.0198 val acc 48.5121 best val_acc 49.974259 te_acc 52.816104\n",
      "trmean: at min-max n_at 8 e 200 | val loss 2.0412 val acc 47.9690 best val_acc 51.912582 te_acc 54.623147\n",
      "trmean: at min-max n_at 12 e 220 | val loss 2.1438 val acc 47.0500 best val_acc 51.912582 te_acc 54.623147\n",
      "trmean: at min-max n_at 10 e 240 | val loss 2.3780 val acc 43.6754 best val_acc 51.912582 te_acc 54.623147\n",
      "trmean: at min-max n_at 14 e 260 | val loss 2.0443 val acc 48.2728 best val_acc 51.912582 te_acc 54.623147\n",
      "trmean: at min-max n_at 10 e 280 | val loss 2.3639 val acc 45.1709 best val_acc 51.912582 te_acc 54.623147\n",
      "trmean: at min-max n_at 9 e 300 | val loss 2.2454 val acc 45.8350 best val_acc 51.912582 te_acc 54.623147\n",
      "trmean: at min-max n_at 12 e 320 | val loss 2.0761 val acc 47.7322 best val_acc 51.912582 te_acc 54.623147\n",
      "trmean: at min-max n_at 9 e 340 | val loss 2.0039 val acc 49.1119 best val_acc 51.912582 te_acc 54.623147\n",
      "trmean: at min-max n_at 12 e 360 | val loss 2.1090 val acc 48.1363 best val_acc 51.912582 te_acc 54.623147\n",
      "trmean: at min-max n_at 10 e 380 | val loss 1.9869 val acc 49.6860 best val_acc 53.387562 te_acc 56.350391\n",
      "trmean: at min-max n_at 13 e 400 | val loss 2.0227 val acc 49.5907 best val_acc 53.763386 te_acc 56.273167\n",
      "trmean: at min-max n_at 17 e 420 | val loss 1.9924 val acc 49.6448 best val_acc 53.763386 te_acc 56.273167\n",
      "trmean: at min-max n_at 16 e 440 | val loss 1.9518 val acc 51.6964 best val_acc 54.522755 te_acc 57.446973\n",
      "trmean: at min-max n_at 11 e 460 | val loss 1.9100 val acc 50.1004 best val_acc 54.522755 te_acc 57.446973\n",
      "trmean: at min-max n_at 11 e 480 | val loss 1.9768 val acc 51.8637 best val_acc 54.522755 te_acc 57.446973\n",
      "trmean: at min-max n_at 10 e 500 | val loss 1.8974 val acc 50.2291 best val_acc 54.522755 te_acc 57.446973\n",
      "trmean: at min-max n_at 13 e 520 | val loss 1.7529 val acc 52.8753 best val_acc 56.139312 te_acc 57.941207\n",
      "trmean: at min-max n_at 7 e 540 | val loss 1.7264 val acc 54.6875 best val_acc 56.139312 te_acc 57.941207\n",
      "trmean: at min-max n_at 11 e 560 | val loss 1.7505 val acc 53.3670 best val_acc 56.139312 te_acc 57.941207\n",
      "trmean: at min-max n_at 10 e 580 | val loss 1.7092 val acc 55.9051 best val_acc 56.322076 te_acc 58.116248\n",
      "trmean: at min-max n_at 15 e 600 | val loss 1.8632 val acc 50.9344 best val_acc 57.035111 te_acc 58.685132\n",
      "trmean: at min-max n_at 13 e 620 | val loss 1.7426 val acc 54.2525 best val_acc 57.035111 te_acc 58.685132\n",
      "trmean: at min-max n_at 8 e 640 | val loss 1.6533 val acc 56.2629 best val_acc 57.035111 te_acc 58.685132\n",
      "trmean: at min-max n_at 11 e 660 | val loss 1.7228 val acc 55.0839 best val_acc 57.035111 te_acc 58.685132\n",
      "trmean: at min-max n_at 9 e 680 | val loss 1.6286 val acc 55.1740 best val_acc 57.035111 te_acc 58.685132\n",
      "trmean: at min-max n_at 10 e 700 | val loss 1.7002 val acc 55.7970 best val_acc 57.035111 te_acc 58.685132\n",
      "trmean: at min-max n_at 11 e 720 | val loss 1.6835 val acc 56.1290 best val_acc 57.035111 te_acc 58.685132\n",
      "trmean: at min-max n_at 13 e 740 | val loss 1.5855 val acc 57.3569 best val_acc 57.912891 te_acc 60.093184\n",
      "trmean: at min-max n_at 11 e 760 | val loss 1.6468 val acc 55.3696 best val_acc 58.221787 te_acc 60.559102\n",
      "trmean: at min-max n_at 15 e 780 | val loss 1.6294 val acc 56.1985 best val_acc 58.221787 te_acc 60.559102\n",
      "trmean: at min-max n_at 12 e 800 | val loss 1.5341 val acc 57.9515 best val_acc 58.551277 te_acc 60.113777\n",
      "trmean: at min-max n_at 14 e 820 | val loss 1.5724 val acc 58.5384 best val_acc 59.055807 te_acc 60.793348\n",
      "trmean: at min-max n_at 7 e 840 | val loss 1.5706 val acc 57.4753 best val_acc 59.634988 te_acc 61.720037\n",
      "trmean: at min-max n_at 14 e 860 | val loss 1.5258 val acc 59.1845 best val_acc 60.064868 te_acc 61.333917\n",
      "trmean: at min-max n_at 13 e 880 | val loss 1.4868 val acc 59.6582 best val_acc 60.178130 te_acc 62.064971\n",
      "trmean: at min-max n_at 12 e 900 | val loss 1.5592 val acc 56.7777 best val_acc 60.178130 te_acc 62.064971\n",
      "trmean: at min-max n_at 17 e 920 | val loss 1.5334 val acc 58.0236 best val_acc 60.330004 te_acc 61.938839\n",
      "trmean: at min-max n_at 11 e 940 | val loss 1.5437 val acc 58.7752 best val_acc 60.330004 te_acc 61.938839\n",
      "trmean: at min-max n_at 10 e 960 | val loss 1.5771 val acc 57.7327 best val_acc 60.330004 te_acc 61.938839\n",
      "trmean: at min-max n_at 14 e 980 | val loss 1.6241 val acc 57.8202 best val_acc 60.330004 te_acc 61.938839\n",
      "trmean: at min-max n_at 10 e 1000 | val loss 1.5653 val acc 58.6259 best val_acc 60.330004 te_acc 61.938839\n",
      "trmean: at min-max n_at 8 e 1020 | val loss 1.5816 val acc 57.1201 best val_acc 60.330004 te_acc 61.938839\n",
      "trmean: at min-max n_at 13 e 1040 | val loss 1.6064 val acc 55.9771 best val_acc 60.330004 te_acc 61.938839\n",
      "trmean: at min-max n_at 9 e 1060 | val loss 1.5900 val acc 57.1844 best val_acc 60.330004 te_acc 61.938839\n",
      "trmean: at min-max n_at 9 e 1080 | val loss 1.5337 val acc 57.9850 best val_acc 60.330004 te_acc 61.938839\n",
      "trmean: at min-max n_at 11 e 1100 | val loss 1.5176 val acc 58.3479 best val_acc 60.757311 te_acc 62.837212\n",
      "trmean: at min-max n_at 12 e 1120 | val loss 1.5513 val acc 57.3981 best val_acc 60.757311 te_acc 62.837212\n",
      "trmean: at min-max n_at 9 e 1140 | val loss 1.6169 val acc 56.8523 best val_acc 60.757311 te_acc 62.837212\n",
      "trmean: at min-max n_at 14 e 1160 | val loss 1.5502 val acc 58.0802 best val_acc 60.821664 te_acc 62.762562\n",
      "trmean: at min-max n_at 12 e 1180 | val loss 1.5194 val acc 58.8267 best val_acc 60.821664 te_acc 62.762562\n",
      "trmean: at min-max n_at 14 e 1200 | val loss 1.7424 val acc 55.1792 best val_acc 60.821664 te_acc 62.762562\n",
      "trmean: at min-max n_at 17 e 1220 | val loss 1.5349 val acc 59.7714 best val_acc 60.821664 te_acc 62.762562\n",
      "trmean: at min-max n_at 14 e 1240 | val loss 1.4874 val acc 60.3197 best val_acc 61.575886 te_acc 63.596582\n",
      "trmean: at min-max n_at 14 e 1260 | val loss 1.4989 val acc 60.7084 best val_acc 61.575886 te_acc 63.596582\n",
      "trmean: at min-max n_at 11 e 1280 | val loss 1.4956 val acc 59.8435 best val_acc 61.575886 te_acc 63.596582\n",
      "trmean: at min-max n_at 8 e 1300 | val loss 1.5748 val acc 58.4277 best val_acc 61.575886 te_acc 63.596582\n",
      "trmean: at min-max n_at 17 e 1320 | val loss 1.6680 val acc 55.8587 best val_acc 61.575886 te_acc 63.596582\n",
      "trmean: at min-max n_at 12 e 1340 | val loss 1.5217 val acc 59.2695 best val_acc 61.575886 te_acc 63.596582\n",
      "trmean: at min-max n_at 11 e 1360 | val loss 1.4876 val acc 60.0623 best val_acc 62.041804 te_acc 63.908052\n",
      "trmean: at min-max n_at 16 e 1380 | val loss 1.4415 val acc 61.1203 best val_acc 62.417628 te_acc 64.404860\n",
      "trmean: at min-max n_at 12 e 1400 | val loss 1.5454 val acc 59.4136 best val_acc 62.417628 te_acc 64.404860\n",
      "trmean: at min-max n_at 6 e 1420 | val loss 1.5602 val acc 58.6362 best val_acc 62.417628 te_acc 64.404860\n",
      "trmean: at min-max n_at 11 e 1440 | val loss 1.5073 val acc 59.5475 best val_acc 62.417628 te_acc 64.404860\n",
      "trmean: at min-max n_at 9 e 1460 | val loss 1.4575 val acc 61.6686 best val_acc 62.417628 te_acc 64.404860\n",
      "trmean: at min-max n_at 12 e 1480 | val loss 1.4629 val acc 60.5334 best val_acc 62.417628 te_acc 64.404860\n",
      "trmean: at min-max n_at 6 e 1499 | val loss 1.4279 val acc 62.0341 best val_acc 62.417628 te_acc 64.404860\n",
      "trmean: at min-max n_at 13 e 1500 | val loss 1.5026 val acc 59.8255 best val_acc 62.417628 te_acc 64.404860\n"
     ]
    }
   ],
   "source": [
    "resume=0\n",
    "nepochs=1500\n",
    "gamma=.1\n",
    "fed_lr=0.001\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "batch_size = 100\n",
    "schedule = [5000]\n",
    "\n",
    "aggregation = 'trmean'\n",
    "chkpt = './' + aggregation\n",
    "\n",
    "at_type='min-max'\n",
    "at_fractions = [20]\n",
    "\n",
    "for at_fraction in at_fractions:\n",
    "    epoch_num = 0\n",
    "\n",
    "    fed_model = mnist_conv().cuda()\n",
    "    fed_model.apply(weights_init)\n",
    "    optimizer_fed = Adam(fed_model.parameters(), lr=fed_lr)\n",
    "\n",
    "    best_global_acc=0\n",
    "    best_global_te_acc=0\n",
    "\n",
    "    while epoch_num <= nepochs:\n",
    "        user_grads = []\n",
    "\n",
    "        round_users = np.random.choice(3400, 60)\n",
    "        n_attacker = np.sum(round_users < (34*at_fraction))\n",
    "\n",
    "        at_idx = []\n",
    "        for i in np.sort(round_users):\n",
    "            if i < (34*at_fraction):\n",
    "                at_idx.append(i)\n",
    "                continue\n",
    "\n",
    "            inputs = user_tr_data_tensors[i]\n",
    "            targets = user_tr_label_tensors[i]\n",
    "\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "            outputs = fed_model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            optimizer_fed.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "\n",
    "            param_grad=[]\n",
    "            for param in fed_model.parameters():\n",
    "                param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
    "\n",
    "            user_grads=param_grad[None,:] if len(user_grads)==0 else torch.cat((user_grads,param_grad[None,:]),0)    \n",
    "\n",
    "        if n_attacker > 0:\n",
    "            attacker_grads = []\n",
    "            n_attacker_ = max(1, n_attacker**2//60)\n",
    "            for i in at_idx:\n",
    "\n",
    "                inputs = user_tr_data_tensors[i]\n",
    "                targets = user_tr_label_tensors[i]\n",
    "\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "                inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "                outputs = fed_model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                optimizer_fed.zero_grad()\n",
    "                loss.backward(retain_graph=True)\n",
    "\n",
    "                param_grad=[]\n",
    "                for param in fed_model.parameters():\n",
    "                    param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
    "\n",
    "                attacker_grads=param_grad[None,:] if len(attacker_grads)==0 else torch.cat((attacker_grads,param_grad[None,:]),0)\n",
    "\n",
    "            mal_updates = []\n",
    "            if at_type == 'lie':\n",
    "                mal_update = lie_attack(malicious_grads, z)\n",
    "            elif at_type == 'fang':\n",
    "                mal_updates = fang_attack_trmean_partial(attacker_grads, n_attacker)\n",
    "            elif at_type == 'our-agr':\n",
    "                mal_update = our_attack_trmean(attacker_grads, n_attacker_, dev_type='sign', threshold=5.0, threshold_diff=1e-5)\n",
    "            elif at_type == 'min-max':\n",
    "                agg_grads = torch.mean(attacker_grads, 0)\n",
    "                mal_update = our_attack_dist(malicious_grads, agg_grads, n_attacker_, dev_type='sign')\n",
    "            elif at_type == 'min-sum':\n",
    "                agg_grads = torch.mean(malicious_grads, 0)\n",
    "                mal_update = our_attack_score(attacker_grads, agg_grads, n_attacker_, dev_type='sign')\n",
    "                \n",
    "        if not len(mal_updates):\n",
    "            mal_updates = torch.stack([mal_update] * n_attacker)\n",
    "        malicious_grads = torch.cat((mal_updates, user_grads), 0)\n",
    "                \n",
    "        if malicious_grads.shape[0] != 60: \n",
    "            print('malicious grads shape ', malicious_grads.shape)\n",
    "            sys.exit()\n",
    "\n",
    "        agg_grads=tr_mean(malicious_grads, n_attacker)\n",
    "\n",
    "        start_idx=0\n",
    "\n",
    "        if epoch_num in schedule:\n",
    "            for param_group in optimizer_fed.param_groups:\n",
    "                param_group['lr'] *= gamma\n",
    "                print('New learnin rate ', param_group['lr'])\n",
    "\n",
    "        optimizer_fed.zero_grad()\n",
    "\n",
    "        model_grads=[]\n",
    "\n",
    "        for i, param in enumerate(fed_model.parameters()):\n",
    "            param_=agg_grads[start_idx:start_idx+len(param.data.view(-1))].reshape(param.data.shape)\n",
    "            start_idx=start_idx+len(param.data.view(-1))\n",
    "            param_=param_.cuda()\n",
    "            model_grads.append(param_)\n",
    "\n",
    "        optimizer_fed.step(model_grads)\n",
    "\n",
    "        val_loss, val_acc = test(val_data_tensor,val_label_tensor,fed_model,criterion,use_cuda)\n",
    "        te_loss, te_acc = test(te_data_tensor,te_label_tensor, fed_model, criterion, use_cuda)\n",
    "\n",
    "        is_best = best_global_acc < val_acc\n",
    "\n",
    "        best_global_acc = max(best_global_acc, val_acc)\n",
    "\n",
    "        if is_best:\n",
    "            best_global_te_acc = te_acc\n",
    "\n",
    "        if epoch_num % 20 == 0 or epoch_num == nepochs-1:\n",
    "            print('%s: at %s n_at %d e %d | val loss %.4f val acc %.4f best val_acc %f te_acc %f'%(aggregation, at_type, n_attacker, epoch_num, val_loss, val_acc, best_global_acc,best_global_te_acc))\n",
    "\n",
    "        epoch_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for our first SOTA AGR-agnostic attack - Min-sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def our_attack_score(all_updates, model_re, n_attackers, dev_type='unit_vec'):\n",
    "\n",
    "    if dev_type == 'unit_vec':\n",
    "        deviation = model_re / torch.norm(model_re)  # unit vector, dir opp to good dir\n",
    "    elif dev_type == 'sign':\n",
    "        deviation = torch.sign(model_re)\n",
    "    elif dev_type == 'std':\n",
    "        deviation = torch.std(all_updates, 0)\n",
    "    \n",
    "    lamda = torch.Tensor([50.0]).float().cuda()\n",
    "    # print(lamda)\n",
    "    threshold_diff = 1e-5\n",
    "    lamda_fail = lamda\n",
    "    lamda_succ = 0\n",
    "    \n",
    "    distances = []\n",
    "    for update in all_updates:\n",
    "        distance = torch.norm((all_updates - update), dim=1) ** 2\n",
    "        distances = distance[None, :] if not len(distances) else torch.cat((distances, distance[None, :]), 0)\n",
    "    \n",
    "    scores = torch.sum(distances, dim=1)\n",
    "    min_score = torch.min(scores)\n",
    "    del distances\n",
    "\n",
    "    while torch.abs(lamda_succ - lamda) > threshold_diff:\n",
    "        mal_update = (model_re - lamda * deviation)\n",
    "        distance = torch.norm((all_updates - mal_update), dim=1) ** 2\n",
    "        score = torch.sum(distance)\n",
    "        \n",
    "        if score <= min_score:\n",
    "            # print('successful lamda is ', lamda)\n",
    "            lamda_succ = lamda\n",
    "            lamda = lamda + lamda_fail / 2\n",
    "        else:\n",
    "            lamda = lamda - lamda_fail / 2\n",
    "\n",
    "        lamda_fail = lamda_fail / 2\n",
    "\n",
    "    # print(lamda_succ)\n",
    "    mal_update = (model_re - lamda_succ * deviation)\n",
    "    \n",
    "    return mal_update\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trmean: at min-max n_at 9 e 0 | val loss 3.9717 val acc 5.2898 best val_acc 5.289848 te_acc 5.974568\n",
      "trmean: at min-max n_at 11 e 20 | val loss 3.8340 val acc 14.8425 best val_acc 16.080622 te_acc 18.026668\n",
      "trmean: at min-max n_at 18 e 40 | val loss 3.6740 val acc 28.0272 best val_acc 28.740218 te_acc 32.390342\n",
      "trmean: at min-max n_at 12 e 60 | val loss 3.4031 val acc 30.4597 best val_acc 30.660523 te_acc 34.367278\n",
      "trmean: at min-max n_at 8 e 80 | val loss 3.1673 val acc 33.8833 best val_acc 34.251442 te_acc 38.231054\n",
      "trmean: at min-max n_at 11 e 100 | val loss 2.6509 val acc 38.8617 best val_acc 38.861717 te_acc 43.222302\n",
      "trmean: at min-max n_at 13 e 120 | val loss 2.6429 val acc 40.3187 best val_acc 40.439662 te_acc 44.882619\n",
      "trmean: at min-max n_at 11 e 140 | val loss 2.2946 val acc 42.3497 best val_acc 42.349671 te_acc 46.970243\n",
      "trmean: at min-max n_at 17 e 160 | val loss 2.1820 val acc 43.2609 best val_acc 43.608423 te_acc 48.316516\n",
      "trmean: at min-max n_at 8 e 180 | val loss 2.1260 val acc 44.2211 best val_acc 45.539024 te_acc 49.920202\n",
      "trmean: at min-max n_at 11 e 200 | val loss 2.1024 val acc 44.7410 best val_acc 47.551998 te_acc 51.755560\n",
      "trmean: at min-max n_at 12 e 220 | val loss 1.9957 val acc 46.7823 best val_acc 47.974156 te_acc 52.414539\n",
      "trmean: at min-max n_at 10 e 240 | val loss 2.0790 val acc 46.5687 best val_acc 49.652492 te_acc 53.791701\n",
      "trmean: at min-max n_at 10 e 260 | val loss 1.7712 val acc 52.2730 best val_acc 52.671952 te_acc 55.763488\n",
      "trmean: at min-max n_at 12 e 280 | val loss 1.7204 val acc 53.7016 best val_acc 54.203563 te_acc 57.282228\n",
      "trmean: at min-max n_at 8 e 300 | val loss 1.7386 val acc 53.0529 best val_acc 54.494440 te_acc 57.987541\n",
      "trmean: at min-max n_at 14 e 320 | val loss 1.6997 val acc 53.5111 best val_acc 54.718390 te_acc 58.028727\n",
      "trmean: at min-max n_at 17 e 340 | val loss 1.8493 val acc 51.0992 best val_acc 57.246190 te_acc 60.144666\n",
      "trmean: at min-max n_at 10 e 360 | val loss 1.6977 val acc 53.7402 best val_acc 57.246190 te_acc 60.144666\n",
      "trmean: at min-max n_at 13 e 380 | val loss 1.7030 val acc 53.3850 best val_acc 57.498456 te_acc 60.574547\n",
      "trmean: at min-max n_at 12 e 400 | val loss 1.8244 val acc 51.1043 best val_acc 57.498456 te_acc 60.574547\n",
      "trmean: at min-max n_at 11 e 420 | val loss 1.8721 val acc 51.7659 best val_acc 57.498456 te_acc 60.574547\n",
      "trmean: at min-max n_at 9 e 440 | val loss 1.6508 val acc 55.5009 best val_acc 58.309308 te_acc 60.883443\n",
      "trmean: at min-max n_at 10 e 460 | val loss 1.6162 val acc 56.1264 best val_acc 58.309308 te_acc 60.883443\n",
      "trmean: at min-max n_at 9 e 480 | val loss 1.6004 val acc 56.2757 best val_acc 58.329901 te_acc 61.712315\n",
      "trmean: at min-max n_at 9 e 500 | val loss 1.5298 val acc 58.9786 best val_acc 60.911759 te_acc 63.086903\n",
      "trmean: at min-max n_at 9 e 520 | val loss 1.8207 val acc 53.0864 best val_acc 60.911759 te_acc 63.086903\n",
      "trmean: at min-max n_at 9 e 540 | val loss 1.5745 val acc 56.9682 best val_acc 60.911759 te_acc 63.086903\n",
      "trmean: at min-max n_at 12 e 560 | val loss 1.7304 val acc 54.7107 best val_acc 60.911759 te_acc 63.086903\n",
      "trmean: at min-max n_at 17 e 580 | val loss 1.8065 val acc 52.5510 best val_acc 60.911759 te_acc 63.086903\n",
      "trmean: at min-max n_at 15 e 600 | val loss 1.7440 val acc 55.3696 best val_acc 60.911759 te_acc 63.086903\n",
      "trmean: at min-max n_at 11 e 620 | val loss 1.7302 val acc 54.8445 best val_acc 60.911759 te_acc 63.086903\n",
      "trmean: at min-max n_at 9 e 640 | val loss 1.4903 val acc 59.3004 best val_acc 60.911759 te_acc 63.086903\n",
      "trmean: at min-max n_at 12 e 660 | val loss 1.7295 val acc 54.3735 best val_acc 60.911759 te_acc 63.086903\n",
      "trmean: at min-max n_at 16 e 680 | val loss 1.6477 val acc 55.9257 best val_acc 61.969728 te_acc 64.240115\n",
      "trmean: at min-max n_at 11 e 700 | val loss 1.5169 val acc 59.0043 best val_acc 62.095861 te_acc 63.316001\n",
      "trmean: at min-max n_at 13 e 720 | val loss 1.5442 val acc 58.2321 best val_acc 62.095861 te_acc 63.316001\n",
      "trmean: at min-max n_at 8 e 740 | val loss 1.5862 val acc 57.3208 best val_acc 63.017401 te_acc 64.708608\n",
      "trmean: at min-max n_at 17 e 760 | val loss 1.4093 val acc 61.5347 best val_acc 63.017401 te_acc 64.708608\n",
      "trmean: at min-max n_at 14 e 780 | val loss 1.4465 val acc 61.1306 best val_acc 63.017401 te_acc 64.708608\n",
      "trmean: at min-max n_at 7 e 800 | val loss 1.5385 val acc 58.9837 best val_acc 63.017401 te_acc 64.708608\n",
      "trmean: at min-max n_at 14 e 820 | val loss 1.5950 val acc 58.1291 best val_acc 63.308278 te_acc 65.012356\n",
      "trmean: at min-max n_at 7 e 840 | val loss 1.3799 val acc 61.8668 best val_acc 63.308278 te_acc 65.012356\n",
      "trmean: at min-max n_at 16 e 860 | val loss 1.7484 val acc 54.4558 best val_acc 63.308278 te_acc 65.012356\n",
      "trmean: at min-max n_at 13 e 880 | val loss 1.6205 val acc 56.9373 best val_acc 63.308278 te_acc 65.012356\n",
      "trmean: at min-max n_at 9 e 900 | val loss 1.6702 val acc 55.7197 best val_acc 63.308278 te_acc 65.012356\n",
      "trmean: at min-max n_at 17 e 920 | val loss 1.5389 val acc 58.4148 best val_acc 63.308278 te_acc 65.012356\n",
      "trmean: at min-max n_at 13 e 940 | val loss 1.4760 val acc 59.6993 best val_acc 64.108834 te_acc 66.060029\n",
      "trmean: at min-max n_at 9 e 960 | val loss 1.3987 val acc 61.5733 best val_acc 64.108834 te_acc 66.060029\n",
      "trmean: at min-max n_at 10 e 980 | val loss 1.5195 val acc 59.8178 best val_acc 64.108834 te_acc 66.060029\n",
      "trmean: at min-max n_at 12 e 1000 | val loss 1.5343 val acc 59.7560 best val_acc 64.108834 te_acc 66.060029\n",
      "trmean: at min-max n_at 15 e 1020 | val loss 1.3516 val acc 62.5360 best val_acc 64.108834 te_acc 66.060029\n",
      "trmean: at min-max n_at 10 e 1040 | val loss 1.4415 val acc 60.9555 best val_acc 64.108834 te_acc 66.060029\n",
      "trmean: at min-max n_at 9 e 1060 | val loss 1.3699 val acc 62.6467 best val_acc 64.108834 te_acc 66.060029\n",
      "trmean: at min-max n_at 10 e 1080 | val loss 1.4728 val acc 60.3557 best val_acc 64.108834 te_acc 66.060029\n",
      "trmean: at min-max n_at 11 e 1100 | val loss 1.4246 val acc 60.4561 best val_acc 64.229819 te_acc 65.897858\n",
      "trmean: at min-max n_at 12 e 1120 | val loss 1.3558 val acc 61.9646 best val_acc 64.229819 te_acc 65.897858\n",
      "trmean: at min-max n_at 7 e 1140 | val loss 1.3420 val acc 62.7342 best val_acc 64.229819 te_acc 65.897858\n",
      "trmean: at min-max n_at 12 e 1160 | val loss 1.4833 val acc 60.5591 best val_acc 64.229819 te_acc 65.897858\n",
      "trmean: at min-max n_at 12 e 1180 | val loss 1.4318 val acc 60.8423 best val_acc 64.229819 te_acc 65.897858\n",
      "trmean: at min-max n_at 16 e 1200 | val loss 1.5286 val acc 60.1035 best val_acc 64.229819 te_acc 65.897858\n",
      "trmean: at min-max n_at 14 e 1220 | val loss 1.5900 val acc 59.1511 best val_acc 64.229819 te_acc 65.897858\n",
      "trmean: at min-max n_at 11 e 1240 | val loss 1.5091 val acc 59.6968 best val_acc 64.229819 te_acc 65.897858\n",
      "trmean: at min-max n_at 15 e 1260 | val loss 1.8142 val acc 56.0981 best val_acc 64.229819 te_acc 65.897858\n",
      "trmean: at min-max n_at 19 e 1280 | val loss 1.5706 val acc 58.8988 best val_acc 64.229819 te_acc 65.897858\n",
      "trmean: at min-max n_at 13 e 1300 | val loss 1.5631 val acc 58.5899 best val_acc 64.229819 te_acc 65.897858\n",
      "trmean: at min-max n_at 12 e 1320 | val loss 1.6590 val acc 57.1741 best val_acc 64.229819 te_acc 65.897858\n",
      "trmean: at min-max n_at 9 e 1340 | val loss 1.3437 val acc 62.9016 best val_acc 64.229819 te_acc 65.897858\n",
      "trmean: at min-max n_at 15 e 1360 | val loss 1.5434 val acc 58.8808 best val_acc 64.229819 te_acc 65.897858\n",
      "trmean: at min-max n_at 12 e 1380 | val loss 1.6632 val acc 56.6825 best val_acc 64.229819 te_acc 65.897858\n",
      "trmean: at min-max n_at 10 e 1400 | val loss 1.4574 val acc 60.3763 best val_acc 64.229819 te_acc 65.897858\n",
      "trmean: at min-max n_at 8 e 1420 | val loss 1.4534 val acc 59.9156 best val_acc 64.229819 te_acc 65.897858\n",
      "trmean: at min-max n_at 7 e 1440 | val loss 1.3439 val acc 62.5026 best val_acc 64.229819 te_acc 65.897858\n",
      "trmean: at min-max n_at 13 e 1460 | val loss 1.5460 val acc 58.5178 best val_acc 64.229819 te_acc 65.897858\n",
      "trmean: at min-max n_at 15 e 1480 | val loss 1.5918 val acc 58.3299 best val_acc 64.229819 te_acc 65.897858\n",
      "trmean: at min-max n_at 12 e 1499 | val loss 1.6688 val acc 56.2680 best val_acc 64.229819 te_acc 65.897858\n",
      "trmean: at min-max n_at 19 e 1500 | val loss 1.7776 val acc 54.7724 best val_acc 64.229819 te_acc 65.897858\n"
     ]
    }
   ],
   "source": [
    "resume=0\n",
    "nepochs=1500\n",
    "gamma=.1\n",
    "fed_lr=0.001\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "batch_size = 100\n",
    "schedule = [5000]\n",
    "\n",
    "aggregation = 'trmean'\n",
    "chkpt = './' + aggregation\n",
    "\n",
    "at_type='min-max'\n",
    "at_fractions = [20]\n",
    "\n",
    "for at_fraction in at_fractions:\n",
    "    epoch_num = 0\n",
    "\n",
    "    fed_model = mnist_conv().cuda()\n",
    "    fed_model.apply(weights_init)\n",
    "    optimizer_fed = Adam(fed_model.parameters(), lr=fed_lr)\n",
    "\n",
    "    best_global_acc=0\n",
    "    best_global_te_acc=0\n",
    "\n",
    "    while epoch_num <= nepochs:\n",
    "        user_grads = []\n",
    "\n",
    "        round_users = np.random.choice(3400, 60)\n",
    "        n_attacker = np.sum(round_users < (34*at_fraction))\n",
    "\n",
    "        at_idx = []\n",
    "        for i in np.sort(round_users):\n",
    "            if i < (34*at_fraction):\n",
    "                at_idx.append(i)\n",
    "                continue\n",
    "\n",
    "            inputs = user_tr_data_tensors[i]\n",
    "            targets = user_tr_label_tensors[i]\n",
    "\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "            outputs = fed_model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            optimizer_fed.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "\n",
    "            param_grad=[]\n",
    "            for param in fed_model.parameters():\n",
    "                param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
    "\n",
    "            user_grads=param_grad[None,:] if len(user_grads)==0 else torch.cat((user_grads,param_grad[None,:]),0)    \n",
    "\n",
    "        if n_attacker > 0:\n",
    "            attacker_grads = []\n",
    "            n_attacker_ = max(1, n_attacker**2//60)\n",
    "            for i in at_idx:\n",
    "\n",
    "                inputs = user_tr_data_tensors[i]\n",
    "                targets = user_tr_label_tensors[i]\n",
    "\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "                inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "                outputs = fed_model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                optimizer_fed.zero_grad()\n",
    "                loss.backward(retain_graph=True)\n",
    "\n",
    "                param_grad=[]\n",
    "                for param in fed_model.parameters():\n",
    "                    param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
    "\n",
    "                attacker_grads=param_grad[None,:] if len(attacker_grads)==0 else torch.cat((attacker_grads,param_grad[None,:]),0)\n",
    "\n",
    "            mal_updates = []\n",
    "            if at_type == 'lie':\n",
    "                mal_update = lie_attack(malicious_grads, z)\n",
    "            elif at_type == 'fang':\n",
    "                mal_updates = fang_attack_trmean_partial(attacker_grads, n_attacker)\n",
    "            elif at_type == 'our-agr':\n",
    "                mal_update = our_attack_trmean(attacker_grads, n_attacker_, dev_type='sign', threshold=5.0, threshold_diff=1e-5)\n",
    "            elif at_type == 'min-max':\n",
    "                agg_grads = torch.mean(attacker_grads, 0)\n",
    "                mal_update = our_attack_dist(malicious_grads, agg_grads, n_attacker_, dev_type='sign')\n",
    "            elif at_type == 'min-sum':\n",
    "                agg_grads = torch.mean(malicious_grads, 0)\n",
    "                mal_update = our_attack_score(attacker_grads, agg_grads, n_attacker_, dev_type='sign')\n",
    "                \n",
    "        if not len(mal_updates):\n",
    "            mal_updates = torch.stack([mal_update] * n_attacker)\n",
    "        malicious_grads = torch.cat((mal_updates, user_grads), 0)\n",
    "                \n",
    "        if malicious_grads.shape[0] != 60: \n",
    "            print('malicious grads shape ', malicious_grads.shape)\n",
    "            sys.exit()\n",
    "\n",
    "        agg_grads=tr_mean(malicious_grads, n_attacker)\n",
    "\n",
    "        start_idx=0\n",
    "\n",
    "        if epoch_num in schedule:\n",
    "            for param_group in optimizer_fed.param_groups:\n",
    "                param_group['lr'] *= gamma\n",
    "                print('New learnin rate ', param_group['lr'])\n",
    "\n",
    "        optimizer_fed.zero_grad()\n",
    "\n",
    "        model_grads=[]\n",
    "\n",
    "        for i, param in enumerate(fed_model.parameters()):\n",
    "            param_=agg_grads[start_idx:start_idx+len(param.data.view(-1))].reshape(param.data.shape)\n",
    "            start_idx=start_idx+len(param.data.view(-1))\n",
    "            param_=param_.cuda()\n",
    "            model_grads.append(param_)\n",
    "\n",
    "        optimizer_fed.step(model_grads)\n",
    "\n",
    "        val_loss, val_acc = test(val_data_tensor,val_label_tensor,fed_model,criterion,use_cuda)\n",
    "        te_loss, te_acc = test(te_data_tensor,te_label_tensor, fed_model, criterion, use_cuda)\n",
    "\n",
    "        is_best = best_global_acc < val_acc\n",
    "\n",
    "        best_global_acc = max(best_global_acc, val_acc)\n",
    "\n",
    "        if is_best:\n",
    "            best_global_te_acc = te_acc\n",
    "\n",
    "        if epoch_num % 20 == 0 or epoch_num == nepochs-1:\n",
    "            print('%s: at %s n_at %d e %d | val loss %.4f val acc %.4f best val_acc %f te_acc %f'%(aggregation, at_type, n_attacker, epoch_num, val_loss, val_acc, best_global_acc,best_global_te_acc))\n",
    "\n",
    "        epoch_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
