{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The notebook contains\n",
    "### Code for _Bulyan_ aggregation algorithm, *when gradient updates of benign clients are unknown to adversary*\n",
    "### Evaluation of all the attacks (Fang, LIE, and our AGR-agnstic) on Multi-krum, except our AGR-tailored attack on Bulyan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse, os, sys, csv, shutil, time, random, operator, pickle, ast, math, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.optim import Optimizer\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "sys.path.insert(0,'./../utils/')\n",
    "from logger import *\n",
    "from eval import *\n",
    "from misc import *\n",
    "\n",
    "from femnist_normal_train import *\n",
    "from femnist_util import *\n",
    "from adam import Adam\n",
    "from sgd import SGD\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the FEMNIST dataset; we use [LEAF framework](https://leaf.cmu.edu/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_tr_data = []\n",
    "user_tr_labels = []\n",
    "\n",
    "for i in range(34):\n",
    "    f = '/mnt/nfs/work1/amir/vshejwalkar/leaf/data/femnist/data/train/all_data_%d_niid_0_keep_0_train_9.json'%i\n",
    "    with open(f, 'r') as myfile:\n",
    "        data=myfile.read()\n",
    "    obj = json.loads(data)\n",
    "    \n",
    "    for user in obj['users']:\n",
    "        user_tr_data.append(obj['user_data'][user]['x'])\n",
    "        user_tr_labels.append(obj['user_data'][user]['y'])\n",
    "\n",
    "user_te_data = []\n",
    "user_te_labels = []\n",
    "\n",
    "for i in range(34):\n",
    "    f = '/mnt/nfs/work1/amir/vshejwalkar/leaf/data/femnist/data/test/all_data_%d_niid_0_keep_0_test_9.json'%i\n",
    "    with open(f, 'r') as myfile:\n",
    "        data=myfile.read()\n",
    "    obj = json.loads(data)\n",
    "    \n",
    "    for user in obj['users']:\n",
    "        user_te_data.append(obj['user_data'][user]['x'])\n",
    "        user_te_labels.append(obj['user_data'][user]['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of clients:  3400\n"
     ]
    }
   ],
   "source": [
    "user_tr_data_tensors=[]\n",
    "user_tr_label_tensors=[]\n",
    "\n",
    "for i in range(len(user_tr_data)):\n",
    "    \n",
    "    user_tr_data_tensor=torch.from_numpy(np.array(user_tr_data[i])).type(torch.FloatTensor)\n",
    "    user_tr_label_tensor=torch.from_numpy(np.array(user_tr_labels[i])).type(torch.LongTensor)\n",
    "\n",
    "    user_tr_data_tensors.append(user_tr_data_tensor)\n",
    "    user_tr_label_tensors.append(user_tr_label_tensor)\n",
    "    \n",
    "    # print('user %d tr len %d'%(i,len(user_tr_data_tensor)))\n",
    "print(\"number of clients: \", len(user_tr_data_tensors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_data = np.concatenate(user_te_data, 0)\n",
    "te_labels = np.concatenate(user_te_labels)\n",
    "te_len = len(te_labels)\n",
    "\n",
    "te_data_tensor = torch.from_numpy(te_data[:(te_len//2)]).type(torch.FloatTensor)\n",
    "te_label_tensor = torch.from_numpy(te_labels[:(te_len//2)]).type(torch.LongTensor)\n",
    "\n",
    "val_data_tensor = torch.from_numpy(te_data[(te_len//2):]).type(torch.FloatTensor)\n",
    "val_label_tensor = torch.from_numpy(te_labels[(te_len//2):]).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for Bulyan aggregation algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bulyan(all_updates, n_attackers):\n",
    "    nusers = all_updates.shape[0]\n",
    "    bulyan_cluster = []\n",
    "    candidate_indices = []\n",
    "    remaining_updates = all_updates\n",
    "    all_indices = np.arange(len(all_updates))\n",
    "\n",
    "    while len(bulyan_cluster) < (nusers - 2 * n_attackers):\n",
    "        distances = []\n",
    "        for update in remaining_updates:\n",
    "            distance = torch.norm((remaining_updates - update), dim=1) ** 2\n",
    "            distances = distance[None, :] if not len(distances) else torch.cat((distances, distance[None, :]), 0)\n",
    "\n",
    "        distances = torch.sort(distances, dim=1)[0]\n",
    "\n",
    "        scores = torch.sum(distances[:, :len(remaining_updates) - 2 - n_attackers], dim=1)\n",
    "        indices = torch.argsort(scores)[:len(remaining_updates) - 2 - n_attackers]\n",
    "\n",
    "        candidate_indices.append(all_indices[indices[0].cpu().numpy()])\n",
    "        all_indices = np.delete(all_indices, indices[0].cpu().numpy())\n",
    "        bulyan_cluster = remaining_updates[indices[0]][None, :] if not len(bulyan_cluster) else torch.cat((bulyan_cluster, remaining_updates[indices[0]][None, :]), 0)\n",
    "        remaining_updates = torch.cat((remaining_updates[:indices[0]], remaining_updates[indices[0] + 1:]), 0)\n",
    "\n",
    "    # print('dim of bulyan cluster ', bulyan_cluster.shape)\n",
    "\n",
    "    n, d = bulyan_cluster.shape\n",
    "    param_med = torch.median(bulyan_cluster, dim=0)[0]\n",
    "    sort_idx = torch.argsort(torch.abs(bulyan_cluster - param_med), dim=0)\n",
    "    sorted_params = bulyan_cluster[sort_idx, torch.arange(d)[None, :]]\n",
    "\n",
    "    return torch.mean(sorted_params[:n - 2 * n_attackers], dim=0), np.array(candidate_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for Multi-krum aggregation algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_krum(all_updates, n_attackers, multi_k=False):\n",
    "    nusers = all_updates.shape[0]\n",
    "    candidates = []\n",
    "    candidate_indices = []\n",
    "    remaining_updates = all_updates\n",
    "    all_indices = np.arange(len(all_updates))\n",
    "\n",
    "    while len(remaining_updates) > 2 * n_attackers + 2:\n",
    "        distances = []\n",
    "        for update in remaining_updates:\n",
    "            distance = torch.norm((remaining_updates - update), dim=1) ** 2\n",
    "            distances = distance[None, :] if not len(distances) else torch.cat((distances, distance[None, :]), 0)\n",
    "\n",
    "        distances = torch.sort(distances, dim=1)[0]\n",
    "        scores = torch.sum(distances[:, :len(remaining_updates) - 2 - n_attackers], dim=1)\n",
    "        indices = torch.argsort(scores)[:len(remaining_updates) - 2 - n_attackers]\n",
    "\n",
    "        candidate_indices.append(all_indices[indices[0].cpu().numpy()])\n",
    "        all_indices = np.delete(all_indices, indices[0].cpu().numpy())\n",
    "        candidates = remaining_updates[indices[0]][None, :] if not len(candidates) else torch.cat((candidates, remaining_updates[indices[0]][None, :]), 0)\n",
    "        remaining_updates = torch.cat((remaining_updates[:indices[0]], remaining_updates[indices[0] + 1:]), 0)\n",
    "        if not multi_k:\n",
    "            break\n",
    "    # print(len(remaining_updates))\n",
    "    aggregate = torch.mean(candidates, dim=0)\n",
    "    return aggregate, np.array(candidate_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for Fang attack on Bulyan\n",
    "### Fang attacks on MKrum and Bulyan are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lambda(all_updates, model_re, n_attackers):\n",
    "\n",
    "    distances = []\n",
    "    n_benign, d = all_updates.shape\n",
    "    for update in all_updates:\n",
    "        distance = torch.norm((all_updates - update), dim=1)\n",
    "        distances = distance[None, :] if not len(distances) else torch.cat((distances, distance[None, :]), 0)\n",
    "\n",
    "    distances[distances == 0] = 10000\n",
    "    distances = torch.sort(distances, dim=1)[0]\n",
    "    scores = torch.sum(distances[:, :n_benign - 2 - n_attackers], dim=1)\n",
    "    min_score = torch.min(scores)\n",
    "    term_1 = min_score / ((n_benign - n_attackers - 1) * torch.sqrt(torch.Tensor([d]))[0])\n",
    "    max_wre_dist = torch.max(torch.norm((all_updates - model_re), dim=1)) / (torch.sqrt(torch.Tensor([d]))[0])\n",
    "\n",
    "    return (term_1 + max_wre_dist)\n",
    "\n",
    "\n",
    "def get_malicious_updates_fang(all_updates, model_re, deviation, n_attackers):\n",
    "\n",
    "    lamda = compute_lambda(all_updates, model_re, n_attackers)\n",
    "\n",
    "    threshold = 1e-5\n",
    "    mal_update = []\n",
    "\n",
    "    while lamda > threshold:\n",
    "        mal_update = (-lamda * deviation)\n",
    "        mal_updates = torch.stack([mal_update] * n_attackers)\n",
    "        mal_updates = torch.cat((mal_updates, all_updates), 0)\n",
    "\n",
    "        # print(mal_updates.shape, n_attackers)\n",
    "        agg_grads, krum_candidate = multi_krum(mal_updates, n_attackers, multi_k=False)\n",
    "        if krum_candidate < n_attackers:\n",
    "            # print('successful lamda is ', lamda)\n",
    "            return mal_update\n",
    "        else:\n",
    "            mal_update = []\n",
    "\n",
    "        lamda *= 0.5\n",
    "\n",
    "    if not len(mal_update):\n",
    "        mal_update = (model_re - lamda * deviation)\n",
    "        \n",
    "    return mal_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Initializing global model\n",
      "multi krum is  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vshejwalkar/NDSS21-Model-Poisoning/femnist/adam.py:76: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729138878/work/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  exp_avg.mul_(beta1).add_(1 - beta1, grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 0 fed_model val loss 3.9978 val acc 5.6168 best val_acc 5.616763 te_acc 6.059514\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 20 fed_model val loss 3.6510 val acc 17.0923 best val_acc 24.853274 te_acc 27.378501\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 8 e 40 fed_model val loss 3.0469 val acc 32.9077 best val_acc 32.907743 te_acc 37.286347\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 60 fed_model val loss 2.2733 val acc 42.3162 best val_acc 42.316207 te_acc 45.904551\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 80 fed_model val loss 1.9151 val acc 49.7271 best val_acc 49.860997 te_acc 52.404242\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 100 fed_model val loss 1.7264 val acc 54.1083 best val_acc 54.108320 te_acc 56.059514\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 120 fed_model val loss 1.5930 val acc 56.8240 best val_acc 57.300247 te_acc 58.674835\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 140 fed_model val loss 1.4744 val acc 60.1035 best val_acc 60.103480 te_acc 61.673703\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 160 fed_model val loss 1.3806 val acc 62.4614 best val_acc 62.538612 te_acc 63.897755\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 180 fed_model val loss 1.3032 val acc 64.9377 best val_acc 64.937706 te_acc 65.987953\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 200 fed_model val loss 1.2532 val acc 65.3959 best val_acc 65.457681 te_acc 66.299423\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 220 fed_model val loss 1.2246 val acc 65.9545 best val_acc 66.598023 te_acc 67.519563\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 240 fed_model val loss 1.1732 val acc 67.0639 best val_acc 67.313633 te_acc 68.201709\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 260 fed_model val loss 1.1449 val acc 68.1605 best val_acc 68.160523 te_acc 68.984246\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 280 fed_model val loss 1.1220 val acc 68.8092 best val_acc 68.809205 te_acc 69.607187\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 300 fed_model val loss 1.1012 val acc 69.4167 best val_acc 69.416701 te_acc 70.206960\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 320 fed_model val loss 1.0794 val acc 69.9547 best val_acc 69.980437 te_acc 70.819605\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 340 fed_model val loss 1.0888 val acc 69.4347 best val_acc 70.482393 te_acc 71.239189\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 360 fed_model val loss 1.0608 val acc 70.6394 best val_acc 70.678027 te_acc 71.221170\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 380 fed_model val loss 1.0418 val acc 71.0873 best val_acc 71.107908 te_acc 71.970243\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 400 fed_model val loss 1.0345 val acc 71.5120 best val_acc 71.512047 te_acc 72.317751\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 420 fed_model val loss 1.0315 val acc 71.7386 best val_acc 71.805498 te_acc 72.570016\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 440 fed_model val loss 1.0251 val acc 72.1221 best val_acc 72.168451 te_acc 72.904654\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 460 fed_model val loss 1.0220 val acc 72.0140 best val_acc 72.508237 te_acc 73.128604\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 480 fed_model val loss 1.0109 val acc 72.7193 best val_acc 72.876339 te_acc 73.373147\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 500 fed_model val loss 1.0017 val acc 73.1054 best val_acc 73.277904 te_acc 73.689765\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 520 fed_model val loss 0.9986 val acc 73.2316 best val_acc 73.398888 te_acc 73.823620\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 540 fed_model val loss 1.0047 val acc 73.3345 best val_acc 73.434926 te_acc 73.895696\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 560 fed_model val loss 1.0130 val acc 73.4375 best val_acc 73.463241 te_acc 73.890548\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 580 fed_model val loss 1.0222 val acc 73.5430 best val_acc 73.545614 te_acc 73.916289\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 600 fed_model val loss 1.0327 val acc 73.6383 best val_acc 73.664024 te_acc 73.913715\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 620 fed_model val loss 1.0445 val acc 73.6692 best val_acc 73.676895 te_acc 74.011532\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 640 fed_model val loss 1.0864 val acc 73.1878 best val_acc 73.785008 te_acc 74.019255\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 660 fed_model val loss 1.0647 val acc 73.9703 best val_acc 73.970346 te_acc 74.034699\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 680 fed_model val loss 1.0718 val acc 73.9008 best val_acc 74.037273 te_acc 74.137665\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 700 fed_model val loss 1.0877 val acc 73.9111 best val_acc 74.075886 te_acc 74.220037\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 720 fed_model val loss 1.1024 val acc 73.9935 best val_acc 74.075886 te_acc 74.220037\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 740 fed_model val loss 1.1204 val acc 73.8365 best val_acc 74.075886 te_acc 74.220037\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 760 fed_model val loss 1.1313 val acc 74.0604 best val_acc 74.075886 te_acc 74.220037\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 780 fed_model val loss 1.1551 val acc 73.7953 best val_acc 74.075886 te_acc 74.220037\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 800 fed_model val loss 1.1646 val acc 73.8648 best val_acc 74.075886 te_acc 74.220037\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 820 fed_model val loss 1.1727 val acc 73.7902 best val_acc 74.075886 te_acc 74.220037\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 840 fed_model val loss 1.1902 val acc 73.8107 best val_acc 74.075886 te_acc 74.220037\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 860 fed_model val loss 1.2651 val acc 72.1582 best val_acc 74.075886 te_acc 74.220037\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 880 fed_model val loss 1.2175 val acc 73.4298 best val_acc 74.075886 te_acc 74.220037\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 900 fed_model val loss 1.2295 val acc 73.8391 best val_acc 74.078460 te_acc 74.119646\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 920 fed_model val loss 1.2416 val acc 73.6563 best val_acc 74.078460 te_acc 74.119646\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 940 fed_model val loss 1.2581 val acc 73.7335 best val_acc 74.078460 te_acc 74.119646\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 960 fed_model val loss 1.2767 val acc 73.7052 best val_acc 74.078460 te_acc 74.119646\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 980 fed_model val loss 1.2945 val acc 73.6872 best val_acc 74.078460 te_acc 74.119646\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 1000 fed_model val loss 1.3126 val acc 73.6717 best val_acc 74.078460 te_acc 74.119646\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 1020 fed_model val loss 1.3298 val acc 73.6692 best val_acc 74.078460 te_acc 74.119646\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 1040 fed_model val loss 1.3488 val acc 73.5508 best val_acc 74.078460 te_acc 74.119646\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 1060 fed_model val loss 1.3667 val acc 73.2033 best val_acc 74.078460 te_acc 74.119646\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 1080 fed_model val loss 1.4544 val acc 72.6653 best val_acc 74.078460 te_acc 74.119646\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 1100 fed_model val loss 1.3657 val acc 73.4735 best val_acc 74.078460 te_acc 74.119646\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 1120 fed_model val loss 1.3699 val acc 73.6769 best val_acc 74.078460 te_acc 74.119646\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 1140 fed_model val loss 1.3865 val acc 73.7129 best val_acc 74.078460 te_acc 74.119646\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 1160 fed_model val loss 1.4044 val acc 73.7464 best val_acc 74.078460 te_acc 74.119646\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 1180 fed_model val loss 1.4229 val acc 73.7258 best val_acc 74.078460 te_acc 74.119646\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 1200 fed_model val loss 1.4407 val acc 73.6949 best val_acc 74.078460 te_acc 74.119646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 1220 fed_model val loss 1.4674 val acc 73.5379 best val_acc 74.078460 te_acc 74.119646\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 1240 fed_model val loss 1.4735 val acc 73.6666 best val_acc 74.078460 te_acc 74.119646\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 1260 fed_model val loss 1.4893 val acc 73.7104 best val_acc 74.078460 te_acc 74.119646\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 1280 fed_model val loss 1.5089 val acc 73.3860 best val_acc 74.078460 te_acc 74.119646\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 1300 fed_model val loss 1.5288 val acc 73.3242 best val_acc 74.078460 te_acc 74.119646\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 1320 fed_model val loss 1.5697 val acc 73.5508 best val_acc 74.078460 te_acc 74.119646\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 1340 fed_model val loss 1.5230 val acc 72.7425 best val_acc 74.078460 te_acc 74.119646\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 1360 fed_model val loss 1.5084 val acc 73.4298 best val_acc 74.078460 te_acc 74.119646\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 1380 fed_model val loss 1.5394 val acc 73.4426 best val_acc 74.078460 te_acc 74.119646\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 1400 fed_model val loss 1.5438 val acc 73.6563 best val_acc 74.078460 te_acc 74.119646\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 1420 fed_model val loss 1.5516 val acc 73.6280 best val_acc 74.078460 te_acc 74.119646\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 1440 fed_model val loss 1.5810 val acc 73.3500 best val_acc 74.078460 te_acc 74.119646\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 1460 fed_model val loss 1.5981 val acc 73.3371 best val_acc 74.078460 te_acc 74.119646\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 1480 fed_model val loss 1.6108 val acc 73.5121 best val_acc 74.078460 te_acc 74.119646\n",
      "mkrum: at fang at_frac 20.0 n_at 9 n_mal_sel 9 e 1500 fed_model val loss 1.6174 val acc 73.4993 best val_acc 74.078460 te_acc 74.119646\n"
     ]
    }
   ],
   "source": [
    "resume=0\n",
    "nepochs=1500\n",
    "gamma=.1\n",
    "fed_lr=0.001\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "batch_size = 100\n",
    "schedule = [2000]\n",
    "\n",
    "aggregation = 'mkrum'\n",
    "at_type = 'fang'\n",
    "chkpt = './' + aggregation\n",
    "epoch_num = 0\n",
    "\n",
    "at_fractions = [20]\n",
    "\n",
    "for at_fraction in at_fractions:\n",
    "\n",
    "    fed_model = mnist_conv().cuda()\n",
    "    fed_model.apply(weights_init)\n",
    "    optimizer_fed = Adam(fed_model.parameters(), lr=fed_lr)\n",
    "\n",
    "    print('==> Initializing global model')\n",
    "    epoch_num = 0\n",
    "    n_attacker = 0\n",
    "    best_global_acc=0\n",
    "    best_global_te_acc=0\n",
    "\n",
    "    while epoch_num <= nepochs:\n",
    "        user_grads = []\n",
    "\n",
    "        # The following condition is necessary for Krum/Multi-krum/Bulyan to work\n",
    "        while n_attacker < 4:\n",
    "            round_users = np.random.choice(3400, 60)\n",
    "            n_attacker = np.sum(round_users < (34*at_fraction))\n",
    "\n",
    "        if n_attacker > 14:\n",
    "            print ('n_attackers actual %d adjusted 14' % n_attacker)\n",
    "            n_attacker = 14\n",
    "\n",
    "        at_idx = []\n",
    "        attacker_count = 0\n",
    "        for i in round_users:\n",
    "            if i < (34*at_fraction) and attacker_count < n_attacker:\n",
    "                at_idx.append(i)\n",
    "                attacker_count += 1\n",
    "                continue\n",
    "\n",
    "            inputs = user_tr_data_tensors[i]\n",
    "            targets = user_tr_label_tensors[i]\n",
    "\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "            outputs = fed_model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            optimizer_fed.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "\n",
    "            param_grad=[]\n",
    "            for param in fed_model.parameters():\n",
    "                param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
    "\n",
    "            user_grads=param_grad[None,:] if len(user_grads)==0 else torch.cat((user_grads,param_grad[None,:]),0)    \n",
    "\n",
    "        if n_attacker > 0:\n",
    "            attacker_grads = []\n",
    "            n_attacker_ = max(1, n_attacker**2//60)\n",
    "            for i in at_idx:\n",
    "\n",
    "                inputs = user_tr_data_tensors[i]\n",
    "                targets = user_tr_label_tensors[i]\n",
    "\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "                inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "                outputs = fed_model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                optimizer_fed.zero_grad()\n",
    "                loss.backward(retain_graph=True)\n",
    "\n",
    "                param_grad=[]\n",
    "                for param in fed_model.parameters():\n",
    "                    param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
    "\n",
    "                attacker_grads=param_grad[None,:] if len(attacker_grads)==0 else torch.cat((attacker_grads,param_grad[None,:]),0)\n",
    "\n",
    "            mal_updates = []\n",
    "            if at_type == 'fang':\n",
    "                agg_grads = torch.mean(attacker_grads, 0)\n",
    "                deviation = torch.sign(agg_grads)\n",
    "                mal_update = get_malicious_updates_fang(attacker_grads, agg_grads, deviation, n_attacker_)\n",
    "\n",
    "            elif at_type == 'our-agr':\n",
    "                agg_grads = torch.mean(attacker_grads, 0)\n",
    "                mal_update = our_attack_mkrum(attacker_grads, agg_grads, n_attacker_, dev_type='sign')\n",
    "            \n",
    "        if not len(mal_updates):\n",
    "            mal_updates = torch.stack([mal_update] * n_attacker)\n",
    "        malicious_grads = torch.cat((mal_updates, user_grads), 0)    \n",
    "        \n",
    "        if malicious_grads.shape[0] != 60: \n",
    "            print('malicious grads shape ', malicious_grads.shape)\n",
    "            sys.exit()\n",
    "\n",
    "        multi_k = True if aggregation == 'mkrum' else False\n",
    "        if epoch_num == 0: print('multi krum is ', multi_k)\n",
    "        agg_grads, krum_candidate = multi_krum(malicious_grads, n_attacker, multi_k=multi_k)\n",
    "            \n",
    "        start_idx=0\n",
    "\n",
    "        if epoch_num in schedule:\n",
    "            for param_group in optimizer_fed.param_groups:\n",
    "                param_group['lr'] *= gamma\n",
    "                print('New learnin rate ', param_group['lr'])\n",
    "\n",
    "        optimizer_fed.zero_grad()\n",
    "\n",
    "        model_grads=[]\n",
    "\n",
    "        for i, param in enumerate(fed_model.parameters()):\n",
    "            param_=agg_grads[start_idx:start_idx+len(param.data.view(-1))].reshape(param.data.shape)\n",
    "            start_idx=start_idx+len(param.data.view(-1))\n",
    "            param_=param_.cuda()\n",
    "            model_grads.append(param_)\n",
    "\n",
    "        optimizer_fed.step(model_grads)\n",
    "\n",
    "        val_loss, val_acc = test(val_data_tensor,val_label_tensor,fed_model,criterion,use_cuda)\n",
    "        te_loss, te_acc = test(te_data_tensor,te_label_tensor, fed_model, criterion, use_cuda)\n",
    "\n",
    "        is_best = best_global_acc < val_acc\n",
    "\n",
    "        best_global_acc = max(best_global_acc, val_acc)\n",
    "\n",
    "        if is_best:\n",
    "            best_global_te_acc = te_acc\n",
    "\n",
    "        if epoch_num % 20 == 0:\n",
    "            print('%s: at %s at_frac %.1f n_at %d n_mal_sel %d e %d fed_model val loss %.4f val acc %.4f best val_acc %f te_acc %f'%(aggregation, at_type, at_fraction, n_attacker, np.sum(krum_candidate < n_attacker), epoch_num, val_loss, val_acc, best_global_acc,best_global_te_acc))\n",
    "\n",
    "        epoch_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our first AGR-agnostic attack - Min-Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def our_attack_dist(all_updates, model_re, n_attackers, dev_type='unit_vec'):\n",
    "\n",
    "    if dev_type == 'unit_vec':\n",
    "        deviation = model_re / torch.norm(model_re)  # unit vector, dir opp to good dir\n",
    "    elif dev_type == 'sign':\n",
    "        deviation = torch.sign(model_re)\n",
    "    elif dev_type == 'std':\n",
    "        deviation = torch.std(all_updates, 0)\n",
    "\n",
    "    lamda = torch.Tensor([50.0]).float().cuda()\n",
    "    # print(lamda)\n",
    "    threshold_diff = 1e-5\n",
    "    lamda_fail = lamda\n",
    "    lamda_succ = 0\n",
    "    \n",
    "    distances = []\n",
    "    for update in all_updates:\n",
    "        distance = torch.norm((all_updates - update), dim=1) ** 2\n",
    "        distances = distance[None, :] if not len(distances) else torch.cat((distances, distance[None, :]), 0)\n",
    "    \n",
    "    max_distance = torch.max(distances)\n",
    "    del distances\n",
    "\n",
    "    while torch.abs(lamda_succ - lamda) > threshold_diff:\n",
    "        mal_update = (model_re - lamda * deviation)\n",
    "        distance = torch.norm((all_updates - mal_update), dim=1) ** 2\n",
    "        max_d = torch.max(distance)\n",
    "        \n",
    "        if max_d <= max_distance:\n",
    "            # print('successful lamda is ', lamda)\n",
    "            lamda_succ = lamda\n",
    "            lamda = lamda + lamda_fail / 2\n",
    "        else:\n",
    "            lamda = lamda - lamda_fail / 2\n",
    "\n",
    "        lamda_fail = lamda_fail / 2\n",
    "\n",
    "    mal_update = (model_re - lamda_succ * deviation)\n",
    "    \n",
    "    return mal_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Initializing global model\n",
      "multi krum is  False\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 0 fed_model val loss 3.9115 val acc 4.5356 best val_acc 4.535626 te_acc 5.037582\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 20 fed_model val loss 3.9039 val acc 4.7055 best val_acc 9.596376 te_acc 10.474156\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 40 fed_model val loss 3.8798 val acc 17.7306 best val_acc 17.730643 te_acc 19.586594\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 60 fed_model val loss 3.6546 val acc 21.6124 best val_acc 21.612438 te_acc 24.423394\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 80 fed_model val loss 3.2039 val acc 29.0028 best val_acc 29.625721 te_acc 33.123970\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 100 fed_model val loss 2.8863 val acc 31.4044 best val_acc 31.507414 te_acc 35.227039\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 120 fed_model val loss 2.8507 val acc 33.5925 best val_acc 36.555292 te_acc 39.868204\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 140 fed_model val loss 2.7030 val acc 37.0083 best val_acc 39.090815 te_acc 42.267298\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 160 fed_model val loss 2.7057 val acc 39.6751 best val_acc 40.915877 te_acc 43.901874\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 180 fed_model val loss 2.9009 val acc 39.5155 best val_acc 40.915877 te_acc 43.901874\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 200 fed_model val loss 3.0429 val acc 40.8052 best val_acc 40.915877 te_acc 43.901874\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 220 fed_model val loss 2.8606 val acc 39.2581 best val_acc 42.339374 te_acc 44.746190\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 240 fed_model val loss 2.9880 val acc 41.1630 best val_acc 43.567236 te_acc 46.069296\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 260 fed_model val loss 2.8409 val acc 43.1322 best val_acc 44.566001 te_acc 46.944502\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 280 fed_model val loss 2.7072 val acc 43.0112 best val_acc 45.868513 te_acc 47.598332\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 300 fed_model val loss 2.7927 val acc 44.1104 best val_acc 46.846685 te_acc 49.083608\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 320 fed_model val loss 2.6949 val acc 45.2147 best val_acc 46.846685 te_acc 49.083608\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 340 fed_model val loss 2.7229 val acc 45.2662 best val_acc 46.957372 te_acc 49.238056\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 360 fed_model val loss 2.6962 val acc 45.5673 best val_acc 47.183896 te_acc 49.330725\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 380 fed_model val loss 2.7018 val acc 46.7180 best val_acc 47.183896 te_acc 49.330725\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 400 fed_model val loss 2.7768 val acc 47.4568 best val_acc 47.456755 te_acc 49.925350\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 420 fed_model val loss 2.8150 val acc 46.7411 best val_acc 47.456755 te_acc 49.925350\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 440 fed_model val loss 2.8910 val acc 46.5223 best val_acc 47.456755 te_acc 49.925350\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 460 fed_model val loss 2.9557 val acc 44.9084 best val_acc 47.456755 te_acc 49.925350\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 480 fed_model val loss 3.0273 val acc 46.9188 best val_acc 48.465815 te_acc 50.643534\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 500 fed_model val loss 3.1137 val acc 46.8801 best val_acc 48.465815 te_acc 50.643534\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 520 fed_model val loss 3.1317 val acc 48.1904 best val_acc 48.465815 te_acc 50.643534\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 540 fed_model val loss 3.1808 val acc 48.2522 best val_acc 48.465815 te_acc 50.643534\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 560 fed_model val loss 3.1420 val acc 47.2174 best val_acc 48.465815 te_acc 50.643534\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 580 fed_model val loss 3.0755 val acc 46.5790 best val_acc 48.465815 te_acc 50.643534\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 600 fed_model val loss 3.1804 val acc 46.8004 best val_acc 48.558484 te_acc 50.779963\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 620 fed_model val loss 3.3053 val acc 45.8376 best val_acc 49.333299 te_acc 51.575371\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 640 fed_model val loss 3.3166 val acc 47.5237 best val_acc 49.333299 te_acc 51.575371\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 660 fed_model val loss 3.3490 val acc 47.9252 best val_acc 49.333299 te_acc 51.575371\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 680 fed_model val loss 3.3569 val acc 47.3435 best val_acc 49.333299 te_acc 51.575371\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 700 fed_model val loss 3.4433 val acc 47.6936 best val_acc 49.333299 te_acc 51.575371\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 720 fed_model val loss 3.5330 val acc 46.7592 best val_acc 49.333299 te_acc 51.575371\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 740 fed_model val loss 3.2604 val acc 49.3127 best val_acc 49.333299 te_acc 51.575371\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 760 fed_model val loss 3.3010 val acc 47.0784 best val_acc 49.333299 te_acc 51.575371\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 780 fed_model val loss 3.3508 val acc 48.6872 best val_acc 49.415671 te_acc 51.606260\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 800 fed_model val loss 2.3988 val acc 49.8301 best val_acc 50.427306 te_acc 52.659082\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 820 fed_model val loss 2.6436 val acc 50.1725 best val_acc 50.427306 te_acc 52.659082\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 840 fed_model val loss 2.8799 val acc 49.9202 best val_acc 50.931837 te_acc 53.621808\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 860 fed_model val loss 2.9774 val acc 49.6731 best val_acc 50.931837 te_acc 53.621808\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 880 fed_model val loss 3.0163 val acc 50.3501 best val_acc 50.931837 te_acc 53.621808\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 900 fed_model val loss 2.7623 val acc 47.6704 best val_acc 50.931837 te_acc 53.621808\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 920 fed_model val loss 2.6313 val acc 48.5250 best val_acc 52.399094 te_acc 54.790465\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 940 fed_model val loss 2.6068 val acc 50.3218 best val_acc 52.399094 te_acc 54.790465\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 960 fed_model val loss 2.8819 val acc 51.3797 best val_acc 52.399094 te_acc 54.790465\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 980 fed_model val loss 2.8563 val acc 52.6102 best val_acc 52.738880 te_acc 55.264106\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 1000 fed_model val loss 3.0471 val acc 51.7118 best val_acc 52.738880 te_acc 55.264106\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 1020 fed_model val loss 2.8324 val acc 50.8804 best val_acc 53.312912 te_acc 55.825268\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 1040 fed_model val loss 2.8983 val acc 52.6771 best val_acc 53.312912 te_acc 55.825268\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 1060 fed_model val loss 3.0111 val acc 51.5110 best val_acc 53.312912 te_acc 55.825268\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 1080 fed_model val loss 3.0471 val acc 51.3978 best val_acc 53.312912 te_acc 55.825268\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 1100 fed_model val loss 2.9828 val acc 51.5239 best val_acc 53.312912 te_acc 55.825268\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 1120 fed_model val loss 2.7342 val acc 52.3785 best val_acc 53.312912 te_acc 55.825268\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 1140 fed_model val loss 2.6771 val acc 52.7543 best val_acc 53.325783 te_acc 55.624485\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 1160 fed_model val loss 2.9890 val acc 51.9975 best val_acc 53.325783 te_acc 55.624485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 1180 fed_model val loss 2.9625 val acc 51.9332 best val_acc 53.325783 te_acc 55.624485\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 1200 fed_model val loss 2.9529 val acc 52.2833 best val_acc 53.325783 te_acc 55.624485\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 1220 fed_model val loss 3.0344 val acc 51.9100 best val_acc 53.325783 te_acc 55.624485\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 1240 fed_model val loss 3.0001 val acc 52.3296 best val_acc 53.325783 te_acc 55.624485\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 1260 fed_model val loss 3.1551 val acc 51.7710 best val_acc 53.325783 te_acc 55.624485\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 1280 fed_model val loss 3.2689 val acc 52.4815 best val_acc 53.325783 te_acc 55.624485\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 1300 fed_model val loss 3.1851 val acc 52.8779 best val_acc 53.325783 te_acc 55.624485\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 1320 fed_model val loss 3.2396 val acc 52.0696 best val_acc 53.325783 te_acc 55.624485\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 1340 fed_model val loss 3.3750 val acc 52.2446 best val_acc 53.325783 te_acc 55.624485\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 1360 fed_model val loss 3.3200 val acc 51.7144 best val_acc 53.325783 te_acc 55.624485\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 1380 fed_model val loss 3.3504 val acc 51.9538 best val_acc 53.325783 te_acc 55.624485\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 1400 fed_model val loss 3.4374 val acc 51.6964 best val_acc 53.325783 te_acc 55.624485\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 1420 fed_model val loss 3.3372 val acc 53.1456 best val_acc 54.213859 te_acc 56.311779\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 1440 fed_model val loss 3.3946 val acc 51.4776 best val_acc 54.213859 te_acc 56.311779\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 1460 fed_model val loss 3.4559 val acc 52.2910 best val_acc 54.213859 te_acc 56.311779\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 1480 fed_model val loss 3.5163 val acc 52.0748 best val_acc 54.213859 te_acc 56.311779\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 0 e 1500 fed_model val loss 3.5826 val acc 51.7298 best val_acc 54.213859 te_acc 56.311779\n"
     ]
    }
   ],
   "source": [
    "resume=0\n",
    "nepochs=1500\n",
    "gamma=.1\n",
    "fed_lr=0.001\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "batch_size = 100\n",
    "schedule = [2000]\n",
    "\n",
    "aggregation = 'bulyan'\n",
    "at_type = 'min-max'\n",
    "chkpt = './' + aggregation\n",
    "epoch_num = 0\n",
    "\n",
    "at_fractions = [20]\n",
    "\n",
    "for at_fraction in at_fractions:\n",
    "\n",
    "    fed_model = mnist_conv().cuda()\n",
    "    fed_model.apply(weights_init)\n",
    "    optimizer_fed = Adam(fed_model.parameters(), lr=fed_lr)\n",
    "\n",
    "    print('==> Initializing global model')\n",
    "    epoch_num = 0\n",
    "    n_attacker = 0\n",
    "    best_global_acc=0\n",
    "    best_global_te_acc=0\n",
    "\n",
    "    while epoch_num <= nepochs:\n",
    "        user_grads = []\n",
    "\n",
    "        # The following condition is necessary for Krum/Multi-krum/Bulyan to work\n",
    "        while n_attacker < 4:\n",
    "            round_users = np.random.choice(3400, 60)\n",
    "            n_attacker = np.sum(round_users < (34*at_fraction))\n",
    "\n",
    "        if n_attacker > 14:\n",
    "            print ('n_attackers actual %d adjusted 14' % n_attacker)\n",
    "            n_attacker = 14\n",
    "\n",
    "        at_idx = []\n",
    "        attacker_count = 0\n",
    "        for i in round_users:\n",
    "            if i < (34*at_fraction) and attacker_count < n_attacker:\n",
    "                at_idx.append(i)\n",
    "                attacker_count += 1\n",
    "                continue\n",
    "\n",
    "            inputs = user_tr_data_tensors[i]\n",
    "            targets = user_tr_label_tensors[i]\n",
    "\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "            outputs = fed_model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            optimizer_fed.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "\n",
    "            param_grad=[]\n",
    "            for param in fed_model.parameters():\n",
    "                param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
    "\n",
    "            user_grads=param_grad[None,:] if len(user_grads)==0 else torch.cat((user_grads,param_grad[None,:]),0)    \n",
    "\n",
    "        if n_attacker > 0:\n",
    "            attacker_grads = []\n",
    "            n_attacker_ = max(1, n_attacker**2//60)\n",
    "            for i in at_idx:\n",
    "\n",
    "                inputs = user_tr_data_tensors[i]\n",
    "                targets = user_tr_label_tensors[i]\n",
    "\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "                inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "                outputs = fed_model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                optimizer_fed.zero_grad()\n",
    "                loss.backward(retain_graph=True)\n",
    "\n",
    "                param_grad=[]\n",
    "                for param in fed_model.parameters():\n",
    "                    param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
    "\n",
    "                attacker_grads=param_grad[None,:] if len(attacker_grads)==0 else torch.cat((attacker_grads,param_grad[None,:]),0)\n",
    "\n",
    "            mal_updates = []\n",
    "            if at_type == 'fang':\n",
    "                agg_grads = torch.mean(attacker_grads, 0)\n",
    "                deviation = torch.sign(agg_grads)\n",
    "                mal_update = get_malicious_updates_fang(attacker_grads, agg_grads, deviation, n_attacker_)\n",
    "            elif at_type == 'our-agr':\n",
    "                agg_grads = torch.mean(attacker_grads, 0)\n",
    "                mal_update = our_attack_mkrum(attacker_grads, agg_grads, n_attacker_, dev_type='sign')\n",
    "            elif at_type == 'min-max':\n",
    "                agg_grads = torch.mean(malicious_grads, 0)\n",
    "                mal_update = our_attack_dist(attacker_grads, agg_grads, n_attacker_, dev_type='sign')\n",
    "            elif at_type == 'min-sum':\n",
    "                agg_grads = torch.mean(malicious_grads, 0)\n",
    "                mal_update = our_attack_score(attacker_grads, agg_grads, n_attacker_, dev_type='sign')\n",
    "\n",
    "        if not len(mal_updates):\n",
    "            mal_updates = torch.stack([mal_update] * n_attacker)\n",
    "        malicious_grads = torch.cat((mal_updates, user_grads), 0)    \n",
    "        \n",
    "        if malicious_grads.shape[0] != 60: \n",
    "            print('malicious grads shape ', malicious_grads.shape)\n",
    "            sys.exit()\n",
    "\n",
    "        multi_k = True if aggregation == 'mkrum' else False\n",
    "        if epoch_num == 0: print('multi krum is ', multi_k)\n",
    "        agg_grads, krum_candidate = multi_krum(malicious_grads, n_attacker, multi_k=multi_k)\n",
    "\n",
    "        start_idx=0\n",
    "\n",
    "        if epoch_num in schedule:\n",
    "            for param_group in optimizer_fed.param_groups:\n",
    "                param_group['lr'] *= gamma\n",
    "                print('New learnin rate ', param_group['lr'])\n",
    "\n",
    "        optimizer_fed.zero_grad()\n",
    "\n",
    "        model_grads=[]\n",
    "\n",
    "        for i, param in enumerate(fed_model.parameters()):\n",
    "            param_=agg_grads[start_idx:start_idx+len(param.data.view(-1))].reshape(param.data.shape)\n",
    "            start_idx=start_idx+len(param.data.view(-1))\n",
    "            param_=param_.cuda()\n",
    "            model_grads.append(param_)\n",
    "\n",
    "        optimizer_fed.step(model_grads)\n",
    "\n",
    "        val_loss, val_acc = test(val_data_tensor,val_label_tensor,fed_model,criterion,use_cuda)\n",
    "        te_loss, te_acc = test(te_data_tensor,te_label_tensor, fed_model, criterion, use_cuda)\n",
    "\n",
    "        is_best = best_global_acc < val_acc\n",
    "\n",
    "        best_global_acc = max(best_global_acc, val_acc)\n",
    "\n",
    "        if is_best:\n",
    "            best_global_te_acc = te_acc\n",
    "\n",
    "        if epoch_num % 20 == 0:\n",
    "            print('%s: at %s at_frac %.1f n_at %d n_mal_sel %d e %d fed_model val loss %.4f val acc %.4f best val_acc %f te_acc %f'%(aggregation, at_type, at_fraction, n_attacker, np.sum(krum_candidate < n_attacker), epoch_num, val_loss, val_acc, best_global_acc,best_global_te_acc))\n",
    "\n",
    "        epoch_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our second AGR-agnostic attack - Min-Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def our_attack_score(all_updates, model_re, n_attackers, dev_type='unit_vec'):\n",
    "\n",
    "    if dev_type == 'unit_vec':\n",
    "        deviation = model_re / torch.norm(model_re)  # unit vector, dir opp to good dir\n",
    "    elif dev_type == 'sign':\n",
    "        deviation = torch.sign(model_re)\n",
    "    elif dev_type == 'std':\n",
    "        deviation = torch.std(all_updates, 0)\n",
    "    \n",
    "    lamda = torch.Tensor([50.0]).float().cuda()\n",
    "    # print(lamda)\n",
    "    threshold_diff = 1e-5\n",
    "    lamda_fail = lamda\n",
    "    lamda_succ = 0\n",
    "    \n",
    "    distances = []\n",
    "    for update in all_updates:\n",
    "        distance = torch.norm((all_updates - update), dim=1) ** 2\n",
    "        distances = distance[None, :] if not len(distances) else torch.cat((distances, distance[None, :]), 0)\n",
    "    \n",
    "    scores = torch.sum(distances, dim=1)\n",
    "    min_score = torch.min(scores)\n",
    "    del distances\n",
    "\n",
    "    while torch.abs(lamda_succ - lamda) > threshold_diff:\n",
    "        mal_update = (model_re - lamda * deviation)\n",
    "        distance = torch.norm((all_updates - mal_update), dim=1) ** 2\n",
    "        score = torch.sum(distance)\n",
    "        \n",
    "        if score <= min_score:\n",
    "            # print('successful lamda is ', lamda)\n",
    "            lamda_succ = lamda\n",
    "            lamda = lamda + lamda_fail / 2\n",
    "        else:\n",
    "            lamda = lamda - lamda_fail / 2\n",
    "\n",
    "        lamda_fail = lamda_fail / 2\n",
    "\n",
    "    mal_update = (model_re - lamda_succ * deviation)\n",
    "    return mal_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Initializing global model\n",
      "multi krum is  False\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 0 e 0 fed_model val loss 3.9216 val acc 4.4636 best val_acc 4.463550 te_acc 4.847096\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 0 e 20 fed_model val loss 3.8622 val acc 4.9964 best val_acc 9.382722 te_acc 10.296540\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 0 e 40 fed_model val loss 3.8286 val acc 15.7280 best val_acc 15.727965 te_acc 17.262150\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 0 e 60 fed_model val loss 3.6181 val acc 24.7889 best val_acc 24.788921 te_acc 27.862438\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 0 e 80 fed_model val loss 3.2380 val acc 23.3809 best val_acc 28.482805 te_acc 32.215301\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 0 e 100 fed_model val loss 2.9159 val acc 32.2925 best val_acc 33.417422 te_acc 37.404757\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 0 e 120 fed_model val loss 2.8121 val acc 33.6131 best val_acc 35.507619 te_acc 38.835976\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 140 fed_model val loss 2.5709 val acc 35.6157 best val_acc 36.107393 te_acc 40.099876\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 160 fed_model val loss 2.3102 val acc 41.3561 best val_acc 41.356054 te_acc 44.766783\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 0 e 180 fed_model val loss 2.0756 val acc 44.9882 best val_acc 45.356260 te_acc 48.818472\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 200 fed_model val loss 1.9215 val acc 48.9472 best val_acc 48.947179 te_acc 51.482702\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 0 e 220 fed_model val loss 1.8450 val acc 50.3604 best val_acc 51.415774 te_acc 53.915259\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 0 e 240 fed_model val loss 1.8661 val acc 50.6641 best val_acc 53.109555 te_acc 55.511223\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 0 e 260 fed_model val loss 1.7498 val acc 53.6707 best val_acc 54.612850 te_acc 56.849773\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 0 e 280 fed_model val loss 1.6567 val acc 55.5807 best val_acc 55.611614 te_acc 57.825371\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 0 e 300 fed_model val loss 1.6008 val acc 56.2371 best val_acc 57.802203 te_acc 60.270799\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 0 e 320 fed_model val loss 1.5483 val acc 57.4753 best val_acc 58.875618 te_acc 60.911759\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 340 fed_model val loss 1.4715 val acc 58.8808 best val_acc 60.281096 te_acc 62.155066\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 360 fed_model val loss 1.4927 val acc 58.2089 best val_acc 60.453563 te_acc 62.103583\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 0 e 380 fed_model val loss 1.3697 val acc 60.8809 best val_acc 61.012150 te_acc 62.932455\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 400 fed_model val loss 1.3356 val acc 61.5373 best val_acc 61.537273 te_acc 63.591433\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 0 e 420 fed_model val loss 1.3355 val acc 62.2374 best val_acc 62.237438 te_acc 64.206652\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 440 fed_model val loss 1.2981 val acc 62.1190 best val_acc 63.210461 te_acc 64.438324\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 460 fed_model val loss 1.3682 val acc 61.1898 best val_acc 64.152595 te_acc 65.771726\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 480 fed_model val loss 1.2136 val acc 65.1359 best val_acc 65.135914 te_acc 66.363777\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 500 fed_model val loss 1.1788 val acc 65.6456 best val_acc 66.178439 te_acc 67.105128\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 0 e 520 fed_model val loss 1.1997 val acc 65.1951 best val_acc 66.178439 te_acc 67.105128\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 540 fed_model val loss 1.1492 val acc 66.0420 best val_acc 66.700988 te_acc 68.196561\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 560 fed_model val loss 1.0865 val acc 67.7693 best val_acc 67.769255 te_acc 68.477142\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 580 fed_model val loss 1.1453 val acc 65.7589 best val_acc 68.124485 te_acc 69.308587\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 600 fed_model val loss 1.1365 val acc 65.9082 best val_acc 69.959843 te_acc 70.533876\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 620 fed_model val loss 1.0981 val acc 67.1489 best val_acc 69.959843 te_acc 70.533876\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 640 fed_model val loss 1.0853 val acc 67.8902 best val_acc 69.959843 te_acc 70.533876\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 660 fed_model val loss 1.1160 val acc 67.3600 best val_acc 69.959843 te_acc 70.533876\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 0 e 680 fed_model val loss 1.0286 val acc 69.4991 best val_acc 69.959843 te_acc 70.533876\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 0 e 700 fed_model val loss 1.0122 val acc 69.7925 best val_acc 70.235276 te_acc 71.285523\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 720 fed_model val loss 1.0023 val acc 69.8157 best val_acc 70.235276 te_acc 71.285523\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 740 fed_model val loss 0.9982 val acc 69.8492 best val_acc 71.069296 te_acc 71.908464\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 760 fed_model val loss 1.1371 val acc 66.2376 best val_acc 71.069296 te_acc 71.908464\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 0 e 780 fed_model val loss 0.9998 val acc 70.1117 best val_acc 71.069296 te_acc 71.908464\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 800 fed_model val loss 1.0398 val acc 68.3510 best val_acc 71.069296 te_acc 71.908464\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 820 fed_model val loss 0.9600 val acc 71.5095 best val_acc 71.509473 te_acc 71.717978\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 0 e 840 fed_model val loss 0.9878 val acc 70.1941 best val_acc 72.459329 te_acc 72.739909\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 860 fed_model val loss 0.9761 val acc 70.8659 best val_acc 72.459329 te_acc 72.739909\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 880 fed_model val loss 0.9805 val acc 70.8093 best val_acc 72.459329 te_acc 72.739909\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 0 e 900 fed_model val loss 0.9858 val acc 71.4039 best val_acc 72.459329 te_acc 72.739909\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 920 fed_model val loss 0.9511 val acc 72.2534 best val_acc 72.459329 te_acc 72.739909\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 940 fed_model val loss 1.0011 val acc 71.0693 best val_acc 72.459329 te_acc 72.739909\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 960 fed_model val loss 0.9937 val acc 70.8968 best val_acc 72.459329 te_acc 72.739909\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 980 fed_model val loss 0.9552 val acc 71.9342 best val_acc 73.046231 te_acc 73.607393\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 1000 fed_model val loss 0.9777 val acc 70.7784 best val_acc 73.746396 te_acc 74.145387\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 1020 fed_model val loss 0.9536 val acc 71.4194 best val_acc 73.746396 te_acc 74.145387\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 1040 fed_model val loss 0.9193 val acc 72.1556 best val_acc 73.746396 te_acc 74.145387\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 0 e 1060 fed_model val loss 0.9088 val acc 73.4272 best val_acc 73.746396 te_acc 74.145387\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 1080 fed_model val loss 0.9477 val acc 71.6124 best val_acc 73.746396 te_acc 74.145387\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 1100 fed_model val loss 0.9445 val acc 71.6408 best val_acc 73.916289 te_acc 74.572694\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 1120 fed_model val loss 0.8954 val acc 73.1878 best val_acc 74.101627 te_acc 74.637047\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 1140 fed_model val loss 0.9052 val acc 73.4555 best val_acc 74.778624 te_acc 75.241969\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 0 e 1160 fed_model val loss 0.9101 val acc 72.7476 best val_acc 74.778624 te_acc 75.241969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 1180 fed_model val loss 0.8779 val acc 73.1930 best val_acc 74.778624 te_acc 75.241969\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 1200 fed_model val loss 0.9424 val acc 72.3873 best val_acc 74.778624 te_acc 75.241969\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 1220 fed_model val loss 0.9748 val acc 71.6922 best val_acc 74.778624 te_acc 75.241969\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 0 e 1240 fed_model val loss 0.9316 val acc 72.7734 best val_acc 74.778624 te_acc 75.241969\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 1260 fed_model val loss 0.9073 val acc 73.9395 best val_acc 74.778624 te_acc 75.241969\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 1280 fed_model val loss 0.9382 val acc 73.3294 best val_acc 74.778624 te_acc 75.241969\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 1300 fed_model val loss 0.9130 val acc 73.3757 best val_acc 74.778624 te_acc 75.241969\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 1320 fed_model val loss 0.9043 val acc 74.1119 best val_acc 74.778624 te_acc 75.241969\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 1340 fed_model val loss 0.9111 val acc 73.0282 best val_acc 74.778624 te_acc 75.241969\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 1360 fed_model val loss 0.9179 val acc 73.6846 best val_acc 74.778624 te_acc 75.241969\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 1380 fed_model val loss 0.9492 val acc 71.4117 best val_acc 74.778624 te_acc 75.241969\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 1400 fed_model val loss 0.9439 val acc 72.6498 best val_acc 74.778624 te_acc 75.241969\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 1420 fed_model val loss 0.9594 val acc 72.9098 best val_acc 74.778624 te_acc 75.241969\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 1440 fed_model val loss 0.9541 val acc 73.6640 best val_acc 74.778624 te_acc 75.241969\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 1460 fed_model val loss 0.9969 val acc 73.0411 best val_acc 74.778624 te_acc 75.241969\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 1480 fed_model val loss 0.9684 val acc 73.3114 best val_acc 74.778624 te_acc 75.241969\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 1 e 1500 fed_model val loss 0.9805 val acc 72.4825 best val_acc 74.778624 te_acc 75.241969\n"
     ]
    }
   ],
   "source": [
    "resume=0\n",
    "nepochs=1500\n",
    "gamma=.1\n",
    "fed_lr=0.001\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "batch_size = 100\n",
    "schedule = [2000]\n",
    "\n",
    "aggregation = 'bulyan'\n",
    "at_type = 'min-sum'\n",
    "chkpt = './' + aggregation\n",
    "epoch_num = 0\n",
    "\n",
    "at_fractions = [20]\n",
    "\n",
    "for at_fraction in at_fractions:\n",
    "\n",
    "    fed_model = mnist_conv().cuda()\n",
    "    fed_model.apply(weights_init)\n",
    "    optimizer_fed = Adam(fed_model.parameters(), lr=fed_lr)\n",
    "\n",
    "    print('==> Initializing global model')\n",
    "    epoch_num = 0\n",
    "    n_attacker = 0\n",
    "    best_global_acc=0\n",
    "    best_global_te_acc=0\n",
    "\n",
    "    while epoch_num <= nepochs:\n",
    "        user_grads = []\n",
    "\n",
    "        # The following condition is necessary for Krum/Multi-krum/Bulyan to work\n",
    "        while n_attacker < 4:\n",
    "            round_users = np.random.choice(3400, 60)\n",
    "            n_attacker = np.sum(round_users < (34*at_fraction))\n",
    "\n",
    "        if n_attacker > 14:\n",
    "            print ('n_attackers actual %d adjusted 14' % n_attacker)\n",
    "            n_attacker = 14\n",
    "\n",
    "        at_idx = []\n",
    "        attacker_count = 0\n",
    "        for i in round_users:\n",
    "            if i < (34*at_fraction) and attacker_count < n_attacker:\n",
    "                at_idx.append(i)\n",
    "                attacker_count += 1\n",
    "                continue\n",
    "\n",
    "            inputs = user_tr_data_tensors[i]\n",
    "            targets = user_tr_label_tensors[i]\n",
    "\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "            outputs = fed_model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            optimizer_fed.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "\n",
    "            param_grad=[]\n",
    "            for param in fed_model.parameters():\n",
    "                param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
    "\n",
    "            user_grads=param_grad[None,:] if len(user_grads)==0 else torch.cat((user_grads,param_grad[None,:]),0)    \n",
    "\n",
    "        if n_attacker > 0:\n",
    "            attacker_grads = []\n",
    "            n_attacker_ = max(1, n_attacker**2//60)\n",
    "            for i in at_idx:\n",
    "\n",
    "                inputs = user_tr_data_tensors[i]\n",
    "                targets = user_tr_label_tensors[i]\n",
    "\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "                inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "                outputs = fed_model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                optimizer_fed.zero_grad()\n",
    "                loss.backward(retain_graph=True)\n",
    "\n",
    "                param_grad=[]\n",
    "                for param in fed_model.parameters():\n",
    "                    param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
    "\n",
    "                attacker_grads=param_grad[None,:] if len(attacker_grads)==0 else torch.cat((attacker_grads,param_grad[None,:]),0)\n",
    "\n",
    "            mal_updates = []\n",
    "            if at_type == 'fang':\n",
    "                agg_grads = torch.mean(attacker_grads, 0)\n",
    "                deviation = torch.sign(agg_grads)\n",
    "                mal_update = get_malicious_updates_fang(attacker_grads, agg_grads, deviation, n_attacker_)\n",
    "            elif at_type == 'our-agr':\n",
    "                agg_grads = torch.mean(attacker_grads, 0)\n",
    "                mal_update = our_attack_mkrum(attacker_grads, agg_grads, n_attacker_, dev_type='sign')\n",
    "            elif at_type == 'min-max':\n",
    "                agg_grads = torch.mean(malicious_grads, 0)\n",
    "                mal_update = our_attack_dist(attacker_grads, agg_grads, n_attacker_, dev_type='sign')\n",
    "            elif at_type == 'min-sum':\n",
    "                agg_grads = torch.mean(malicious_grads, 0)\n",
    "                mal_update = our_attack_score(attacker_grads, agg_grads, n_attacker_, dev_type='sign')\n",
    "\n",
    "        if not len(mal_updates):\n",
    "            mal_updates = torch.stack([mal_update] * n_attacker)\n",
    "        malicious_grads = torch.cat((mal_updates, user_grads), 0)    \n",
    "        \n",
    "        if malicious_grads.shape[0] != 60: \n",
    "            print('malicious grads shape ', malicious_grads.shape)\n",
    "            sys.exit()\n",
    "\n",
    "        multi_k = True if aggregation == 'mkrum' else False\n",
    "        if epoch_num == 0: print('multi krum is ', multi_k)\n",
    "        agg_grads, krum_candidate = multi_krum(malicious_grads, n_attacker, multi_k=multi_k)\n",
    "\n",
    "        start_idx=0\n",
    "\n",
    "        if epoch_num in schedule:\n",
    "            for param_group in optimizer_fed.param_groups:\n",
    "                param_group['lr'] *= gamma\n",
    "                print('New learnin rate ', param_group['lr'])\n",
    "\n",
    "        optimizer_fed.zero_grad()\n",
    "\n",
    "        model_grads=[]\n",
    "\n",
    "        for i, param in enumerate(fed_model.parameters()):\n",
    "            param_=agg_grads[start_idx:start_idx+len(param.data.view(-1))].reshape(param.data.shape)\n",
    "            start_idx=start_idx+len(param.data.view(-1))\n",
    "            param_=param_.cuda()\n",
    "            model_grads.append(param_)\n",
    "\n",
    "        optimizer_fed.step(model_grads)\n",
    "\n",
    "        val_loss, val_acc = test(val_data_tensor,val_label_tensor,fed_model,criterion,use_cuda)\n",
    "        te_loss, te_acc = test(te_data_tensor,te_label_tensor, fed_model, criterion, use_cuda)\n",
    "\n",
    "        is_best = best_global_acc < val_acc\n",
    "\n",
    "        best_global_acc = max(best_global_acc, val_acc)\n",
    "\n",
    "        if is_best:\n",
    "            best_global_te_acc = te_acc\n",
    "\n",
    "        if epoch_num % 20 == 0:\n",
    "            print('%s: at %s at_frac %.1f n_at %d n_mal_sel %d e %d fed_model val loss %.4f val acc %.4f best val_acc %f te_acc %f'%(aggregation, at_type, at_fraction, n_attacker, np.sum(krum_candidate < n_attacker), epoch_num, val_loss, val_acc, best_global_acc,best_global_te_acc))\n",
    "\n",
    "        epoch_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
