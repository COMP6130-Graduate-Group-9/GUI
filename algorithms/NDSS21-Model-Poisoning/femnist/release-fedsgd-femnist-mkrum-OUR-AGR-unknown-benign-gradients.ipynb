{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The notebook contains\n",
    "### Code for _Bulyan_ aggregation algorithm, *when gradient updates of benign clients are unknown to adversary*\n",
    "### Evaluation of our SOTA AGR-tailored attack on Bulyan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse, os, sys, csv, shutil, time, random, operator, pickle, ast, math, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.optim import Optimizer\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "sys.path.insert(0,'./../utils/')\n",
    "from logger import *\n",
    "from eval import *\n",
    "from misc import *\n",
    "\n",
    "from femnist_normal_train import *\n",
    "from femnist_util import *\n",
    "from adam import Adam\n",
    "from sgd import SGD\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the FEMNIST dataset; we use [LEAF framework](https://leaf.cmu.edu/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_tr_data = []\n",
    "user_tr_labels = []\n",
    "\n",
    "for i in range(34):\n",
    "    f = '/mnt/nfs/work1/amir/vshejwalkar/leaf/data/femnist/data/train/all_data_%d_niid_0_keep_0_train_9.json'%i\n",
    "    with open(f, 'r') as myfile:\n",
    "        data=myfile.read()\n",
    "    obj = json.loads(data)\n",
    "    \n",
    "    for user in obj['users']:\n",
    "        user_tr_data.append(obj['user_data'][user]['x'])\n",
    "        user_tr_labels.append(obj['user_data'][user]['y'])\n",
    "\n",
    "user_te_data = []\n",
    "user_te_labels = []\n",
    "\n",
    "for i in range(34):\n",
    "    f = '/mnt/nfs/work1/amir/vshejwalkar/leaf/data/femnist/data/test/all_data_%d_niid_0_keep_0_test_9.json'%i\n",
    "    with open(f, 'r') as myfile:\n",
    "        data=myfile.read()\n",
    "    obj = json.loads(data)\n",
    "    \n",
    "    for user in obj['users']:\n",
    "        user_te_data.append(obj['user_data'][user]['x'])\n",
    "        user_te_labels.append(obj['user_data'][user]['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of clients:  3400\n"
     ]
    }
   ],
   "source": [
    "user_tr_data_tensors=[]\n",
    "user_tr_label_tensors=[]\n",
    "\n",
    "for i in range(len(user_tr_data)):\n",
    "    \n",
    "    user_tr_data_tensor=torch.from_numpy(np.array(user_tr_data[i])).type(torch.FloatTensor)\n",
    "    user_tr_label_tensor=torch.from_numpy(np.array(user_tr_labels[i])).type(torch.LongTensor)\n",
    "\n",
    "    user_tr_data_tensors.append(user_tr_data_tensor)\n",
    "    user_tr_label_tensors.append(user_tr_label_tensor)\n",
    "    \n",
    "    # print('user %d tr len %d'%(i,len(user_tr_data_tensor)))\n",
    "print(\"number of clients: \", len(user_tr_data_tensors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_data = np.concatenate(user_te_data, 0)\n",
    "te_labels = np.concatenate(user_te_labels)\n",
    "te_len = len(te_labels)\n",
    "\n",
    "te_data_tensor = torch.from_numpy(te_data[:(te_len//2)]).type(torch.FloatTensor)\n",
    "te_label_tensor = torch.from_numpy(te_labels[:(te_len//2)]).type(torch.LongTensor)\n",
    "\n",
    "val_data_tensor = torch.from_numpy(te_data[(te_len//2):]).type(torch.FloatTensor)\n",
    "val_label_tensor = torch.from_numpy(te_labels[(te_len//2):]).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for Multi-krum aggregation algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_krum(all_updates, n_attackers, multi_k=False):\n",
    "    nusers = all_updates.shape[0]\n",
    "    candidates = []\n",
    "    candidate_indices = []\n",
    "    remaining_updates = all_updates\n",
    "    all_indices = np.arange(len(all_updates))\n",
    "\n",
    "    while len(remaining_updates) > 2 * n_attackers + 2:\n",
    "        distances = []\n",
    "        for update in remaining_updates:\n",
    "            distance = torch.norm((remaining_updates - update), dim=1) ** 2\n",
    "            distances = distance[None, :] if not len(distances) else torch.cat((distances, distance[None, :]), 0)\n",
    "\n",
    "        distances = torch.sort(distances, dim=1)[0]\n",
    "        scores = torch.sum(distances[:, :len(remaining_updates) - 2 - n_attackers], dim=1)\n",
    "        indices = torch.argsort(scores)[:len(remaining_updates) - 2 - n_attackers]\n",
    "\n",
    "        candidate_indices.append(all_indices[indices[0].cpu().numpy()])\n",
    "        all_indices = np.delete(all_indices, indices[0].cpu().numpy())\n",
    "        candidates = remaining_updates[indices[0]][None, :] if not len(candidates) else torch.cat((candidates, remaining_updates[indices[0]][None, :]), 0)\n",
    "        remaining_updates = torch.cat((remaining_updates[:indices[0]], remaining_updates[indices[0] + 1:]), 0)\n",
    "        if not multi_k:\n",
    "            break\n",
    "    # print(len(remaining_updates))\n",
    "    aggregate = torch.mean(candidates, dim=0)\n",
    "    return aggregate, np.array(candidate_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for Bulyan aggregation algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bulyan(all_updates, n_attackers):\n",
    "    nusers = all_updates.shape[0]\n",
    "    bulyan_cluster = []\n",
    "    candidate_indices = []\n",
    "    remaining_updates = all_updates\n",
    "    all_indices = np.arange(len(all_updates))\n",
    "\n",
    "    while len(bulyan_cluster) < (nusers - 2 * n_attackers):\n",
    "        distances = []\n",
    "        for update in remaining_updates:\n",
    "            distance = torch.norm((remaining_updates - update), dim=1) ** 2\n",
    "            distances = distance[None, :] if not len(distances) else torch.cat((distances, distance[None, :]), 0)\n",
    "\n",
    "        distances = torch.sort(distances, dim=1)[0]\n",
    "\n",
    "        scores = torch.sum(distances[:, :len(remaining_updates) - 2 - n_attackers], dim=1)\n",
    "        indices = torch.argsort(scores)[:len(remaining_updates) - 2 - n_attackers]\n",
    "\n",
    "        candidate_indices.append(all_indices[indices[0].cpu().numpy()])\n",
    "        all_indices = np.delete(all_indices, indices[0].cpu().numpy())\n",
    "        bulyan_cluster = remaining_updates[indices[0]][None, :] if not len(bulyan_cluster) else torch.cat((bulyan_cluster, remaining_updates[indices[0]][None, :]), 0)\n",
    "        remaining_updates = torch.cat((remaining_updates[:indices[0]], remaining_updates[indices[0] + 1:]), 0)\n",
    "\n",
    "    # print('dim of bulyan cluster ', bulyan_cluster.shape)\n",
    "\n",
    "    n, d = bulyan_cluster.shape\n",
    "    param_med = torch.median(bulyan_cluster, dim=0)[0]\n",
    "    sort_idx = torch.argsort(torch.abs(bulyan_cluster - param_med), dim=0)\n",
    "    sorted_params = bulyan_cluster[sort_idx, torch.arange(d)[None, :]]\n",
    "\n",
    "    return torch.mean(sorted_params[:n - 2 * n_attackers], dim=0), np.array(candidate_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for our AGR-tailored attack on Bulyan\n",
    "### Our AGR-tailored attacks on MKrum and Bulyan are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def our_attack_mkrum(all_updates, model_re, n_attackers,dev_type='unit_vec'):\n",
    "\n",
    "    if dev_type == 'unit_vec':\n",
    "        deviation = model_re / torch.norm(model_re)  # unit vector, dir opp to good dir\n",
    "    elif dev_type == 'sign':\n",
    "        deviation = torch.sign(model_re)\n",
    "    elif dev_type == 'std':\n",
    "        deviation = torch.std(all_updates, 0)\n",
    "        \n",
    "    lamda = torch.Tensor([20.0]).cuda() #compute_lambda_our(all_updates, model_re, n_attackers)\n",
    "    # print(lamda)\n",
    "    threshold_diff = 1e-5\n",
    "    lamda_fail = lamda\n",
    "    lamda_succ = 0\n",
    "\n",
    "    while torch.abs(lamda_succ - lamda) > threshold_diff:\n",
    "        mal_update = (model_re - lamda * deviation)\n",
    "        mal_updates = torch.stack([mal_update] * n_attackers)\n",
    "        mal_updates = torch.cat((mal_updates, all_updates), 0)\n",
    "\n",
    "        agg_grads, krum_candidate = multi_krum(mal_updates, n_attackers, multi_k=True)\n",
    "\n",
    "        if np.sum(krum_candidate < n_attackers) == n_attackers:\n",
    "            # print('successful lamda is ', lamda)\n",
    "            lamda_succ = lamda\n",
    "            lamda = lamda + lamda_fail / 2\n",
    "        else:\n",
    "            lamda = lamda - lamda_fail / 2\n",
    "\n",
    "        lamda_fail = lamda_fail / 2\n",
    "\n",
    "    mal_update = (model_re - lamda_succ * deviation)\n",
    "\n",
    "    return mal_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Initializing global model\n",
      "multi krum is  True\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 0 fed_model val loss 3.9671 val acc 3.8252 best val_acc 3.825165 te_acc 4.092875\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 20 fed_model val loss 3.6667 val acc 17.2879 best val_acc 17.287891 te_acc 19.012562\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 40 fed_model val loss 3.3128 val acc 26.5754 best val_acc 29.118616 te_acc 32.915465\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 8 e 60 fed_model val loss 2.9159 val acc 32.7379 best val_acc 32.961800 te_acc 37.201400\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 80 fed_model val loss 2.7312 val acc 34.0404 best val_acc 34.104716 te_acc 38.429263\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 100 fed_model val loss 2.6795 val acc 34.9465 best val_acc 35.245058 te_acc 39.260708\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 6 e 120 fed_model val loss 2.6479 val acc 36.3700 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 6 e 140 fed_model val loss 2.9885 val acc 31.5074 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 5 e 160 fed_model val loss 3.4727 val acc 24.3616 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 4 e 180 fed_model val loss 3.6675 val acc 21.8801 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 200 fed_model val loss 3.5066 val acc 19.9701 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 220 fed_model val loss 3.4289 val acc 19.7668 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 240 fed_model val loss 3.3524 val acc 21.2340 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 260 fed_model val loss 3.2904 val acc 21.9754 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 280 fed_model val loss 3.3523 val acc 21.6819 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 300 fed_model val loss 3.3810 val acc 20.9200 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 320 fed_model val loss 3.4121 val acc 21.0075 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 340 fed_model val loss 3.4082 val acc 20.4438 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 360 fed_model val loss 3.4612 val acc 21.2134 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 380 fed_model val loss 3.4622 val acc 20.8917 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 400 fed_model val loss 3.4186 val acc 20.4335 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 420 fed_model val loss 3.5374 val acc 21.0281 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 440 fed_model val loss 3.5961 val acc 19.3421 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 7 e 460 fed_model val loss 3.9035 val acc 9.0687 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 480 fed_model val loss 3.7744 val acc 5.3362 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 500 fed_model val loss 3.7499 val acc 5.3336 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 520 fed_model val loss 3.7462 val acc 5.3336 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 540 fed_model val loss 3.7443 val acc 5.3336 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 560 fed_model val loss 3.7439 val acc 5.3336 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 580 fed_model val loss 3.7437 val acc 5.3336 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 600 fed_model val loss 3.7437 val acc 5.3336 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 620 fed_model val loss 3.7438 val acc 5.3336 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 640 fed_model val loss 3.7440 val acc 5.3336 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 660 fed_model val loss 3.7444 val acc 5.3336 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 680 fed_model val loss 3.7449 val acc 5.3336 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 700 fed_model val loss 3.7454 val acc 5.3336 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 720 fed_model val loss 3.7450 val acc 5.3336 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 740 fed_model val loss 3.7451 val acc 5.3336 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 760 fed_model val loss 3.7451 val acc 5.3336 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 780 fed_model val loss 3.7456 val acc 5.3336 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 800 fed_model val loss 3.7455 val acc 5.3336 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 820 fed_model val loss 3.7455 val acc 5.3336 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 840 fed_model val loss 3.7456 val acc 5.3336 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 860 fed_model val loss 3.7456 val acc 5.3336 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 880 fed_model val loss 3.7456 val acc 5.3336 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 900 fed_model val loss 3.7456 val acc 5.3336 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 920 fed_model val loss 3.7457 val acc 5.3336 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 940 fed_model val loss 3.7451 val acc 5.3336 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 960 fed_model val loss 3.7455 val acc 5.3336 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 980 fed_model val loss 3.7454 val acc 5.3310 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 1000 fed_model val loss 3.7457 val acc 5.3310 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 1020 fed_model val loss 3.7456 val acc 5.3310 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 1040 fed_model val loss 3.7453 val acc 5.3310 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 1060 fed_model val loss 3.7452 val acc 5.3388 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 1080 fed_model val loss 3.7453 val acc 5.3388 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 1100 fed_model val loss 3.7443 val acc 5.3645 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 1120 fed_model val loss 3.7446 val acc 5.3388 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 1140 fed_model val loss 3.7446 val acc 5.3413 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 1160 fed_model val loss 3.7447 val acc 5.3413 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 1180 fed_model val loss 3.7447 val acc 5.3465 best val_acc 36.369955 te_acc 40.092154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 1200 fed_model val loss 3.7448 val acc 5.3568 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 1220 fed_model val loss 3.7447 val acc 5.3722 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 1240 fed_model val loss 3.7448 val acc 5.3851 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 1260 fed_model val loss 3.7448 val acc 5.3980 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 1280 fed_model val loss 3.7448 val acc 5.4134 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 1300 fed_model val loss 3.7449 val acc 5.4494 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 1320 fed_model val loss 3.7449 val acc 5.4778 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 1340 fed_model val loss 3.7449 val acc 5.4984 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 1360 fed_model val loss 3.7449 val acc 5.5292 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 1380 fed_model val loss 3.7449 val acc 5.5576 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 1400 fed_model val loss 3.7450 val acc 5.5782 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 1420 fed_model val loss 3.7450 val acc 5.5962 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 1440 fed_model val loss 3.7451 val acc 5.5807 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 1460 fed_model val loss 3.7452 val acc 5.6528 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 1480 fed_model val loss 3.7447 val acc 5.7738 best val_acc 36.369955 te_acc 40.092154\n",
      "mkrum: at our-agr at_frac 20.0 n_at 9 n_mal_sel 9 e 1500 fed_model val loss 3.7429 val acc 5.7197 best val_acc 36.369955 te_acc 40.092154\n"
     ]
    }
   ],
   "source": [
    "resume=0\n",
    "nepochs=1500\n",
    "gamma=.1\n",
    "fed_lr=0.001\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "batch_size = 100\n",
    "schedule = [2000]\n",
    "\n",
    "aggregation = 'mkrum'\n",
    "at_type = 'our-agr'\n",
    "chkpt = './' + aggregation\n",
    "epoch_num = 0\n",
    "\n",
    "at_fractions = [20]\n",
    "\n",
    "for at_fraction in at_fractions:\n",
    "\n",
    "    fed_model = mnist_conv().cuda()\n",
    "    fed_model.apply(weights_init)\n",
    "    optimizer_fed = Adam(fed_model.parameters(), lr=fed_lr)\n",
    "\n",
    "    print('==> Initializing global model')\n",
    "    epoch_num = 0\n",
    "    n_attacker = 0\n",
    "    best_global_acc=0\n",
    "    best_global_te_acc=0\n",
    "\n",
    "    while epoch_num <= nepochs:\n",
    "        user_grads = []\n",
    "        \n",
    "        # The following condition is necessary for Krum/Multi-krum/Bulyan to work\n",
    "        while n_attacker < 4:\n",
    "            round_users = np.random.choice(3400, 60)\n",
    "            n_attacker = np.sum(round_users < (34*at_fraction))\n",
    "\n",
    "        if n_attacker > 14:\n",
    "            print ('n_attackers actual %d adjusted 14' % n_attacker)\n",
    "            n_attacker = 14\n",
    "\n",
    "        at_idx = []\n",
    "        attacker_count = 0\n",
    "        for i in round_users:\n",
    "            if i < (34*at_fraction) and attacker_count < n_attacker:\n",
    "                at_idx.append(i)\n",
    "                attacker_count += 1\n",
    "                continue\n",
    "\n",
    "            inputs = user_tr_data_tensors[i]\n",
    "            targets = user_tr_label_tensors[i]\n",
    "\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "            outputs = fed_model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            optimizer_fed.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "\n",
    "            param_grad=[]\n",
    "            for param in fed_model.parameters():\n",
    "                param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
    "\n",
    "            user_grads=param_grad[None,:] if len(user_grads)==0 else torch.cat((user_grads,param_grad[None,:]),0)    \n",
    "\n",
    "        if n_attacker > 0:\n",
    "            attacker_grads = []\n",
    "            n_attacker_ = max(1, n_attacker**2//60)\n",
    "            for i in at_idx:\n",
    "\n",
    "                inputs = user_tr_data_tensors[i]\n",
    "                targets = user_tr_label_tensors[i]\n",
    "\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "                inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "                outputs = fed_model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                optimizer_fed.zero_grad()\n",
    "                loss.backward(retain_graph=True)\n",
    "\n",
    "                param_grad=[]\n",
    "                for param in fed_model.parameters():\n",
    "                    param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
    "\n",
    "                attacker_grads=param_grad[None,:] if len(attacker_grads)==0 else torch.cat((attacker_grads,param_grad[None,:]),0)\n",
    "\n",
    "            mal_updates = []\n",
    "            if at_type == 'fang':\n",
    "                agg_grads = torch.mean(attacker_grads, 0)\n",
    "                deviation = torch.sign(agg_grads)\n",
    "                mal_update = get_malicious_updates_fang(attacker_grads, agg_grads, deviation, n_attacker_)\n",
    "\n",
    "            elif at_type == 'our-agr':\n",
    "                agg_grads = torch.mean(attacker_grads, 0)\n",
    "                mal_update = our_attack_mkrum(attacker_grads, agg_grads, n_attacker_, dev_type='sign')\n",
    "            \n",
    "        if not len(mal_updates):\n",
    "            mal_updates = torch.stack([mal_update] * n_attacker)\n",
    "        malicious_grads = torch.cat((mal_updates, user_grads), 0)    \n",
    "        \n",
    "        if malicious_grads.shape[0] != 60: \n",
    "            print('malicious grads shape ', malicious_grads.shape)\n",
    "            sys.exit()\n",
    "\n",
    "        multi_k = True if aggregation == 'mkrum' else False\n",
    "        if epoch_num == 0: print('multi krum is ', multi_k)\n",
    "        agg_grads, krum_candidate = multi_krum(malicious_grads, n_attacker, multi_k=multi_k)\n",
    "            \n",
    "        start_idx=0\n",
    "\n",
    "        if epoch_num in schedule:\n",
    "            for param_group in optimizer_fed.param_groups:\n",
    "                param_group['lr'] *= gamma\n",
    "                print('New learnin rate ', param_group['lr'])\n",
    "\n",
    "        optimizer_fed.zero_grad()\n",
    "\n",
    "        model_grads=[]\n",
    "\n",
    "        for i, param in enumerate(fed_model.parameters()):\n",
    "            param_=agg_grads[start_idx:start_idx+len(param.data.view(-1))].reshape(param.data.shape)\n",
    "            start_idx=start_idx+len(param.data.view(-1))\n",
    "            param_=param_.cuda()\n",
    "            model_grads.append(param_)\n",
    "\n",
    "        optimizer_fed.step(model_grads)\n",
    "\n",
    "        val_loss, val_acc = test(val_data_tensor,val_label_tensor,fed_model,criterion,use_cuda)\n",
    "        te_loss, te_acc = test(te_data_tensor,te_label_tensor, fed_model, criterion, use_cuda)\n",
    "\n",
    "        is_best = best_global_acc < val_acc\n",
    "\n",
    "        best_global_acc = max(best_global_acc, val_acc)\n",
    "\n",
    "        if is_best:\n",
    "            best_global_te_acc = te_acc\n",
    "\n",
    "        if epoch_num % 20 == 0:\n",
    "            print('%s: at %s at_frac %.1f n_at %d n_mal_sel %d e %d fed_model val loss %.4f val acc %.4f best val_acc %f te_acc %f'%(aggregation, at_type, at_fraction, n_attacker, np.sum(krum_candidate < n_attacker), epoch_num, val_loss, val_acc, best_global_acc,best_global_te_acc))\n",
    "\n",
    "        epoch_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
