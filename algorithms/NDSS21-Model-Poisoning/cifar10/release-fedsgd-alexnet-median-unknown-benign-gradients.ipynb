{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The notebook contains\n",
    "\n",
    "### Code for _Median_ aggregation algorithm, *when gradient updates of benign clients are unknown to adversary*\n",
    "### Evaluation of all of the attacks (Fang, LIE, and our SOTA AGR-tailored and AGR-agnstic) on Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse, os, sys, csv, shutil, time, random, operator, pickle, ast, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.optim import Optimizer\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "sys.path.insert(0,'./../utils/')\n",
    "from logger import *\n",
    "from eval import *\n",
    "from misc import *\n",
    "\n",
    "from cifar10_normal_train import *\n",
    "from cifar10_util import *\n",
    "from adam import Adam\n",
    "from sgd import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get CIFAR10 data and split it in IID fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "total data len:  60000\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "data_loc='/mnt/nfs/work1/amir/vshejwalkar/cifar10_data/'\n",
    "# load the train dataset\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "cifar10_train = datasets.CIFAR10(root=data_loc, train=True, download=True, transform=train_transform)\n",
    "\n",
    "cifar10_test = datasets.CIFAR10(root=data_loc, train=False, download=True, transform=train_transform)\n",
    "\n",
    "X=[]\n",
    "Y=[]\n",
    "for i in range(len(cifar10_train)):\n",
    "    X.append(cifar10_train[i][0].numpy())\n",
    "    Y.append(cifar10_train[i][1])\n",
    "\n",
    "for i in range(len(cifar10_test)):\n",
    "    X.append(cifar10_test[i][0].numpy())\n",
    "    Y.append(cifar10_test[i][1])\n",
    "\n",
    "X=np.array(X)\n",
    "Y=np.array(Y)\n",
    "\n",
    "print('total data len: ',len(X))\n",
    "\n",
    "if not os.path.isfile('./cifar10_shuffle.pkl'):\n",
    "    all_indices = np.arange(len(X))\n",
    "    np.random.shuffle(all_indices)\n",
    "    pickle.dump(all_indices,open('./cifar10_shuffle.pkl','wb'))\n",
    "else:\n",
    "    all_indices=pickle.load(open('./cifar10_shuffle.pkl','rb'))\n",
    "\n",
    "X=X[all_indices]\n",
    "Y=Y[all_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data len:  60000\n",
      "total tr len 50000 | val len 5000 | test len 5000\n",
      "user 0 tr len 1000\n",
      "user 1 tr len 1000\n",
      "user 2 tr len 1000\n",
      "user 3 tr len 1000\n",
      "user 4 tr len 1000\n",
      "user 5 tr len 1000\n",
      "user 6 tr len 1000\n",
      "user 7 tr len 1000\n",
      "user 8 tr len 1000\n",
      "user 9 tr len 1000\n",
      "user 10 tr len 1000\n",
      "user 11 tr len 1000\n",
      "user 12 tr len 1000\n",
      "user 13 tr len 1000\n",
      "user 14 tr len 1000\n",
      "user 15 tr len 1000\n",
      "user 16 tr len 1000\n",
      "user 17 tr len 1000\n",
      "user 18 tr len 1000\n",
      "user 19 tr len 1000\n",
      "user 20 tr len 1000\n",
      "user 21 tr len 1000\n",
      "user 22 tr len 1000\n",
      "user 23 tr len 1000\n",
      "user 24 tr len 1000\n",
      "user 25 tr len 1000\n",
      "user 26 tr len 1000\n",
      "user 27 tr len 1000\n",
      "user 28 tr len 1000\n",
      "user 29 tr len 1000\n",
      "user 30 tr len 1000\n",
      "user 31 tr len 1000\n",
      "user 32 tr len 1000\n",
      "user 33 tr len 1000\n",
      "user 34 tr len 1000\n",
      "user 35 tr len 1000\n",
      "user 36 tr len 1000\n",
      "user 37 tr len 1000\n",
      "user 38 tr len 1000\n",
      "user 39 tr len 1000\n",
      "user 40 tr len 1000\n",
      "user 41 tr len 1000\n",
      "user 42 tr len 1000\n",
      "user 43 tr len 1000\n",
      "user 44 tr len 1000\n",
      "user 45 tr len 1000\n",
      "user 46 tr len 1000\n",
      "user 47 tr len 1000\n",
      "user 48 tr len 1000\n",
      "user 49 tr len 1000\n"
     ]
    }
   ],
   "source": [
    "# data loading\n",
    "\n",
    "nusers=50\n",
    "user_tr_len=1000\n",
    "\n",
    "total_tr_len=user_tr_len*nusers\n",
    "val_len=5000\n",
    "te_len=5000\n",
    "\n",
    "print('total data len: ',len(X))\n",
    "\n",
    "if not os.path.isfile('./cifar10_shuffle.pkl'):\n",
    "    all_indices = np.arange(len(X))\n",
    "    np.random.shuffle(all_indices)\n",
    "    pickle.dump(all_indices,open('./cifar10_shuffle.pkl','wb'))\n",
    "else:\n",
    "    all_indices=pickle.load(open('./cifar10_shuffle.pkl','rb'))\n",
    "\n",
    "total_tr_data=X[:total_tr_len]\n",
    "total_tr_label=Y[:total_tr_len]\n",
    "\n",
    "val_data=X[total_tr_len:(total_tr_len+val_len)]\n",
    "val_label=Y[total_tr_len:(total_tr_len+val_len)]\n",
    "\n",
    "te_data=X[(total_tr_len+val_len):(total_tr_len+val_len+te_len)]\n",
    "te_label=Y[(total_tr_len+val_len):(total_tr_len+val_len+te_len)]\n",
    "\n",
    "total_tr_data_tensor=torch.from_numpy(total_tr_data).type(torch.FloatTensor)\n",
    "total_tr_label_tensor=torch.from_numpy(total_tr_label).type(torch.LongTensor)\n",
    "\n",
    "val_data_tensor=torch.from_numpy(val_data).type(torch.FloatTensor)\n",
    "val_label_tensor=torch.from_numpy(val_label).type(torch.LongTensor)\n",
    "\n",
    "te_data_tensor=torch.from_numpy(te_data).type(torch.FloatTensor)\n",
    "te_label_tensor=torch.from_numpy(te_label).type(torch.LongTensor)\n",
    "\n",
    "print('total tr len %d | val len %d | test len %d'%(len(total_tr_data_tensor),len(val_data_tensor),len(te_data_tensor)))\n",
    "\n",
    "#==============================================================================================================\n",
    "\n",
    "user_tr_data_tensors=[]\n",
    "user_tr_label_tensors=[]\n",
    "\n",
    "for i in range(nusers):\n",
    "    \n",
    "    user_tr_data_tensor=torch.from_numpy(total_tr_data[user_tr_len*i:user_tr_len*(i+1)]).type(torch.FloatTensor)\n",
    "    user_tr_label_tensor=torch.from_numpy(total_tr_label[user_tr_len*i:user_tr_len*(i+1)]).type(torch.LongTensor)\n",
    "\n",
    "    user_tr_data_tensors.append(user_tr_data_tensor)\n",
    "    user_tr_label_tensors.append(user_tr_label_tensor)\n",
    "    print('user %d tr len %d'%(i,len(user_tr_data_tensor)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial knowledge Fang attack on median aggregation\n",
    "### Note that Fang attacks on Trimmed-mean and median are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fang_attack_trmean_partial(all_updates, n_attackers):\n",
    "\n",
    "    model_re = torch.mean(all_updates, 0)\n",
    "    model_std = torch.std(all_updates, 0)\n",
    "    deviation = torch.sign(model_re)\n",
    "    \n",
    "    max_vector_low = model_re + 3 * model_std \n",
    "    max_vector_hig = model_re + 4 * model_std\n",
    "    min_vector_low = model_re - 4 * model_std\n",
    "    min_vector_hig = model_re - 3 * model_std\n",
    "\n",
    "    max_range = torch.cat((max_vector_low[:,None], max_vector_hig[:,None]), dim=1)\n",
    "    min_range = torch.cat((min_vector_low[:,None], min_vector_hig[:,None]), dim=1)\n",
    "\n",
    "    rand = torch.from_numpy(np.random.uniform(0, 1, [len(deviation), n_attackers])).type(torch.FloatTensor).cuda()\n",
    "\n",
    "    max_rand = torch.stack([max_range[:, 0]] * rand.shape[1]).T + rand * torch.stack([max_range[:, 1] - max_range[:, 0]] * rand.shape[1]).T\n",
    "    min_rand = torch.stack([min_range[:, 0]] * rand.shape[1]).T + rand * torch.stack([min_range[:, 1] - min_range[:, 0]] * rand.shape[1]).T\n",
    "\n",
    "    mal_vec = (torch.stack([(deviation > 0).type(torch.FloatTensor)] * max_rand.shape[1]).T.cuda() * max_rand + torch.stack(\n",
    "        [(deviation > 0).type(torch.FloatTensor)] * min_rand.shape[1]).T.cuda() * min_rand).T\n",
    "\n",
    "    return mal_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 2472266])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vshejwalkar/NDSS21-Model-Poisoning/cifar10/sgd.py:109: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729138878/work/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  p.data.add_(-group['lr'], d_p)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median: at fang n_at 10 e 0 fed_model val loss 2.3023 val acc 10.2881 best val_acc 10.288149 te_acc 9.659091\n",
      "median: at fang n_at 10 e 25 fed_model val loss 2.2122 val acc 20.5154 best val_acc 20.515422 te_acc 19.825487\n",
      "median: at fang n_at 10 e 50 fed_model val loss 2.1932 val acc 18.6485 best val_acc 20.515422 te_acc 19.825487\n",
      "median: at fang n_at 10 e 75 fed_model val loss 2.1634 val acc 20.3328 best val_acc 23.295455 te_acc 23.701299\n",
      "median: at fang n_at 10 e 100 fed_model val loss 2.1253 val acc 22.3823 best val_acc 24.228896 te_acc 24.086851\n",
      "median: at fang n_at 10 e 125 fed_model val loss 2.0022 val acc 21.4692 best val_acc 24.228896 te_acc 24.086851\n",
      "median: at fang n_at 10 e 150 fed_model val loss 1.9876 val acc 19.5008 best val_acc 25.446429 te_acc 26.116071\n",
      "median: at fang n_at 10 e 175 fed_model val loss 2.0078 val acc 23.4578 best val_acc 28.125000 te_acc 27.150974\n",
      "median: at fang n_at 10 e 200 fed_model val loss 1.8895 val acc 28.7744 best val_acc 28.774351 te_acc 29.606331\n",
      "median: at fang n_at 10 e 225 fed_model val loss 1.8210 val acc 32.6705 best val_acc 32.670455 te_acc 31.919643\n",
      "median: at fang n_at 10 e 250 fed_model val loss 1.7817 val acc 34.3750 best val_acc 35.470779 te_acc 35.105519\n",
      "median: at fang n_at 10 e 275 fed_model val loss 1.7776 val acc 33.6039 best val_acc 39.245130 te_acc 38.575487\n",
      "median: at fang n_at 10 e 300 fed_model val loss 1.6872 val acc 38.5552 best val_acc 40.280032 te_acc 39.833604\n",
      "median: at fang n_at 10 e 325 fed_model val loss 1.6274 val acc 41.2541 best val_acc 41.254058 te_acc 41.152597\n",
      "median: at fang n_at 10 e 350 fed_model val loss 1.6440 val acc 39.9351 best val_acc 42.836851 te_acc 43.790584\n",
      "median: at fang n_at 10 e 375 fed_model val loss 1.5071 val acc 45.5966 best val_acc 46.225649 te_acc 46.063312\n",
      "median: at fang n_at 10 e 400 fed_model val loss 1.6393 val acc 40.8888 best val_acc 46.225649 te_acc 46.063312\n",
      "median: at fang n_at 10 e 425 fed_model val loss 1.5405 val acc 45.3937 best val_acc 46.225649 te_acc 46.063312\n",
      "median: at fang n_at 10 e 450 fed_model val loss 1.5477 val acc 43.3239 best val_acc 47.321429 te_acc 47.767857\n",
      "median: at fang n_at 10 e 475 fed_model val loss 1.5605 val acc 43.7703 best val_acc 47.443182 te_acc 47.889610\n",
      "median: at fang n_at 10 e 500 fed_model val loss 1.5649 val acc 43.5674 best val_acc 47.443182 te_acc 47.889610\n",
      "median: at fang n_at 10 e 525 fed_model val loss 1.5874 val acc 41.4976 best val_acc 48.254870 te_acc 49.431818\n",
      "median: at fang n_at 10 e 550 fed_model val loss 1.5189 val acc 45.7386 best val_acc 48.315747 te_acc 49.208604\n",
      "median: at fang n_at 10 e 575 fed_model val loss 1.4799 val acc 47.2606 best val_acc 48.802760 te_acc 49.512987\n",
      "median: at fang n_at 10 e 600 fed_model val loss 1.4769 val acc 47.4432 best val_acc 49.411526 te_acc 50.020292\n",
      "median: at fang n_at 10 e 625 fed_model val loss 1.4690 val acc 47.6258 best val_acc 49.411526 te_acc 50.020292\n",
      "median: at fang n_at 10 e 650 fed_model val loss 1.4743 val acc 46.0430 best val_acc 49.797078 te_acc 51.258117\n",
      "median: at fang n_at 10 e 675 fed_model val loss 1.4483 val acc 48.0925 best val_acc 49.797078 te_acc 51.258117\n",
      "median: at fang n_at 10 e 700 fed_model val loss 1.3968 val acc 50.5073 best val_acc 50.507305 te_acc 51.481331\n",
      "median: at fang n_at 10 e 725 fed_model val loss 1.4393 val acc 48.4781 best val_acc 50.507305 te_acc 51.481331\n",
      "median: at fang n_at 10 e 750 fed_model val loss 1.4922 val acc 46.8953 best val_acc 50.507305 te_acc 51.481331\n",
      "median: at fang n_at 10 e 775 fed_model val loss 1.4316 val acc 48.9651 best val_acc 50.507305 te_acc 51.481331\n",
      "median: at fang n_at 10 e 800 fed_model val loss 1.3889 val acc 51.3799 best val_acc 51.481331 te_acc 51.785714\n",
      "median: at fang n_at 10 e 825 fed_model val loss 1.4574 val acc 48.1940 best val_acc 52.008929 te_acc 52.353896\n",
      "median: at fang n_at 10 e 850 fed_model val loss 1.4448 val acc 48.3969 best val_acc 52.008929 te_acc 52.353896\n",
      "median: at fang n_at 10 e 875 fed_model val loss 1.4595 val acc 48.7419 best val_acc 52.008929 te_acc 52.353896\n",
      "median: at fang n_at 10 e 900 fed_model val loss 1.3739 val acc 52.1713 best val_acc 52.171266 te_acc 52.617695\n",
      "median: at fang n_at 10 e 925 fed_model val loss 1.5335 val acc 47.5852 best val_acc 52.171266 te_acc 52.617695\n",
      "median: at fang n_at 10 e 950 fed_model val loss 1.4726 val acc 47.7881 best val_acc 52.171266 te_acc 52.617695\n",
      "median: at fang n_at 10 e 975 fed_model val loss 1.4767 val acc 48.3969 best val_acc 52.171266 te_acc 52.617695\n",
      "New learnin rate  0.25\n",
      "median: at fang n_at 10 e 1000 fed_model val loss 1.3799 val acc 51.4002 best val_acc 52.171266 te_acc 52.617695\n",
      "median: at fang n_at 10 e 1025 fed_model val loss 1.3461 val acc 53.4903 best val_acc 53.490260 te_acc 53.469968\n",
      "median: at fang n_at 10 e 1050 fed_model val loss 1.3401 val acc 53.3482 best val_acc 53.490260 te_acc 53.469968\n",
      "median: at fang n_at 10 e 1075 fed_model val loss 1.3367 val acc 53.4497 best val_acc 53.632305 te_acc 53.794643\n",
      "median: at fang n_at 10 e 1100 fed_model val loss 1.3344 val acc 53.4700 best val_acc 53.632305 te_acc 53.794643\n",
      "median: at fang n_at 10 e 1125 fed_model val loss 1.3332 val acc 53.6120 best val_acc 53.794643 te_acc 54.423701\n",
      "median: at fang n_at 10 e 1150 fed_model val loss 1.3333 val acc 53.9773 best val_acc 53.997565 te_acc 54.565747\n",
      "median: at fang n_at 10 e 1175 fed_model val loss 1.3328 val acc 54.0787 best val_acc 54.261364 te_acc 54.565747\n",
      "median: at fang n_at 10 e 1199 fed_model val loss 1.3328 val acc 53.9976 best val_acc 54.322240 te_acc 54.525162\n",
      "median: at fang n_at 10 e 1200 fed_model val loss 1.3336 val acc 54.1599 best val_acc 54.322240 te_acc 54.525162\n"
     ]
    }
   ],
   "source": [
    "batch_size=250\n",
    "resume=0\n",
    "nepochs=1200\n",
    "schedule=[1000]\n",
    "nbatches = user_tr_len//batch_size\n",
    "\n",
    "gamma=.5\n",
    "opt = 'sgd'\n",
    "fed_lr=0.5\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "aggregation='median'\n",
    "multi_k = False\n",
    "candidates = []\n",
    "\n",
    "at_type='fang'\n",
    "z_values=[0.0]\n",
    "n_attackers=[10]\n",
    "\n",
    "arch='alexnet'\n",
    "chkpt='./'+aggregation\n",
    "\n",
    "for n_attacker in n_attackers:\n",
    "    epoch_num = 0\n",
    "    best_global_acc = 0\n",
    "    best_global_te_acc = 0\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    r=np.arange(user_tr_len)\n",
    "\n",
    "    fed_model, _ = return_model(arch, 0.1, 0.9, parallel=False)\n",
    "    optimizer_fed = SGD(fed_model.parameters(), lr=fed_lr)\n",
    "\n",
    "    while epoch_num <= nepochs:\n",
    "        user_grads=[]\n",
    "        if not epoch_num and epoch_num%nbatches == 0:\n",
    "            np.random.shuffle(r)\n",
    "            for i in range(nusers):\n",
    "                user_tr_data_tensors[i]=user_tr_data_tensors[i][r]\n",
    "                user_tr_label_tensors[i]=user_tr_label_tensors[i][r]\n",
    "\n",
    "        for i in range(nusers):\n",
    "\n",
    "            inputs = user_tr_data_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
    "            targets = user_tr_label_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
    "\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "            outputs = fed_model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            fed_model.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "\n",
    "            param_grad=[]\n",
    "            for param in fed_model.parameters():\n",
    "                param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
    "\n",
    "            user_grads=param_grad[None, :] if len(user_grads)==0 else torch.cat((user_grads,param_grad[None,:]), 0)\n",
    "\n",
    "        if epoch_num in schedule:\n",
    "            for param_group in optimizer_fed.param_groups:\n",
    "                param_group['lr'] *= gamma\n",
    "                print('New learnin rate ', param_group['lr'])\n",
    "\n",
    "        if n_attacker > 0:\n",
    "            if at_type == 'lie':\n",
    "                malicious_grad = get_malicious_updates_lie(user_grads[:n_attacker], n_attacker, z, epoch_num)\n",
    "            elif at_type == 'fang':\n",
    "                mal_updates = fang_attack_trmean_partial(user_grads[:n_attacker], n_attacker)\n",
    "\n",
    "        malicious_grads = torch.cat((mal_updates, user_grads[n_attacker:]))\n",
    "        \n",
    "        if not epoch_num : \n",
    "            print(malicious_grads.shape)\n",
    "\n",
    "        if aggregation=='median':\n",
    "            agg_grads=torch.median(malicious_grads,dim=0)[0]\n",
    "\n",
    "        elif aggregation=='average':\n",
    "            agg_grads=torch.mean(malicious_grads,dim=0)\n",
    "\n",
    "        elif aggregation=='trmean':\n",
    "            agg_grads=tr_mean(malicious_grads, n_attacker)\n",
    "\n",
    "        elif aggregation=='krum' or aggregation=='mkrum':\n",
    "            multi_k = True if aggregation == 'mkrum' else False\n",
    "            if epoch_num == 0: print('multi krum is ', multi_k)\n",
    "            agg_grads, krum_candidate = multi_krum(malicious_grads, n_attacker, multi_k=multi_k)\n",
    "\n",
    "        elif aggregation=='bulyan':\n",
    "            agg_grads, krum_candidate=bulyan(malicious_grads, n_attacker)\n",
    "\n",
    "        del user_grads\n",
    "\n",
    "        start_idx=0\n",
    "\n",
    "        optimizer_fed.zero_grad()\n",
    "\n",
    "        model_grads=[]\n",
    "\n",
    "        for i, param in enumerate(fed_model.parameters()):\n",
    "            param_=agg_grads[start_idx:start_idx+len(param.data.view(-1))].reshape(param.data.shape)\n",
    "            start_idx=start_idx+len(param.data.view(-1))\n",
    "            param_=param_.cuda()\n",
    "            model_grads.append(param_)\n",
    "\n",
    "        optimizer_fed.step(model_grads)\n",
    "\n",
    "        val_loss, val_acc = test(val_data_tensor,val_label_tensor,fed_model,criterion,use_cuda)\n",
    "        te_loss, te_acc = test(te_data_tensor,te_label_tensor, fed_model, criterion, use_cuda)\n",
    "\n",
    "        is_best = best_global_acc < val_acc\n",
    "\n",
    "        best_global_acc = max(best_global_acc, val_acc)\n",
    "\n",
    "        if is_best:\n",
    "            best_global_te_acc = te_acc\n",
    "\n",
    "        if epoch_num%25==0 or epoch_num==nepochs-1:\n",
    "            print('%s: at %s n_at %d e %d fed_model val loss %.4f val acc %.4f best val_acc %f te_acc %f'%(aggregation, at_type, n_attacker, epoch_num, val_loss, val_acc, best_global_acc,best_global_te_acc))\n",
    "\n",
    "        if val_loss > 10:\n",
    "            print('val loss %f too high'%val_loss)\n",
    "            break\n",
    "\n",
    "        epoch_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for LIE attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lie_attack(all_updates, z):\n",
    "    avg = torch.mean(all_updates, dim=0)\n",
    "    std = torch.std(all_updates, dim=0)\n",
    "    return avg + z * std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 2472266])\n",
      "median: at LIE n_at 10 e 0 fed_model val loss 2.3032 val acc 9.5982 best val_acc 9.598214 te_acc 10.024351\n",
      "median: at LIE n_at 10 e 10 fed_model val loss 2.2999 val acc 14.2045 best val_acc 14.204545 te_acc 14.874188\n",
      "median: at LIE n_at 10 e 20 fed_model val loss 2.2895 val acc 16.5990 best val_acc 16.599026 te_acc 17.938312\n",
      "median: at LIE n_at 10 e 30 fed_model val loss 2.2597 val acc 14.7930 best val_acc 17.370130 te_acc 18.810877\n",
      "median: at LIE n_at 10 e 40 fed_model val loss 2.2493 val acc 12.6420 best val_acc 17.370130 te_acc 18.810877\n",
      "median: at LIE n_at 10 e 50 fed_model val loss 2.1841 val acc 20.0690 best val_acc 20.068994 te_acc 20.819805\n",
      "median: at LIE n_at 10 e 60 fed_model val loss 2.0994 val acc 20.3531 best val_acc 21.692370 te_acc 21.935877\n",
      "median: at LIE n_at 10 e 70 fed_model val loss 2.3090 val acc 11.3231 best val_acc 21.692370 te_acc 21.935877\n",
      "median: at LIE n_at 10 e 80 fed_model val loss 2.2904 val acc 9.6388 best val_acc 21.692370 te_acc 21.935877\n",
      "median: at LIE n_at 10 e 90 fed_model val loss 2.2123 val acc 10.1055 best val_acc 21.692370 te_acc 21.935877\n",
      "median: at LIE n_at 10 e 100 fed_model val loss 2.2807 val acc 16.0308 best val_acc 22.382305 te_acc 21.875000\n",
      "median: at LIE n_at 10 e 110 fed_model val loss 2.1675 val acc 19.5820 best val_acc 22.382305 te_acc 21.875000\n",
      "median: at LIE n_at 10 e 120 fed_model val loss 2.1087 val acc 21.6721 best val_acc 23.133117 te_acc 23.072240\n",
      "median: at LIE n_at 10 e 130 fed_model val loss 2.1640 val acc 21.3474 best val_acc 23.133117 te_acc 23.072240\n",
      "median: at LIE n_at 10 e 140 fed_model val loss 2.0650 val acc 22.6867 best val_acc 24.715909 te_acc 24.350649\n",
      "median: at LIE n_at 10 e 150 fed_model val loss 2.0239 val acc 26.4813 best val_acc 26.481331 te_acc 26.745130\n",
      "median: at LIE n_at 10 e 160 fed_model val loss 2.0348 val acc 24.8377 best val_acc 26.481331 te_acc 26.745130\n",
      "median: at LIE n_at 10 e 170 fed_model val loss 1.9925 val acc 26.9481 best val_acc 26.948052 te_acc 26.948052\n",
      "median: at LIE n_at 10 e 180 fed_model val loss 1.9291 val acc 30.4992 best val_acc 30.499188 te_acc 30.438312\n",
      "median: at LIE n_at 10 e 190 fed_model val loss 2.3420 val acc 14.9959 best val_acc 30.884740 te_acc 30.641234\n",
      "median: at LIE n_at 10 e 200 fed_model val loss 2.2682 val acc 17.0252 best val_acc 30.884740 te_acc 30.641234\n",
      "median: at LIE n_at 10 e 210 fed_model val loss 2.2393 val acc 14.0219 best val_acc 30.884740 te_acc 30.641234\n",
      "median: at LIE n_at 10 e 220 fed_model val loss 2.1252 val acc 18.4659 best val_acc 30.884740 te_acc 30.641234\n",
      "median: at LIE n_at 10 e 230 fed_model val loss 2.0951 val acc 19.8052 best val_acc 30.884740 te_acc 30.641234\n",
      "median: at LIE n_at 10 e 240 fed_model val loss 2.0132 val acc 24.5333 best val_acc 30.884740 te_acc 30.641234\n",
      "median: at LIE n_at 10 e 250 fed_model val loss 2.1119 val acc 21.2459 best val_acc 30.884740 te_acc 30.641234\n",
      "median: at LIE n_at 10 e 260 fed_model val loss 2.0306 val acc 23.1534 best val_acc 30.884740 te_acc 30.641234\n",
      "median: at LIE n_at 10 e 270 fed_model val loss 2.2468 val acc 15.1177 best val_acc 30.884740 te_acc 30.641234\n",
      "median: at LIE n_at 10 e 280 fed_model val loss 2.2470 val acc 16.4367 best val_acc 30.884740 te_acc 30.641234\n",
      "median: at LIE n_at 10 e 290 fed_model val loss 1.9262 val acc 25.7305 best val_acc 30.884740 te_acc 30.641234\n",
      "median: at LIE n_at 10 e 300 fed_model val loss 1.8710 val acc 29.1193 best val_acc 30.884740 te_acc 30.641234\n",
      "median: at LIE n_at 10 e 310 fed_model val loss 1.8656 val acc 30.0325 best val_acc 30.884740 te_acc 30.641234\n",
      "median: at LIE n_at 10 e 320 fed_model val loss 2.0717 val acc 20.8807 best val_acc 30.884740 te_acc 30.641234\n",
      "median: at LIE n_at 10 e 330 fed_model val loss 2.1041 val acc 20.0893 best val_acc 30.884740 te_acc 30.641234\n",
      "median: at LIE n_at 10 e 340 fed_model val loss 1.8549 val acc 30.2557 best val_acc 31.371753 te_acc 31.594968\n",
      "median: at LIE n_at 10 e 350 fed_model val loss 1.7518 val acc 34.1112 best val_acc 34.111201 te_acc 34.192370\n",
      "median: at LIE n_at 10 e 360 fed_model val loss 2.0502 val acc 23.5187 best val_acc 34.111201 te_acc 34.192370\n",
      "median: at LIE n_at 10 e 370 fed_model val loss 1.7687 val acc 34.1112 best val_acc 34.395292 te_acc 35.491071\n",
      "median: at LIE n_at 10 e 380 fed_model val loss 1.7051 val acc 36.2622 best val_acc 36.424513 te_acc 36.992695\n",
      "median: at LIE n_at 10 e 390 fed_model val loss 1.9466 val acc 27.2727 best val_acc 37.134740 te_acc 37.175325\n",
      "median: at LIE n_at 10 e 400 fed_model val loss 2.0278 val acc 26.2987 best val_acc 37.134740 te_acc 37.175325\n",
      "median: at LIE n_at 10 e 410 fed_model val loss 1.8109 val acc 33.7662 best val_acc 37.134740 te_acc 37.175325\n",
      "median: at LIE n_at 10 e 420 fed_model val loss 1.7822 val acc 33.8271 best val_acc 37.418831 te_acc 38.392857\n",
      "median: at LIE n_at 10 e 430 fed_model val loss 1.7719 val acc 36.4042 best val_acc 39.387175 te_acc 39.610390\n",
      "median: at LIE n_at 10 e 440 fed_model val loss 1.9725 val acc 30.2760 best val_acc 39.387175 te_acc 39.610390\n",
      "median: at LIE n_at 10 e 450 fed_model val loss 1.9509 val acc 26.3799 best val_acc 40.990260 te_acc 41.314935\n",
      "median: at LIE n_at 10 e 460 fed_model val loss 1.6689 val acc 39.6104 best val_acc 40.990260 te_acc 41.314935\n",
      "median: at LIE n_at 10 e 470 fed_model val loss 1.7083 val acc 39.1640 best val_acc 41.741071 te_acc 42.248377\n",
      "median: at LIE n_at 10 e 480 fed_model val loss 1.9377 val acc 29.0381 best val_acc 41.741071 te_acc 42.248377\n",
      "median: at LIE n_at 10 e 490 fed_model val loss 1.6600 val acc 39.0016 best val_acc 41.741071 te_acc 42.248377\n",
      "median: at LIE n_at 10 e 500 fed_model val loss 1.8205 val acc 31.1688 best val_acc 43.851461 te_acc 44.115260\n",
      "median: at LIE n_at 10 e 510 fed_model val loss 2.1643 val acc 25.6899 best val_acc 43.851461 te_acc 44.115260\n",
      "median: at LIE n_at 10 e 520 fed_model val loss 1.9186 val acc 31.4326 best val_acc 43.851461 te_acc 44.115260\n",
      "median: at LIE n_at 10 e 530 fed_model val loss 1.6605 val acc 37.2159 best val_acc 43.851461 te_acc 44.115260\n",
      "median: at LIE n_at 10 e 540 fed_model val loss 1.5367 val acc 43.6891 best val_acc 43.851461 te_acc 44.115260\n",
      "median: at LIE n_at 10 e 550 fed_model val loss 1.6241 val acc 41.2338 best val_acc 45.556006 te_acc 45.880682\n",
      "median: at LIE n_at 10 e 560 fed_model val loss 1.5314 val acc 42.9586 best val_acc 45.556006 te_acc 45.880682\n",
      "median: at LIE n_at 10 e 570 fed_model val loss 1.5695 val acc 42.0860 best val_acc 45.556006 te_acc 45.880682\n",
      "median: at LIE n_at 10 e 580 fed_model val loss 1.8339 val acc 37.3174 best val_acc 45.738636 te_acc 46.509740\n",
      "median: at LIE n_at 10 e 590 fed_model val loss 1.5683 val acc 43.6485 best val_acc 46.408279 te_acc 47.118506\n",
      "median: at LIE n_at 10 e 600 fed_model val loss 1.6000 val acc 40.0974 best val_acc 46.408279 te_acc 47.118506\n",
      "median: at LIE n_at 10 e 610 fed_model val loss 1.5751 val acc 43.2833 best val_acc 46.895292 te_acc 47.991071\n",
      "median: at LIE n_at 10 e 620 fed_model val loss 1.4335 val acc 47.9099 best val_acc 48.620130 te_acc 49.512987\n",
      "median: at LIE n_at 10 e 630 fed_model val loss 1.4922 val acc 46.7330 best val_acc 48.620130 te_acc 49.512987\n",
      "median: at LIE n_at 10 e 640 fed_model val loss 1.5128 val acc 43.6080 best val_acc 48.883929 te_acc 49.857955\n",
      "median: at LIE n_at 10 e 650 fed_model val loss 1.3732 val acc 49.9594 best val_acc 50.365260 te_acc 51.603084\n",
      "median: at LIE n_at 10 e 660 fed_model val loss 1.5794 val acc 42.4310 best val_acc 50.669643 te_acc 52.049513\n",
      "median: at LIE n_at 10 e 670 fed_model val loss 1.8723 val acc 37.0333 best val_acc 50.669643 te_acc 52.049513\n",
      "median: at LIE n_at 10 e 680 fed_model val loss 1.3920 val acc 50.1826 best val_acc 50.669643 te_acc 52.049513\n",
      "median: at LIE n_at 10 e 690 fed_model val loss 1.4416 val acc 48.4375 best val_acc 50.669643 te_acc 52.049513\n",
      "median: at LIE n_at 10 e 700 fed_model val loss 1.5717 val acc 43.2630 best val_acc 50.669643 te_acc 52.049513\n",
      "median: at LIE n_at 10 e 710 fed_model val loss 1.3526 val acc 50.8117 best val_acc 51.440747 te_acc 52.840909\n",
      "median: at LIE n_at 10 e 720 fed_model val loss 1.4170 val acc 47.9099 best val_acc 51.440747 te_acc 52.840909\n",
      "median: at LIE n_at 10 e 730 fed_model val loss 1.5376 val acc 45.5154 best val_acc 51.440747 te_acc 52.840909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median: at LIE n_at 10 e 740 fed_model val loss 1.2958 val acc 53.4903 best val_acc 53.713474 te_acc 54.646916\n",
      "median: at LIE n_at 10 e 750 fed_model val loss 1.2847 val acc 53.9570 best val_acc 53.956981 te_acc 55.357143\n",
      "median: at LIE n_at 10 e 760 fed_model val loss 1.2763 val acc 54.0787 best val_acc 54.078734 te_acc 55.560065\n",
      "median: at LIE n_at 10 e 770 fed_model val loss 1.2705 val acc 54.2411 best val_acc 54.241071 te_acc 55.986201\n",
      "median: at LIE n_at 10 e 780 fed_model val loss 1.2637 val acc 54.6266 best val_acc 54.626623 te_acc 56.351461\n",
      "val loss 21.384922 too high\n"
     ]
    }
   ],
   "source": [
    "batch_size=250\n",
    "resume=0\n",
    "nepochs=1200\n",
    "schedule=[1000]\n",
    "nbatches = user_tr_len//batch_size\n",
    "\n",
    "gamma=.5\n",
    "opt = 'sgd'\n",
    "fed_lr=0.5\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "aggregation='median'\n",
    "multi_k = False\n",
    "candidates = []\n",
    "\n",
    "at_type='LIE'\n",
    "z_values={3:0.69847, 5:0.7054, 8:0.71904, 10:0.72575, 12:0.73891}\n",
    "n_attackers=[10]\n",
    "\n",
    "arch='alexnet'\n",
    "chkpt='./'+aggregation\n",
    "\n",
    "for n_attacker in n_attackers:\n",
    "    epoch_num = 0\n",
    "    best_global_acc = 0\n",
    "    best_global_te_acc = 0\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    r=np.arange(user_tr_len)\n",
    "\n",
    "    fed_model, _ = return_model(arch, 0.1, 0.9, parallel=False)\n",
    "    optimizer_fed = SGD(fed_model.parameters(), lr=fed_lr)\n",
    "\n",
    "    while epoch_num <= nepochs:\n",
    "        user_grads=[]\n",
    "        if not epoch_num and epoch_num%nbatches == 0:\n",
    "            np.random.shuffle(r)\n",
    "            for i in range(nusers):\n",
    "                user_tr_data_tensors[i]=user_tr_data_tensors[i][r]\n",
    "                user_tr_label_tensors[i]=user_tr_label_tensors[i][r]\n",
    "\n",
    "        for i in range(nusers):\n",
    "\n",
    "            inputs = user_tr_data_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
    "            targets = user_tr_label_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
    "\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "            outputs = fed_model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            fed_model.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "\n",
    "            param_grad=[]\n",
    "            for param in fed_model.parameters():\n",
    "                param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
    "\n",
    "            user_grads=param_grad[None, :] if len(user_grads)==0 else torch.cat((user_grads,param_grad[None,:]), 0)\n",
    "\n",
    "        if epoch_num in schedule:\n",
    "            for param_group in optimizer_fed.param_groups:\n",
    "                param_group['lr'] *= gamma\n",
    "                print('New learnin rate ', param_group['lr'])\n",
    "\n",
    "        if n_attacker > 0:\n",
    "            if at_type == 'lie':\n",
    "                mal_update = lie_attack(user_grads[:n_attacker], z_values[n_attacker])\n",
    "                mal_updates = torch.cat((torch.stack([mal_update]*n_attacker), malicious_grads))\n",
    "            elif at_type == 'fang':\n",
    "                mal_updates = fang_attack_trmean_partial(user_grads[:n_attacker], n_attacker)\n",
    "\n",
    "        malicious_grads = torch.cat((mal_updates, user_grads[n_attacker:]))\n",
    "        \n",
    "        if not epoch_num : \n",
    "            print(malicious_grads.shape)\n",
    "\n",
    "        agg_grads=torch.median(malicious_grads,dim=0)[0]\n",
    "\n",
    "        del user_grads\n",
    "\n",
    "        start_idx=0\n",
    "\n",
    "        optimizer_fed.zero_grad()\n",
    "\n",
    "        model_grads=[]\n",
    "\n",
    "        for i, param in enumerate(fed_model.parameters()):\n",
    "            param_=agg_grads[start_idx:start_idx+len(param.data.view(-1))].reshape(param.data.shape)\n",
    "            start_idx=start_idx+len(param.data.view(-1))\n",
    "            param_=param_.cuda()\n",
    "            model_grads.append(param_)\n",
    "\n",
    "        optimizer_fed.step(model_grads)\n",
    "\n",
    "        val_loss, val_acc = test(val_data_tensor,val_label_tensor,fed_model,criterion,use_cuda)\n",
    "        te_loss, te_acc = test(te_data_tensor,te_label_tensor, fed_model, criterion, use_cuda)\n",
    "\n",
    "        is_best = best_global_acc < val_acc\n",
    "\n",
    "        best_global_acc = max(best_global_acc, val_acc)\n",
    "\n",
    "        if is_best:\n",
    "            best_global_te_acc = te_acc\n",
    "\n",
    "        if epoch_num%10==0 or epoch_num==nepochs-1:\n",
    "            print('%s: at %s n_at %d e %d fed_model val loss %.4f val acc %.4f best val_acc %f te_acc %f'%(aggregation, at_type, n_attacker, epoch_num, val_loss, val_acc, best_global_acc,best_global_te_acc))\n",
    "\n",
    "        if val_loss > 10:\n",
    "            print('val loss %f too high'%val_loss)\n",
    "            break\n",
    "\n",
    "        epoch_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for our AGR-tailored attack on Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def our_attack_median(all_updates, model_re, n_attackers, dev_type='unit_vec', threshold=30):\n",
    "\n",
    "    if dev_type == 'unit_vec':\n",
    "        deviation = model_re / torch.norm(model_re)  # unit vector, dir opp to good dir\n",
    "    elif dev_type == 'sign':\n",
    "        deviation = torch.sign(model_re)\n",
    "    elif dev_type == 'std':\n",
    "        deviation = torch.std(all_updates, 0)\n",
    "\n",
    "    lamda = torch.Tensor([threshold]).cuda() #compute_lambda_our(all_updates, model_re, n_attackers)\n",
    "\n",
    "    threshold_diff = 1e-5\n",
    "    prev_loss = -1\n",
    "    lamda_fail = lamda\n",
    "    lamda_succ = 0\n",
    "    iters = 0 \n",
    "    while torch.abs(lamda_succ - lamda) > threshold_diff:\n",
    "        mal_update = (model_re - lamda * deviation)\n",
    "        mal_updates = torch.stack([mal_update] * n_attackers)\n",
    "        mal_updates = torch.cat((mal_updates, all_updates), 0)\n",
    "\n",
    "        agg_grads = torch.median(mal_updates, 0)[0]\n",
    "        \n",
    "        loss = torch.norm(agg_grads - model_re)\n",
    "        \n",
    "        if prev_loss < loss:\n",
    "            lamda_succ = lamda\n",
    "            lamda = lamda + lamda_fail / 2\n",
    "        else:\n",
    "            lamda = lamda - lamda_fail / 2\n",
    "\n",
    "        lamda_fail = lamda_fail / 2\n",
    "        prev_loss = loss\n",
    "        \n",
    "    mal_update = (model_re - lamda_succ * deviation)\n",
    "    return mal_update\n",
    "    mal_updates = torch.stack([mal_update] * n_attackers)\n",
    "    mal_updates = torch.cat((mal_updates, all_updates), 0)\n",
    "\n",
    "    return mal_updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 2472266])\n",
      "median: at our-agr n_at 10 e 0 fed_model val loss 2.3024 val acc 10.3287 best val_acc 10.328734 te_acc 9.618506\n",
      "median: at our-agr n_at 10 e 25 fed_model val loss 2.2805 val acc 11.1607 best val_acc 20.434253 te_acc 20.921266\n",
      "median: at our-agr n_at 10 e 50 fed_model val loss 2.1633 val acc 18.3239 best val_acc 20.434253 te_acc 20.921266\n",
      "median: at our-agr n_at 10 e 75 fed_model val loss 2.2596 val acc 13.5349 best val_acc 20.576299 te_acc 20.677760\n",
      "median: at our-agr n_at 10 e 100 fed_model val loss 2.1557 val acc 22.1591 best val_acc 22.159091 te_acc 21.915584\n",
      "median: at our-agr n_at 10 e 125 fed_model val loss 2.2116 val acc 18.2021 best val_acc 24.573864 te_acc 24.614448\n",
      "median: at our-agr n_at 10 e 150 fed_model val loss 2.4119 val acc 15.7062 best val_acc 24.573864 te_acc 24.614448\n",
      "median: at our-agr n_at 10 e 175 fed_model val loss 2.1056 val acc 22.5446 best val_acc 24.573864 te_acc 24.614448\n",
      "median: at our-agr n_at 10 e 200 fed_model val loss 2.3313 val acc 10.2476 best val_acc 24.573864 te_acc 24.614448\n",
      "median: at our-agr n_at 10 e 225 fed_model val loss 2.0693 val acc 24.1274 best val_acc 24.573864 te_acc 24.614448\n",
      "median: at our-agr n_at 10 e 250 fed_model val loss 2.1649 val acc 17.0860 best val_acc 24.573864 te_acc 24.614448\n",
      "median: at our-agr n_at 10 e 275 fed_model val loss 2.1535 val acc 20.6169 best val_acc 24.776786 te_acc 24.249188\n",
      "median: at our-agr n_at 10 e 300 fed_model val loss 2.0889 val acc 19.9067 best val_acc 25.000000 te_acc 24.472403\n",
      "median: at our-agr n_at 10 e 325 fed_model val loss 2.1036 val acc 21.8547 best val_acc 25.771104 te_acc 25.162338\n",
      "median: at our-agr n_at 10 e 350 fed_model val loss 2.1006 val acc 19.7849 best val_acc 25.771104 te_acc 25.162338\n",
      "median: at our-agr n_at 10 e 375 fed_model val loss 2.3000 val acc 12.1956 best val_acc 25.771104 te_acc 25.162338\n",
      "median: at our-agr n_at 10 e 400 fed_model val loss 2.2890 val acc 11.9115 best val_acc 25.771104 te_acc 25.162338\n",
      "median: at our-agr n_at 10 e 425 fed_model val loss 2.1747 val acc 17.1469 best val_acc 25.771104 te_acc 25.162338\n",
      "median: at our-agr n_at 10 e 450 fed_model val loss 2.0077 val acc 25.6899 best val_acc 25.953734 te_acc 26.826299\n",
      "median: at our-agr n_at 10 e 475 fed_model val loss 2.1102 val acc 20.0487 best val_acc 26.866883 te_acc 26.501623\n",
      "median: at our-agr n_at 10 e 500 fed_model val loss 2.1612 val acc 18.5268 best val_acc 26.866883 te_acc 26.501623\n",
      "median: at our-agr n_at 10 e 525 fed_model val loss 2.1400 val acc 18.6688 best val_acc 26.866883 te_acc 26.501623\n",
      "median: at our-agr n_at 10 e 550 fed_model val loss 2.0107 val acc 25.7102 best val_acc 26.866883 te_acc 26.501623\n",
      "median: at our-agr n_at 10 e 575 fed_model val loss 2.1552 val acc 17.4513 best val_acc 26.866883 te_acc 26.501623\n",
      "median: at our-agr n_at 10 e 600 fed_model val loss 2.3038 val acc 10.2476 best val_acc 26.866883 te_acc 26.501623\n",
      "median: at our-agr n_at 10 e 625 fed_model val loss 2.3027 val acc 10.2881 best val_acc 26.866883 te_acc 26.501623\n",
      "median: at our-agr n_at 10 e 650 fed_model val loss 2.3028 val acc 10.2881 best val_acc 26.866883 te_acc 26.501623\n",
      "median: at our-agr n_at 10 e 675 fed_model val loss 2.3028 val acc 10.2881 best val_acc 26.866883 te_acc 26.501623\n",
      "median: at our-agr n_at 10 e 700 fed_model val loss 2.3028 val acc 10.2881 best val_acc 26.866883 te_acc 26.501623\n",
      "median: at our-agr n_at 10 e 725 fed_model val loss 2.3028 val acc 10.2881 best val_acc 26.866883 te_acc 26.501623\n",
      "median: at our-agr n_at 10 e 750 fed_model val loss 2.3027 val acc 10.2881 best val_acc 26.866883 te_acc 26.501623\n",
      "median: at our-agr n_at 10 e 775 fed_model val loss 2.3028 val acc 10.2881 best val_acc 26.866883 te_acc 26.501623\n",
      "median: at our-agr n_at 10 e 800 fed_model val loss 2.3028 val acc 10.2881 best val_acc 26.866883 te_acc 26.501623\n",
      "median: at our-agr n_at 10 e 825 fed_model val loss 2.3028 val acc 10.2881 best val_acc 26.866883 te_acc 26.501623\n",
      "median: at our-agr n_at 10 e 850 fed_model val loss 2.3027 val acc 10.2881 best val_acc 26.866883 te_acc 26.501623\n",
      "median: at our-agr n_at 10 e 875 fed_model val loss 2.3028 val acc 10.2881 best val_acc 26.866883 te_acc 26.501623\n",
      "median: at our-agr n_at 10 e 900 fed_model val loss 2.3028 val acc 10.2881 best val_acc 26.866883 te_acc 26.501623\n",
      "median: at our-agr n_at 10 e 925 fed_model val loss 2.3028 val acc 10.2881 best val_acc 26.866883 te_acc 26.501623\n",
      "median: at our-agr n_at 10 e 950 fed_model val loss 2.3026 val acc 10.2881 best val_acc 26.866883 te_acc 26.501623\n",
      "median: at our-agr n_at 10 e 975 fed_model val loss 2.3028 val acc 9.7606 best val_acc 26.866883 te_acc 26.501623\n",
      "New learnin rate  0.25\n",
      "median: at our-agr n_at 10 e 1000 fed_model val loss 2.3028 val acc 10.2881 best val_acc 26.866883 te_acc 26.501623\n",
      "median: at our-agr n_at 10 e 1025 fed_model val loss 2.3027 val acc 10.2881 best val_acc 26.866883 te_acc 26.501623\n",
      "median: at our-agr n_at 10 e 1050 fed_model val loss 2.3026 val acc 10.2881 best val_acc 26.866883 te_acc 26.501623\n",
      "median: at our-agr n_at 10 e 1075 fed_model val loss 2.3028 val acc 10.2881 best val_acc 26.866883 te_acc 26.501623\n",
      "median: at our-agr n_at 10 e 1100 fed_model val loss 2.3027 val acc 10.2881 best val_acc 26.866883 te_acc 26.501623\n",
      "median: at our-agr n_at 10 e 1125 fed_model val loss 2.3028 val acc 10.2881 best val_acc 26.866883 te_acc 26.501623\n",
      "median: at our-agr n_at 10 e 1150 fed_model val loss 2.3026 val acc 10.2881 best val_acc 26.866883 te_acc 26.501623\n",
      "median: at our-agr n_at 10 e 1175 fed_model val loss 2.3028 val acc 9.7606 best val_acc 26.866883 te_acc 26.501623\n",
      "median: at our-agr n_at 10 e 1199 fed_model val loss 2.3028 val acc 9.7606 best val_acc 26.866883 te_acc 26.501623\n",
      "median: at our-agr n_at 10 e 1200 fed_model val loss 2.3027 val acc 10.2881 best val_acc 26.866883 te_acc 26.501623\n"
     ]
    }
   ],
   "source": [
    "batch_size=250\n",
    "resume=0\n",
    "nepochs=1200\n",
    "schedule=[1000]\n",
    "nbatches = user_tr_len//batch_size\n",
    "\n",
    "gamma=.5\n",
    "opt = 'sgd'\n",
    "fed_lr=0.5\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "aggregation='median'\n",
    "multi_k = False\n",
    "candidates = []\n",
    "\n",
    "at_type='our-agr'\n",
    "dev_type = 'std'\n",
    "threshold=10\n",
    "n_attackers=[10]\n",
    "partial_attackers = {4:1, 5:1, 8:2, 10:3, 12:4}\n",
    "\n",
    "arch='alexnet'\n",
    "chkpt='./'+aggregation\n",
    "\n",
    "for n_attacker in n_attackers:\n",
    "    epoch_num = 0\n",
    "    best_global_acc = 0\n",
    "    best_global_te_acc = 0\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    r=np.arange(user_tr_len)\n",
    "\n",
    "    fed_model, _ = return_model(arch, 0.1, 0.9, parallel=False)\n",
    "    optimizer_fed = SGD(fed_model.parameters(), lr=fed_lr)\n",
    "\n",
    "    while epoch_num <= nepochs:\n",
    "        user_grads=[]\n",
    "        if not epoch_num and epoch_num%nbatches == 0:\n",
    "            np.random.shuffle(r)\n",
    "            for i in range(nusers):\n",
    "                user_tr_data_tensors[i]=user_tr_data_tensors[i][r]\n",
    "                user_tr_label_tensors[i]=user_tr_label_tensors[i][r]\n",
    "\n",
    "        for i in range(nusers):\n",
    "\n",
    "            inputs = user_tr_data_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
    "            targets = user_tr_label_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
    "\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "            outputs = fed_model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            fed_model.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "\n",
    "            param_grad=[]\n",
    "            for param in fed_model.parameters():\n",
    "                param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
    "\n",
    "            user_grads=param_grad[None, :] if len(user_grads)==0 else torch.cat((user_grads,param_grad[None,:]), 0)\n",
    "\n",
    "        if epoch_num in schedule:\n",
    "            for param_group in optimizer_fed.param_groups:\n",
    "                param_group['lr'] *= gamma\n",
    "                print('New learnin rate ', param_group['lr'])\n",
    "\n",
    "        if n_attacker > 0:\n",
    "            if at_type == 'lie':\n",
    "                mal_update = lie_attack(user_grads[:n_attacker], z_values[n_attacker])\n",
    "                mal_updates = torch.cat((torch.stack([mal_update]*n_attacker), malicious_grads))\n",
    "            elif at_type == 'our-agr':\n",
    "                n_attacker_ = partial_attackers[n_attacker]\n",
    "                agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "                mal_update = our_attack_median(user_grads[:n_attacker], agg_grads, n_attacker_, threshold=threshold, dev_type=dev_type)\n",
    "                mal_updates = torch.stack([mal_update]*n_attacker)\n",
    "                \n",
    "        malicious_grads = torch.cat((mal_updates, user_grads[n_attacker:]))\n",
    "        \n",
    "        if not epoch_num :  print(malicious_grads.shape)\n",
    "\n",
    "        agg_grads=torch.median(malicious_grads,dim=0)[0]\n",
    "\n",
    "        del user_grads\n",
    "\n",
    "        start_idx=0\n",
    "\n",
    "        optimizer_fed.zero_grad()\n",
    "\n",
    "        model_grads=[]\n",
    "\n",
    "        for i, param in enumerate(fed_model.parameters()):\n",
    "            param_=agg_grads[start_idx:start_idx+len(param.data.view(-1))].reshape(param.data.shape)\n",
    "            start_idx=start_idx+len(param.data.view(-1))\n",
    "            param_=param_.cuda()\n",
    "            model_grads.append(param_)\n",
    "\n",
    "        optimizer_fed.step(model_grads)\n",
    "\n",
    "        val_loss, val_acc = test(val_data_tensor,val_label_tensor,fed_model,criterion,use_cuda)\n",
    "        te_loss, te_acc = test(te_data_tensor,te_label_tensor, fed_model, criterion, use_cuda)\n",
    "\n",
    "        is_best = best_global_acc < val_acc\n",
    "\n",
    "        best_global_acc = max(best_global_acc, val_acc)\n",
    "\n",
    "        if is_best:\n",
    "            best_global_te_acc = te_acc\n",
    "\n",
    "        if epoch_num%25==0 or epoch_num==nepochs-1:\n",
    "            print('%s: at %s n_at %d e %d fed_model val loss %.4f val acc %.4f best val_acc %f te_acc %f'%(aggregation, at_type, n_attacker, epoch_num, val_loss, val_acc, best_global_acc,best_global_te_acc))\n",
    "\n",
    "        if val_loss > 10:\n",
    "            print('val loss %f too high'%val_loss)\n",
    "            break\n",
    "\n",
    "        epoch_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for our first AGR-agnostic attack - Min-max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "MIN-MAX attack\n",
    "'''\n",
    "def our_attack_dist(all_updates, model_re, n_attackers, dev_type='unit_vec', threshold=30):\n",
    "\n",
    "    if dev_type == 'unit_vec':\n",
    "        deviation = model_re / torch.norm(model_re)  # unit vector, dir opp to good dir\n",
    "    elif dev_type == 'sign':\n",
    "        deviation = torch.sign(model_re)\n",
    "    elif dev_type == 'std':\n",
    "        deviation = torch.std(all_updates, 0)\n",
    "\n",
    "    lamda = torch.Tensor([threshold]).float().cuda()\n",
    "    # print(lamda)\n",
    "    threshold_diff = 1e-5\n",
    "    lamda_fail = lamda\n",
    "    lamda_succ = 0\n",
    "    \n",
    "    distances = []\n",
    "    for update in all_updates:\n",
    "        distance = torch.norm((all_updates - update), dim=1) ** 2\n",
    "        distances = distance[None, :] if not len(distances) else torch.cat((distances, distance[None, :]), 0)\n",
    "    \n",
    "    max_distance = torch.max(distances)\n",
    "    del distances\n",
    "\n",
    "    while torch.abs(lamda_succ - lamda) > threshold_diff:\n",
    "        mal_update = (model_re - lamda * deviation)\n",
    "        distance = torch.norm((all_updates - mal_update), dim=1) ** 2\n",
    "        max_d = torch.max(distance)\n",
    "        \n",
    "        if max_d <= max_distance:\n",
    "            # print('successful lamda is ', lamda)\n",
    "            lamda_succ = lamda\n",
    "            lamda = lamda + lamda_fail / 2\n",
    "        else:\n",
    "            lamda = lamda - lamda_fail / 2\n",
    "\n",
    "        lamda_fail = lamda_fail / 2\n",
    "\n",
    "    mal_update = (model_re - lamda_succ * deviation)\n",
    "    \n",
    "    return mal_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious_grads shape  torch.Size([50, 2472266])\n",
      "median: at min-max n_at 10 | e 0 fed_model val loss 2.3024 val acc 9.7606 best val_acc 9.760552 te_acc 9.557630\n",
      "median: at min-max n_at 10 | e 25 fed_model val loss 2.3020 val acc 11.1404 best val_acc 23.234578 te_acc 23.741883\n",
      "median: at min-max n_at 10 | e 50 fed_model val loss 2.2817 val acc 8.4213 best val_acc 23.234578 te_acc 23.741883\n",
      "median: at min-max n_at 10 | e 75 fed_model val loss 2.2948 val acc 13.4740 best val_acc 23.234578 te_acc 23.741883\n",
      "median: at min-max n_at 10 | e 100 fed_model val loss 2.3046 val acc 9.7606 best val_acc 23.234578 te_acc 23.741883\n",
      "median: at min-max n_at 10 | e 125 fed_model val loss 2.1790 val acc 15.0162 best val_acc 23.234578 te_acc 23.741883\n",
      "median: at min-max n_at 10 | e 150 fed_model val loss 2.1026 val acc 18.6891 best val_acc 23.234578 te_acc 23.741883\n",
      "median: at min-max n_at 10 | e 175 fed_model val loss 2.3584 val acc 10.7143 best val_acc 23.234578 te_acc 23.741883\n",
      "median: at min-max n_at 10 | e 200 fed_model val loss 2.1909 val acc 15.7670 best val_acc 23.234578 te_acc 23.741883\n",
      "median: at min-max n_at 10 | e 225 fed_model val loss 2.2256 val acc 14.7321 best val_acc 24.127435 te_acc 24.492695\n",
      "median: at min-max n_at 10 | e 250 fed_model val loss 2.2035 val acc 14.6713 best val_acc 24.127435 te_acc 24.492695\n",
      "median: at min-max n_at 10 | e 275 fed_model val loss 2.0480 val acc 21.6721 best val_acc 24.452110 te_acc 24.837662\n",
      "median: at min-max n_at 10 | e 300 fed_model val loss 2.1347 val acc 18.7906 best val_acc 27.150974 te_acc 28.226461\n",
      "median: at min-max n_at 10 | e 325 fed_model val loss 2.1441 val acc 20.3734 best val_acc 27.698864 te_acc 28.368506\n",
      "median: at min-max n_at 10 | e 350 fed_model val loss 2.1128 val acc 18.7703 best val_acc 27.698864 te_acc 28.368506\n",
      "median: at min-max n_at 10 | e 375 fed_model val loss 2.0139 val acc 24.3506 best val_acc 27.698864 te_acc 28.368506\n",
      "median: at min-max n_at 10 | e 400 fed_model val loss 2.1127 val acc 18.7703 best val_acc 27.698864 te_acc 28.368506\n",
      "median: at min-max n_at 10 | e 425 fed_model val loss 2.2837 val acc 13.7784 best val_acc 27.698864 te_acc 28.368506\n",
      "median: at min-max n_at 10 | e 450 fed_model val loss 2.0162 val acc 21.5097 best val_acc 27.698864 te_acc 28.368506\n",
      "median: at min-max n_at 10 | e 475 fed_model val loss 2.1715 val acc 17.8166 best val_acc 28.368506 te_acc 29.342532\n",
      "median: at min-max n_at 10 | e 500 fed_model val loss 2.2571 val acc 11.6071 best val_acc 28.368506 te_acc 29.342532\n",
      "median: at min-max n_at 10 | e 525 fed_model val loss 2.0510 val acc 20.7995 best val_acc 28.368506 te_acc 29.342532\n",
      "median: at min-max n_at 10 | e 550 fed_model val loss 2.1491 val acc 20.6778 best val_acc 28.368506 te_acc 29.342532\n",
      "median: at min-max n_at 10 | e 575 fed_model val loss 2.0754 val acc 19.9067 best val_acc 28.368506 te_acc 29.342532\n",
      "median: at min-max n_at 10 | e 600 fed_model val loss 2.3534 val acc 10.2476 best val_acc 28.368506 te_acc 29.342532\n",
      "median: at min-max n_at 10 | e 625 fed_model val loss 2.3060 val acc 9.1721 best val_acc 28.368506 te_acc 29.342532\n",
      "median: at min-max n_at 10 | e 650 fed_model val loss 2.3030 val acc 10.1055 best val_acc 28.368506 te_acc 29.342532\n",
      "median: at min-max n_at 10 | e 675 fed_model val loss 2.3168 val acc 12.5000 best val_acc 28.368506 te_acc 29.342532\n",
      "median: at min-max n_at 10 | e 700 fed_model val loss 2.2713 val acc 14.2248 best val_acc 28.368506 te_acc 29.342532\n",
      "median: at min-max n_at 10 | e 725 fed_model val loss 2.5187 val acc 9.8214 best val_acc 28.368506 te_acc 29.342532\n",
      "median: at min-max n_at 10 | e 750 fed_model val loss 2.3502 val acc 13.4943 best val_acc 28.368506 te_acc 29.342532\n",
      "median: at min-max n_at 10 | e 775 fed_model val loss 2.3018 val acc 10.3287 best val_acc 28.368506 te_acc 29.342532\n",
      "median: at min-max n_at 10 | e 800 fed_model val loss 2.3083 val acc 10.0446 best val_acc 28.368506 te_acc 29.342532\n",
      "median: at min-max n_at 10 | e 825 fed_model val loss 2.3024 val acc 10.0649 best val_acc 28.368506 te_acc 29.342532\n",
      "median: at min-max n_at 10 | e 850 fed_model val loss 2.3024 val acc 9.6388 best val_acc 28.368506 te_acc 29.342532\n",
      "median: at min-max n_at 10 | e 875 fed_model val loss 2.3024 val acc 9.8620 best val_acc 28.368506 te_acc 29.342532\n",
      "median: at min-max n_at 10 | e 900 fed_model val loss 2.3022 val acc 10.0446 best val_acc 28.368506 te_acc 29.342532\n",
      "median: at min-max n_at 10 | e 925 fed_model val loss 2.3019 val acc 10.0852 best val_acc 28.368506 te_acc 29.342532\n",
      "median: at min-max n_at 10 | e 950 fed_model val loss 2.3030 val acc 10.2476 best val_acc 28.368506 te_acc 29.342532\n",
      "median: at min-max n_at 10 | e 975 fed_model val loss 2.3029 val acc 9.7606 best val_acc 28.368506 te_acc 29.342532\n",
      "New learnin rate  0.25\n",
      "median: at min-max n_at 10 | e 1000 fed_model val loss 2.3029 val acc 9.9635 best val_acc 28.368506 te_acc 29.342532\n",
      "median: at min-max n_at 10 | e 1025 fed_model val loss 2.3029 val acc 9.9635 best val_acc 28.368506 te_acc 29.342532\n",
      "median: at min-max n_at 10 | e 1050 fed_model val loss 2.3028 val acc 9.9635 best val_acc 28.368506 te_acc 29.342532\n",
      "median: at min-max n_at 10 | e 1075 fed_model val loss 2.3029 val acc 9.7606 best val_acc 28.368506 te_acc 29.342532\n",
      "median: at min-max n_at 10 | e 1100 fed_model val loss 2.3029 val acc 9.9635 best val_acc 28.368506 te_acc 29.342532\n",
      "median: at min-max n_at 10 | e 1125 fed_model val loss 2.3029 val acc 9.9635 best val_acc 28.368506 te_acc 29.342532\n",
      "median: at min-max n_at 10 | e 1150 fed_model val loss 2.3029 val acc 9.9635 best val_acc 28.368506 te_acc 29.342532\n",
      "median: at min-max n_at 10 | e 1175 fed_model val loss 2.3029 val acc 9.7606 best val_acc 28.368506 te_acc 29.342532\n",
      "median: at min-max n_at 10 | e 1199 fed_model val loss 2.3029 val acc 9.7606 best val_acc 28.368506 te_acc 29.342532\n",
      "median: at min-max n_at 10 | e 1200 fed_model val loss 2.3029 val acc 9.9635 best val_acc 28.368506 te_acc 29.342532\n"
     ]
    }
   ],
   "source": [
    "batch_size=250\n",
    "resume=0\n",
    "nepochs=1200\n",
    "schedule=[1000]\n",
    "nbatches = user_tr_len//batch_size\n",
    "\n",
    "gamma=.5\n",
    "opt = 'sgd'\n",
    "fed_lr=0.5\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "aggregation='median'\n",
    "multi_k = False\n",
    "candidates = []\n",
    "\n",
    "at_type='min-max'\n",
    "dev_type ='std'\n",
    "threshold=10\n",
    "n_attackers=[10]\n",
    "\n",
    "arch='alexnet'\n",
    "chkpt='./'+aggregation\n",
    "\n",
    "for n_attacker in n_attackers:\n",
    "    candidates = []\n",
    "\n",
    "    epoch_num = 0\n",
    "    best_global_acc = 0\n",
    "    best_global_te_acc = 0\n",
    "\n",
    "    fed_model, _ = return_model(arch, 0.1, 0.9, parallel=False)\n",
    "    optimizer_fed = SGD(fed_model.parameters(), lr=fed_lr)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    r=np.arange(user_tr_len)\n",
    "\n",
    "    while epoch_num <= nepochs:\n",
    "        user_grads=[]\n",
    "        if not epoch_num and epoch_num%nbatches == 0:\n",
    "            np.random.shuffle(r)\n",
    "            for i in range(nusers):\n",
    "                user_tr_data_tensors[i]=user_tr_data_tensors[i][r]\n",
    "                user_tr_label_tensors[i]=user_tr_label_tensors[i][r]\n",
    "\n",
    "        for i in range(n_attacker, nusers):\n",
    "\n",
    "            inputs = user_tr_data_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
    "            targets = user_tr_label_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
    "\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "            outputs = fed_model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            fed_model.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "\n",
    "            param_grad=[]\n",
    "            for param in fed_model.parameters():\n",
    "                param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
    "\n",
    "            user_grads=param_grad[None, :] if len(user_grads)==0 else torch.cat((user_grads,param_grad[None,:]), 0)\n",
    "\n",
    "        if epoch_num in schedule:\n",
    "            for param_group in optimizer_fed.param_groups:\n",
    "                param_group['lr'] *= gamma\n",
    "                print('New learnin rate ', param_group['lr'])\n",
    "\n",
    "        if n_attacker > 0:\n",
    "            if at_type == 'lie':\n",
    "                mal_update = lie_attack(user_grads[:n_attacker], z_values[n_attacker])\n",
    "            elif at_type == 'fang':\n",
    "                mal_updates = fang_attack_trmean_partial(user_grads[:n_attacker], n_attacker)\n",
    "            elif at_type == 'our-agr':\n",
    "                n_attacker_ = partial_attackers[n_attacker]\n",
    "                agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "                mal_update = our_attack_median(user_grads[:n_attacker], agg_grads, n_attacker_, threshold=threshold, dev_type=dev_type)\n",
    "            elif at_type == 'min-max':\n",
    "                n_attacker_ = partial_attackers[n_attacker]\n",
    "                agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "                mal_update = our_attack_dist(user_grads[:n_attacker], agg_grads, n_attacker_, threshold=threshold, dev_type=dev_type)\n",
    "            elif at_type == 'min-sum':\n",
    "                n_attacker_ = partial_attackers[n_attacker]\n",
    "                agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "                mal_update = our_attack_score(user_grads[:n_attacker], agg_grads, n_attacker_, threshold=threshold, dev_type=dev_type)\n",
    "\n",
    "            mal_updates = torch.stack([mal_update] * n_attacker)\n",
    "            malicious_grads = torch.cat((mal_updates, user_grads), 0)\n",
    "\n",
    "        if epoch_num==0: print('malicious_grads shape ', malicious_grads.shape)\n",
    "\n",
    "        agg_grads=torch.median(malicious_grads,dim=0)[0]\n",
    "\n",
    "        del user_grads\n",
    "\n",
    "        start_idx=0\n",
    "\n",
    "        optimizer_fed.zero_grad()\n",
    "\n",
    "        model_grads=[]\n",
    "\n",
    "        for i, param in enumerate(fed_model.parameters()):\n",
    "            param_=agg_grads[start_idx:start_idx+len(param.data.view(-1))].reshape(param.data.shape)\n",
    "            start_idx=start_idx+len(param.data.view(-1))\n",
    "            param_=param_.cuda()\n",
    "            model_grads.append(param_)\n",
    "\n",
    "        optimizer_fed.step(model_grads)\n",
    "\n",
    "        val_loss, val_acc = test(val_data_tensor,val_label_tensor,fed_model,criterion,use_cuda)\n",
    "        te_loss, te_acc = test(te_data_tensor,te_label_tensor, fed_model, criterion, use_cuda)\n",
    "\n",
    "        is_best = best_global_acc < val_acc\n",
    "\n",
    "        best_global_acc = max(best_global_acc, val_acc)\n",
    "\n",
    "        if is_best:\n",
    "            best_global_te_acc = te_acc\n",
    "\n",
    "        if epoch_num%25==0 or epoch_num==nepochs-1:\n",
    "            print('%s: at %s n_at %d | e %d fed_model val loss %.4f val acc %.4f best val_acc %f te_acc %f'%(aggregation, at_type, n_attacker, epoch_num, val_loss, val_acc, best_global_acc,best_global_te_acc))\n",
    "\n",
    "        if val_loss > 1000:\n",
    "            print('val loss %f too high'%val_loss)\n",
    "            break\n",
    "            \n",
    "        epoch_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for our second AGR-agnostic attack - Min-sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "MIN-SUM attack\n",
    "'''\n",
    "\n",
    "def our_attack_score(all_updates, model_re, n_attackers, dev_type='unit_vec', threshold=30):\n",
    "\n",
    "    if dev_type == 'unit_vec':\n",
    "        deviation = model_re / torch.norm(model_re)  # unit vector, dir opp to good dir\n",
    "    elif dev_type == 'sign':\n",
    "        deviation = torch.sign(model_re)\n",
    "    elif dev_type == 'std':\n",
    "        deviation = torch.std(all_updates, 0)\n",
    "    \n",
    "    lamda = torch.Tensor([threshold]).float().cuda()\n",
    "    # print(lamda)\n",
    "    threshold_diff = 1e-5\n",
    "    lamda_fail = lamda\n",
    "    lamda_succ = 0\n",
    "    \n",
    "    distances = []\n",
    "    for update in all_updates:\n",
    "        distance = torch.norm((all_updates - update), dim=1) ** 2\n",
    "        distances = distance[None, :] if not len(distances) else torch.cat((distances, distance[None, :]), 0)\n",
    "    \n",
    "    scores = torch.sum(distances, dim=1)\n",
    "    min_score = torch.min(scores)\n",
    "    del distances\n",
    "\n",
    "    while torch.abs(lamda_succ - lamda) > threshold_diff:\n",
    "        mal_update = (model_re - lamda * deviation)\n",
    "        distance = torch.norm((all_updates - mal_update), dim=1) ** 2\n",
    "        score = torch.sum(distance)\n",
    "        \n",
    "        if score <= min_score:\n",
    "            # print('successful lamda is ', lamda)\n",
    "            lamda_succ = lamda\n",
    "            lamda = lamda + lamda_fail / 2\n",
    "        else:\n",
    "            lamda = lamda - lamda_fail / 2\n",
    "\n",
    "        lamda_fail = lamda_fail / 2\n",
    "\n",
    "    # print(lamda_succ)\n",
    "    mal_update = (model_re - lamda_succ * deviation)\n",
    "    \n",
    "    return mal_update\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious_grads shape  torch.Size([60, 2472266])\n",
      "median: at min-sum n_at 10 | e 0 fed_model val loss 2.3026 val acc 11.2216 best val_acc 11.221591 te_acc 11.525974\n",
      "median: at min-sum n_at 10 | e 10 fed_model val loss 2.2894 val acc 15.8888 best val_acc 17.451299 te_acc 18.222403\n",
      "median: at min-sum n_at 10 | e 20 fed_model val loss 2.3073 val acc 9.7200 best val_acc 21.185065 te_acc 20.880682\n",
      "median: at min-sum n_at 10 | e 30 fed_model val loss 2.2310 val acc 16.8019 best val_acc 21.185065 te_acc 20.880682\n",
      "median: at min-sum n_at 10 | e 40 fed_model val loss 2.3030 val acc 10.2273 best val_acc 21.185065 te_acc 20.880682\n",
      "median: at min-sum n_at 10 | e 50 fed_model val loss 2.3009 val acc 14.6104 best val_acc 21.185065 te_acc 20.880682\n",
      "median: at min-sum n_at 10 | e 60 fed_model val loss 2.2903 val acc 14.6510 best val_acc 21.185065 te_acc 20.880682\n",
      "median: at min-sum n_at 10 | e 70 fed_model val loss 2.1752 val acc 17.0252 best val_acc 21.185065 te_acc 20.880682\n",
      "median: at min-sum n_at 10 | e 80 fed_model val loss 2.1361 val acc 17.9789 best val_acc 21.185065 te_acc 20.880682\n",
      "median: at min-sum n_at 10 | e 90 fed_model val loss 2.1370 val acc 19.2370 best val_acc 21.185065 te_acc 20.880682\n",
      "median: at min-sum n_at 10 | e 100 fed_model val loss 2.3435 val acc 9.7403 best val_acc 21.185065 te_acc 20.880682\n",
      "median: at min-sum n_at 10 | e 110 fed_model val loss 2.2513 val acc 9.3750 best val_acc 21.185065 te_acc 20.880682\n",
      "median: at min-sum n_at 10 | e 120 fed_model val loss 2.1818 val acc 18.6891 best val_acc 21.185065 te_acc 20.880682\n",
      "median: at min-sum n_at 10 | e 130 fed_model val loss 2.5227 val acc 14.8945 best val_acc 23.396916 te_acc 23.538961\n",
      "median: at min-sum n_at 10 | e 140 fed_model val loss 2.2833 val acc 14.1031 best val_acc 23.396916 te_acc 23.538961\n",
      "median: at min-sum n_at 10 | e 150 fed_model val loss 2.2238 val acc 16.6396 best val_acc 23.396916 te_acc 23.538961\n",
      "median: at min-sum n_at 10 | e 160 fed_model val loss 2.2578 val acc 14.1640 best val_acc 23.396916 te_acc 23.538961\n",
      "median: at min-sum n_at 10 | e 170 fed_model val loss 2.2451 val acc 9.7403 best val_acc 23.396916 te_acc 23.538961\n",
      "median: at min-sum n_at 10 | e 180 fed_model val loss 2.1647 val acc 18.5065 best val_acc 23.396916 te_acc 23.538961\n",
      "median: at min-sum n_at 10 | e 190 fed_model val loss 2.3053 val acc 11.6071 best val_acc 23.396916 te_acc 23.538961\n",
      "median: at min-sum n_at 10 | e 200 fed_model val loss 2.1850 val acc 16.8628 best val_acc 23.396916 te_acc 23.538961\n",
      "median: at min-sum n_at 10 | e 210 fed_model val loss 2.0879 val acc 19.1558 best val_acc 24.472403 te_acc 26.116071\n",
      "median: at min-sum n_at 10 | e 220 fed_model val loss 2.1088 val acc 20.9821 best val_acc 24.472403 te_acc 26.116071\n",
      "median: at min-sum n_at 10 | e 230 fed_model val loss 2.2299 val acc 13.6972 best val_acc 24.472403 te_acc 26.116071\n",
      "median: at min-sum n_at 10 | e 240 fed_model val loss 2.0016 val acc 24.5942 best val_acc 24.594156 te_acc 24.005682\n",
      "median: at min-sum n_at 10 | e 250 fed_model val loss 2.1248 val acc 21.1648 best val_acc 24.594156 te_acc 24.005682\n",
      "median: at min-sum n_at 10 | e 260 fed_model val loss 1.9649 val acc 26.8060 best val_acc 26.806006 te_acc 28.104708\n",
      "median: at min-sum n_at 10 | e 270 fed_model val loss 2.3464 val acc 10.4708 best val_acc 27.211851 te_acc 28.551136\n",
      "median: at min-sum n_at 10 | e 280 fed_model val loss 2.0600 val acc 21.7330 best val_acc 27.211851 te_acc 28.551136\n",
      "median: at min-sum n_at 10 | e 290 fed_model val loss 2.2990 val acc 9.9635 best val_acc 27.211851 te_acc 28.551136\n",
      "median: at min-sum n_at 10 | e 300 fed_model val loss 2.1742 val acc 17.4919 best val_acc 27.211851 te_acc 28.551136\n",
      "median: at min-sum n_at 10 | e 310 fed_model val loss 2.2501 val acc 18.1615 best val_acc 27.211851 te_acc 28.551136\n",
      "median: at min-sum n_at 10 | e 320 fed_model val loss 1.9824 val acc 26.0755 best val_acc 27.211851 te_acc 28.551136\n",
      "median: at min-sum n_at 10 | e 330 fed_model val loss 1.9952 val acc 27.1307 best val_acc 27.313312 te_acc 28.064123\n",
      "median: at min-sum n_at 10 | e 340 fed_model val loss 1.9686 val acc 22.1185 best val_acc 28.713474 te_acc 29.484578\n",
      "median: at min-sum n_at 10 | e 350 fed_model val loss 2.3584 val acc 19.4805 best val_acc 28.713474 te_acc 29.484578\n",
      "median: at min-sum n_at 10 | e 360 fed_model val loss 1.9135 val acc 27.6380 best val_acc 28.835227 te_acc 29.545455\n",
      "median: at min-sum n_at 10 | e 370 fed_model val loss 2.2473 val acc 15.7468 best val_acc 30.478896 te_acc 31.392045\n",
      "median: at min-sum n_at 10 | e 380 fed_model val loss 1.9613 val acc 24.5942 best val_acc 30.478896 te_acc 31.392045\n",
      "median: at min-sum n_at 10 | e 390 fed_model val loss 1.9795 val acc 26.7857 best val_acc 32.832792 te_acc 34.415584\n",
      "median: at min-sum n_at 10 | e 400 fed_model val loss 2.2801 val acc 21.8953 best val_acc 33.847403 te_acc 34.719968\n",
      "median: at min-sum n_at 10 | e 410 fed_model val loss 1.8058 val acc 33.4213 best val_acc 33.847403 te_acc 34.719968\n",
      "median: at min-sum n_at 10 | e 420 fed_model val loss 2.0440 val acc 26.2784 best val_acc 33.847403 te_acc 34.719968\n",
      "median: at min-sum n_at 10 | e 430 fed_model val loss 2.7759 val acc 13.5146 best val_acc 33.847403 te_acc 34.719968\n",
      "median: at min-sum n_at 10 | e 440 fed_model val loss 2.2362 val acc 11.9521 best val_acc 33.847403 te_acc 34.719968\n",
      "median: at min-sum n_at 10 | e 450 fed_model val loss 2.2786 val acc 14.5292 best val_acc 33.847403 te_acc 34.719968\n",
      "median: at min-sum n_at 10 | e 460 fed_model val loss 1.9620 val acc 23.9448 best val_acc 33.847403 te_acc 34.719968\n",
      "median: at min-sum n_at 10 | e 470 fed_model val loss 2.0296 val acc 24.1071 best val_acc 33.847403 te_acc 34.719968\n",
      "median: at min-sum n_at 10 | e 480 fed_model val loss 2.1472 val acc 22.4838 best val_acc 33.847403 te_acc 34.719968\n",
      "median: at min-sum n_at 10 | e 490 fed_model val loss 1.9477 val acc 27.3133 best val_acc 33.847403 te_acc 34.719968\n",
      "median: at min-sum n_at 10 | e 500 fed_model val loss 1.9333 val acc 26.9481 best val_acc 34.232955 te_acc 34.922890\n",
      "val loss 15299.964717 too high\n"
     ]
    }
   ],
   "source": [
    "batch_size=250\n",
    "resume=0\n",
    "nepochs=1200\n",
    "schedule=[1000]\n",
    "nbatches = user_tr_len//batch_size\n",
    "\n",
    "gamma=.5\n",
    "opt = 'sgd'\n",
    "fed_lr=0.5\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "aggregation='median'\n",
    "\n",
    "at_type='min-sum'\n",
    "dev_type ='std'\n",
    "threshold=10\n",
    "n_attackers=[10]\n",
    "\n",
    "arch='alexnet'\n",
    "chkpt='./'+aggregation\n",
    "\n",
    "for n_attacker in n_attackers:\n",
    "    candidates = []\n",
    "\n",
    "    epoch_num = 0\n",
    "    best_global_acc = 0\n",
    "    best_global_te_acc = 0\n",
    "\n",
    "    fed_model, _ = return_model(arch, 0.1, 0.9, parallel=False)\n",
    "    optimizer_fed = SGD(fed_model.parameters(), lr=fed_lr)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    r=np.arange(user_tr_len)\n",
    "\n",
    "    while epoch_num <= nepochs:\n",
    "        user_grads=[]\n",
    "        if not epoch_num and epoch_num%nbatches == 0:\n",
    "            np.random.shuffle(r)\n",
    "            for i in range(nusers):\n",
    "                user_tr_data_tensors[i]=user_tr_data_tensors[i][r]\n",
    "                user_tr_label_tensors[i]=user_tr_label_tensors[i][r]\n",
    "\n",
    "        for i in range(nusers):\n",
    "\n",
    "            inputs = user_tr_data_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
    "            targets = user_tr_label_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
    "\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "            outputs = fed_model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            fed_model.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "\n",
    "            param_grad=[]\n",
    "            for param in fed_model.parameters():\n",
    "                param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
    "\n",
    "            user_grads=param_grad[None, :] if len(user_grads)==0 else torch.cat((user_grads,param_grad[None,:]), 0)\n",
    "\n",
    "        if epoch_num in schedule:\n",
    "            for param_group in optimizer_fed.param_groups:\n",
    "                param_group['lr'] *= gamma\n",
    "                print('New learnin rate ', param_group['lr'])\n",
    "\n",
    "        if n_attacker > 0:\n",
    "            if at_type == 'lie':\n",
    "                mal_update = lie_attack(user_grads[:n_attacker], z_values[n_attacker])\n",
    "                attacker_grads = torch.cat((torch.stack([mal_update]*n_attacker), malicious_grads))\n",
    "            elif at_type == 'fang':\n",
    "                attacker_grads = fang_attack_trmean_partial(user_grads[:n_attacker], n_attacker)\n",
    "            elif at_type == 'our-agr':\n",
    "                n_attacker_ = partial_attackers[n_attacker]\n",
    "                agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "                mal_update = our_attack_median(user_grads[:n_attacker], agg_grads, n_attacker_, threshold=threshold, dev_type=dev_type)\n",
    "            elif at_type == 'min-max':\n",
    "                n_attacker_ = partial_attackers[n_attacker]\n",
    "                agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "                mal_update = our_attack_dist(user_grads[:n_attacker], agg_grads, n_attacker_, threshold=threshold, dev_type=dev_type)\n",
    "            elif at_type == 'min-sum':\n",
    "                n_attacker_ = partial_attackers[n_attacker]\n",
    "                agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "                mal_update = our_attack_score(user_grads[:n_attacker], agg_grads, n_attacker_, threshold=threshold, dev_type=dev_type)\n",
    "\n",
    "            mal_updates = torch.stack([mal_update] * n_attacker)\n",
    "            malicious_grads = torch.cat((mal_updates, user_grads), 0)\n",
    "\n",
    "        if epoch_num==0: print('malicious_grads shape ', malicious_grads.shape)\n",
    "\n",
    "        agg_grads=torch.median(malicious_grads,dim=0)[0]\n",
    "\n",
    "        del user_grads\n",
    "\n",
    "        start_idx=0\n",
    "\n",
    "        optimizer_fed.zero_grad()\n",
    "\n",
    "        model_grads=[]\n",
    "\n",
    "        for i, param in enumerate(fed_model.parameters()):\n",
    "            param_=agg_grads[start_idx:start_idx+len(param.data.view(-1))].reshape(param.data.shape)\n",
    "            start_idx=start_idx+len(param.data.view(-1))\n",
    "            param_=param_.cuda()\n",
    "            model_grads.append(param_)\n",
    "\n",
    "        optimizer_fed.step(model_grads)\n",
    "\n",
    "        val_loss, val_acc = test(val_data_tensor,val_label_tensor,fed_model,criterion,use_cuda)\n",
    "        te_loss, te_acc = test(te_data_tensor,te_label_tensor, fed_model, criterion, use_cuda)\n",
    "\n",
    "        is_best = best_global_acc < val_acc\n",
    "\n",
    "        best_global_acc = max(best_global_acc, val_acc)\n",
    "\n",
    "        if is_best:\n",
    "            best_global_te_acc = te_acc\n",
    "\n",
    "        if epoch_num%10==0 or epoch_num==nepochs-1:\n",
    "            print('%s: at %s n_at %d | e %d fed_model val loss %.4f val acc %.4f best val_acc %f te_acc %f'%(aggregation, at_type, n_attacker, epoch_num, val_loss, val_acc, best_global_acc,best_global_te_acc))\n",
    "\n",
    "        if val_loss > 1000:\n",
    "            print('val loss %f too high'%val_loss)\n",
    "            break\n",
    "            \n",
    "        epoch_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
