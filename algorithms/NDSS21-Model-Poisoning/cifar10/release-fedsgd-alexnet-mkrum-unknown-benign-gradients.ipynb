{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The notebook contains\n",
    "### Code for _Multi-krum_ aggregation algorithm, *when gradient updates of benign clients are unknown to adversary*\n",
    "### Evaluation of all of the attacks (Fang, LIE, and our SOTA AGR-tailored and AGR-agnstic) on Multi-krum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse, os, sys, csv, shutil, time, random, operator, pickle, ast, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.optim import Optimizer\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "sys.path.insert(0,'./../utils/')\n",
    "from logger import *\n",
    "from eval import *\n",
    "from misc import *\n",
    "\n",
    "from cifar10_normal_train import *\n",
    "from cifar10_util import *\n",
    "from adam import Adam\n",
    "from sgd import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get cifar10 data and split it in IID fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "total data len:  60000\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "data_loc='/mnt/nfs/work1/amir/vshejwalkar/cifar10_data/'\n",
    "# load the train dataset\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "cifar10_train = datasets.CIFAR10(root=data_loc, train=True, download=True, transform=train_transform)\n",
    "\n",
    "cifar10_test = datasets.CIFAR10(root=data_loc, train=False, download=True, transform=train_transform)\n",
    "\n",
    "X=[]\n",
    "Y=[]\n",
    "for i in range(len(cifar10_train)):\n",
    "    X.append(cifar10_train[i][0].numpy())\n",
    "    Y.append(cifar10_train[i][1])\n",
    "\n",
    "for i in range(len(cifar10_test)):\n",
    "    X.append(cifar10_test[i][0].numpy())\n",
    "    Y.append(cifar10_test[i][1])\n",
    "\n",
    "X=np.array(X)\n",
    "Y=np.array(Y)\n",
    "\n",
    "print('total data len: ',len(X))\n",
    "\n",
    "if not os.path.isfile('./cifar10_shuffle.pkl'):\n",
    "    all_indices = np.arange(len(X))\n",
    "    np.random.shuffle(all_indices)\n",
    "    pickle.dump(all_indices,open('./cifar10_shuffle.pkl','wb'))\n",
    "else:\n",
    "    all_indices=pickle.load(open('./cifar10_shuffle.pkl','rb'))\n",
    "\n",
    "X=X[all_indices]\n",
    "Y=Y[all_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide cifar10 data among 50 clients in IID fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data len:  60000\n",
      "total tr len 50000 | val len 5000 | test len 5000\n",
      "user 0 tr len 1000\n",
      "user 1 tr len 1000\n",
      "user 2 tr len 1000\n",
      "user 3 tr len 1000\n",
      "user 4 tr len 1000\n",
      "user 5 tr len 1000\n",
      "user 6 tr len 1000\n",
      "user 7 tr len 1000\n",
      "user 8 tr len 1000\n",
      "user 9 tr len 1000\n",
      "user 10 tr len 1000\n",
      "user 11 tr len 1000\n",
      "user 12 tr len 1000\n",
      "user 13 tr len 1000\n",
      "user 14 tr len 1000\n",
      "user 15 tr len 1000\n",
      "user 16 tr len 1000\n",
      "user 17 tr len 1000\n",
      "user 18 tr len 1000\n",
      "user 19 tr len 1000\n",
      "user 20 tr len 1000\n",
      "user 21 tr len 1000\n",
      "user 22 tr len 1000\n",
      "user 23 tr len 1000\n",
      "user 24 tr len 1000\n",
      "user 25 tr len 1000\n",
      "user 26 tr len 1000\n",
      "user 27 tr len 1000\n",
      "user 28 tr len 1000\n",
      "user 29 tr len 1000\n",
      "user 30 tr len 1000\n",
      "user 31 tr len 1000\n",
      "user 32 tr len 1000\n",
      "user 33 tr len 1000\n",
      "user 34 tr len 1000\n",
      "user 35 tr len 1000\n",
      "user 36 tr len 1000\n",
      "user 37 tr len 1000\n",
      "user 38 tr len 1000\n",
      "user 39 tr len 1000\n",
      "user 40 tr len 1000\n",
      "user 41 tr len 1000\n",
      "user 42 tr len 1000\n",
      "user 43 tr len 1000\n",
      "user 44 tr len 1000\n",
      "user 45 tr len 1000\n",
      "user 46 tr len 1000\n",
      "user 47 tr len 1000\n",
      "user 48 tr len 1000\n",
      "user 49 tr len 1000\n"
     ]
    }
   ],
   "source": [
    "# data loading\n",
    "\n",
    "nusers=50\n",
    "user_tr_len=1000\n",
    "\n",
    "total_tr_len=user_tr_len*nusers\n",
    "val_len=5000\n",
    "te_len=5000\n",
    "\n",
    "print('total data len: ',len(X))\n",
    "\n",
    "if not os.path.isfile('./cifar10_shuffle.pkl'):\n",
    "    all_indices = np.arange(len(X))\n",
    "    np.random.shuffle(all_indices)\n",
    "    pickle.dump(all_indices,open('./cifar10_shuffle.pkl','wb'))\n",
    "else:\n",
    "    all_indices=pickle.load(open('./cifar10_shuffle.pkl','rb'))\n",
    "\n",
    "total_tr_data=X[:total_tr_len]\n",
    "total_tr_label=Y[:total_tr_len]\n",
    "\n",
    "val_data=X[total_tr_len:(total_tr_len+val_len)]\n",
    "val_label=Y[total_tr_len:(total_tr_len+val_len)]\n",
    "\n",
    "te_data=X[(total_tr_len+val_len):(total_tr_len+val_len+te_len)]\n",
    "te_label=Y[(total_tr_len+val_len):(total_tr_len+val_len+te_len)]\n",
    "\n",
    "total_tr_data_tensor=torch.from_numpy(total_tr_data).type(torch.FloatTensor)\n",
    "total_tr_label_tensor=torch.from_numpy(total_tr_label).type(torch.LongTensor)\n",
    "\n",
    "val_data_tensor=torch.from_numpy(val_data).type(torch.FloatTensor)\n",
    "val_label_tensor=torch.from_numpy(val_label).type(torch.LongTensor)\n",
    "\n",
    "te_data_tensor=torch.from_numpy(te_data).type(torch.FloatTensor)\n",
    "te_label_tensor=torch.from_numpy(te_label).type(torch.LongTensor)\n",
    "\n",
    "print('total tr len %d | val len %d | test len %d'%(len(total_tr_data_tensor),len(val_data_tensor),len(te_data_tensor)))\n",
    "\n",
    "#==============================================================================================================\n",
    "\n",
    "user_tr_data_tensors=[]\n",
    "user_tr_label_tensors=[]\n",
    "\n",
    "for i in range(nusers):\n",
    "    \n",
    "    user_tr_data_tensor=torch.from_numpy(total_tr_data[user_tr_len*i:user_tr_len*(i+1)]).type(torch.FloatTensor)\n",
    "    user_tr_label_tensor=torch.from_numpy(total_tr_label[user_tr_len*i:user_tr_len*(i+1)]).type(torch.LongTensor)\n",
    "\n",
    "    user_tr_data_tensors.append(user_tr_data_tensor)\n",
    "    user_tr_label_tensors.append(user_tr_label_tensor)\n",
    "    print('user %d tr len %d'%(i,len(user_tr_data_tensor)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for Multi-krum aggregation algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_krum(all_updates, n_attackers, multi_k=False):\n",
    "\n",
    "    candidates = []\n",
    "    candidate_indices = []\n",
    "    remaining_updates = all_updates\n",
    "    all_indices = np.arange(len(all_updates))\n",
    "\n",
    "    while len(remaining_updates) > 2 * n_attackers + 2:\n",
    "        torch.cuda.empty_cache()\n",
    "        distances = []\n",
    "        for update in remaining_updates:\n",
    "            distance = []\n",
    "            for update_ in remaining_updates:\n",
    "                distance.append(torch.norm((update - update_)) ** 2)\n",
    "            distance = torch.Tensor(distance).float()\n",
    "            distances = distance[None, :] if not len(distances) else torch.cat((distances, distance[None, :]), 0)\n",
    "\n",
    "        distances = torch.sort(distances, dim=1)[0]\n",
    "        scores = torch.sum(distances[:, :len(remaining_updates) - 2 - n_attackers], dim=1)\n",
    "        indices = torch.argsort(scores)[:len(remaining_updates) - 2 - n_attackers]\n",
    "\n",
    "        candidate_indices.append(all_indices[indices[0].cpu().numpy()])\n",
    "        all_indices = np.delete(all_indices, indices[0].cpu().numpy())\n",
    "        candidates = remaining_updates[indices[0]][None, :] if not len(candidates) else torch.cat((candidates, remaining_updates[indices[0]][None, :]), 0)\n",
    "        remaining_updates = torch.cat((remaining_updates[:indices[0]], remaining_updates[indices[0] + 1:]), 0)\n",
    "        if not multi_k:\n",
    "            break\n",
    "    # print(len(remaining_updates))\n",
    "\n",
    "    aggregate = torch.mean(candidates, dim=0)\n",
    "\n",
    "    return aggregate, np.array(candidate_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for fang attack on Multi-krum\n",
    "### Note that Fang attacks on Multi-krum and Bulyan are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lambda_fang(all_updates, model_re, n_attackers):\n",
    "\n",
    "    distances = []\n",
    "    n_benign, d = all_updates.shape\n",
    "    for update in all_updates:\n",
    "        distance = torch.norm((all_updates - update), dim=1)\n",
    "        distances = distance[None, :] if not len(distances) else torch.cat((distances, distance[None, :]), 0)\n",
    "\n",
    "    distances[distances == 0] = 10000\n",
    "    distances = torch.sort(distances, dim=1)[0]\n",
    "    scores = torch.sum(distances[:, :n_benign - 2 - n_attackers], dim=1)\n",
    "    min_score = torch.min(scores)\n",
    "    term_1 = min_score / ((n_benign - n_attackers - 1) * torch.sqrt(torch.Tensor([d]))[0])\n",
    "    max_wre_dist = torch.max(torch.norm((all_updates - model_re), dim=1)) / (torch.sqrt(torch.Tensor([d]))[0])\n",
    "\n",
    "    return (term_1 + max_wre_dist)\n",
    "\n",
    "\n",
    "def get_malicious_updates_fang(all_updates, model_re, deviation, n_attackers):\n",
    "\n",
    "    lamda = compute_lambda_fang(all_updates, model_re, n_attackers)\n",
    "    threshold = 1e-5\n",
    "\n",
    "    mal_updates = []\n",
    "    while lamda > threshold:\n",
    "        mal_update = (- lamda * deviation)\n",
    "\n",
    "        mal_updates = torch.stack([mal_update] * n_attackers)\n",
    "        mal_updates = torch.cat((mal_updates, all_updates), 0)\n",
    "\n",
    "        agg_grads, krum_candidate = multi_krum(mal_updates, n_attackers, multi_k=False)\n",
    "        \n",
    "        if krum_candidate < n_attackers:\n",
    "            return mal_update\n",
    "        \n",
    "        lamda *= 0.5\n",
    "\n",
    "    if not len(mal_updates):\n",
    "        print(lamda, threshold)\n",
    "        mal_update = (model_re - lamda * deviation)\n",
    "        \n",
    "#         mal_updates = torch.stack([mal_update] * n_attackers)\n",
    "#         mal_updates = torch.cat((mal_updates, all_updates), 0)\n",
    "\n",
    "    return mal_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Fang attack on Multi-krum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi krum is  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vshejwalkar/NDSS21-Model-Poisoning/cifar10/sgd.py:109: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729138878/work/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  p.data.add_(-group['lr'], d_p)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkrum: at fang n_at 10 n_mal_sel 9 e 0 val loss 2.3027 val acc 9.9432 best val_acc 9.943182 te_acc 9.496753\n",
      "mkrum: at fang n_at 10 n_mal_sel 9 e 25 val loss 2.2894 val acc 14.6510 best val_acc 14.650974 te_acc 14.387175\n",
      "mkrum: at fang n_at 10 n_mal_sel 0 e 50 val loss 2.3061 val acc 10.3896 best val_acc 20.799513 te_acc 20.921266\n",
      "mkrum: at fang n_at 10 n_mal_sel 10 e 75 val loss 2.3020 val acc 10.3896 best val_acc 20.799513 te_acc 20.921266\n",
      "mkrum: at fang n_at 10 n_mal_sel 9 e 100 val loss 2.2969 val acc 9.2735 best val_acc 20.799513 te_acc 20.921266\n",
      "mkrum: at fang n_at 10 n_mal_sel 5 e 125 val loss 2.2790 val acc 11.7289 best val_acc 20.799513 te_acc 20.921266\n",
      "mkrum: at fang n_at 10 n_mal_sel 5 e 150 val loss 2.1117 val acc 21.4083 best val_acc 22.605519 te_acc 22.869318\n",
      "mkrum: at fang n_at 10 n_mal_sel 5 e 175 val loss 2.0584 val acc 22.8287 best val_acc 23.478084 te_acc 23.599838\n",
      "mkrum: at fang n_at 10 n_mal_sel 10 e 200 val loss 2.0281 val acc 24.1071 best val_acc 24.492695 te_acc 24.452110\n",
      "mkrum: at fang n_at 10 n_mal_sel 7 e 225 val loss 1.9964 val acc 26.6234 best val_acc 26.623377 te_acc 26.623377\n",
      "mkrum: at fang n_at 10 n_mal_sel 7 e 250 val loss 1.9609 val acc 25.8929 best val_acc 27.069805 te_acc 27.008929\n",
      "mkrum: at fang n_at 10 n_mal_sel 10 e 275 val loss 1.8952 val acc 31.2297 best val_acc 31.229708 te_acc 30.945617\n",
      "mkrum: at fang n_at 10 n_mal_sel 4 e 300 val loss 1.9497 val acc 27.6177 best val_acc 31.737013 te_acc 31.493506\n",
      "mkrum: at fang n_at 10 n_mal_sel 4 e 325 val loss 2.1770 val acc 17.1469 best val_acc 34.719968 te_acc 34.922890\n",
      "mkrum: at fang n_at 10 n_mal_sel 8 e 350 val loss 1.8362 val acc 31.0268 best val_acc 34.719968 te_acc 34.922890\n",
      "mkrum: at fang n_at 10 n_mal_sel 6 e 375 val loss 1.8414 val acc 31.5950 best val_acc 35.349026 te_acc 35.085227\n",
      "mkrum: at fang n_at 10 n_mal_sel 6 e 400 val loss 1.6739 val acc 38.0682 best val_acc 38.068182 te_acc 38.413149\n",
      "mkrum: at fang n_at 10 n_mal_sel 9 e 425 val loss 1.6911 val acc 37.9667 best val_acc 38.697240 te_acc 39.407468\n",
      "mkrum: at fang n_at 10 n_mal_sel 5 e 450 val loss 1.6509 val acc 38.7784 best val_acc 40.503247 te_acc 41.233766\n",
      "mkrum: at fang n_at 10 n_mal_sel 4 e 475 val loss 1.8201 val acc 35.3490 best val_acc 42.126623 te_acc 42.694805\n",
      "mkrum: at fang n_at 10 n_mal_sel 5 e 500 val loss 1.8060 val acc 33.0560 best val_acc 42.126623 te_acc 42.694805\n",
      "mkrum: at fang n_at 10 n_mal_sel 10 e 525 val loss 1.5408 val acc 43.4456 best val_acc 43.445617 te_acc 45.089286\n",
      "mkrum: at fang n_at 10 n_mal_sel 5 e 550 val loss 1.7385 val acc 40.6250 best val_acc 44.805195 te_acc 45.982143\n",
      "mkrum: at fang n_at 10 n_mal_sel 8 e 575 val loss 1.5093 val acc 44.8458 best val_acc 45.576299 te_acc 46.347403\n",
      "mkrum: at fang n_at 10 n_mal_sel 3 e 600 val loss 2.0952 val acc 23.5187 best val_acc 46.509740 te_acc 47.483766\n",
      "mkrum: at fang n_at 10 n_mal_sel 9 e 625 val loss 1.5725 val acc 40.8888 best val_acc 46.509740 te_acc 47.483766\n",
      "mkrum: at fang n_at 10 n_mal_sel 10 e 650 val loss 1.4535 val acc 46.7938 best val_acc 47.524351 te_acc 48.153409\n",
      "mkrum: at fang n_at 10 n_mal_sel 8 e 675 val loss 1.5376 val acc 44.3385 best val_acc 48.051948 te_acc 49.675325\n",
      "mkrum: at fang n_at 10 n_mal_sel 10 e 700 val loss 1.4144 val acc 48.0722 best val_acc 48.072240 te_acc 49.472403\n",
      "mkrum: at fang n_at 10 n_mal_sel 7 e 725 val loss 1.9495 val acc 30.0731 best val_acc 48.457792 te_acc 49.756494\n",
      "mkrum: at fang n_at 10 n_mal_sel 10 e 750 val loss 1.4764 val acc 45.6575 best val_acc 48.457792 te_acc 49.756494\n",
      "mkrum: at fang n_at 10 n_mal_sel 6 e 775 val loss 1.5995 val acc 42.7760 best val_acc 48.640422 te_acc 49.553571\n",
      "mkrum: at fang n_at 10 n_mal_sel 6 e 800 val loss 1.4370 val acc 47.9708 best val_acc 50.547890 te_acc 51.176948\n",
      "mkrum: at fang n_at 10 n_mal_sel 6 e 825 val loss 1.5826 val acc 41.4164 best val_acc 50.689935 te_acc 52.171266\n",
      "mkrum: at fang n_at 10 n_mal_sel 10 e 850 val loss 1.3593 val acc 51.8263 best val_acc 52.150974 te_acc 53.206169\n",
      "mkrum: at fang n_at 10 n_mal_sel 10 e 875 val loss 1.3821 val acc 51.6640 best val_acc 52.150974 te_acc 53.206169\n",
      "mkrum: at fang n_at 10 n_mal_sel 8 e 900 val loss 1.4897 val acc 48.6607 best val_acc 52.617695 te_acc 54.484578\n",
      "mkrum: at fang n_at 10 n_mal_sel 10 e 925 val loss 1.3806 val acc 51.1161 best val_acc 52.982955 te_acc 54.768669\n",
      "mkrum: at fang n_at 10 n_mal_sel 10 e 950 val loss 1.3673 val acc 52.7800 best val_acc 52.982955 te_acc 54.768669\n",
      "mkrum: at fang n_at 10 n_mal_sel 10 e 975 val loss 1.3889 val acc 50.8929 best val_acc 52.982955 te_acc 54.768669\n",
      "New learnin rate  0.25\n",
      "mkrum: at fang n_at 10 n_mal_sel 6 e 1000 val loss 1.4586 val acc 48.7013 best val_acc 52.982955 te_acc 54.768669\n",
      "mkrum: at fang n_at 10 n_mal_sel 10 e 1025 val loss 1.3691 val acc 53.6323 best val_acc 54.849838 te_acc 55.275974\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-96974aa5e7c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0magg_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_grads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_attacker\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0mdeviation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magg_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                 \u001b[0mmal_update\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_malicious_updates_fang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_grads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_attacker\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magg_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeviation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_attacker_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mat_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'our-agr'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0magg_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_grads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_attacker\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-d83734173c13>\u001b[0m in \u001b[0;36mget_malicious_updates_fang\u001b[0;34m(all_updates, model_re, deviation, n_attackers)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mmal_updates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmal_updates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_updates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0magg_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkrum_candidate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_krum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmal_updates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_attackers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkrum_candidate\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn_attackers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-aff3ce27bcd4>\u001b[0m in \u001b[0;36mmulti_krum\u001b[0;34m(all_updates, n_attackers, multi_k)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mupdate_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mremaining_updates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mupdate_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size=250\n",
    "resume=0\n",
    "nepochs=1200\n",
    "schedule=[1000]\n",
    "nbatches = user_tr_len//batch_size\n",
    "\n",
    "gamma=.5\n",
    "opt = 'sgd'\n",
    "fed_lr=0.5\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "aggregation='mkrum'\n",
    "multi_k = False\n",
    "candidates = []\n",
    "\n",
    "at_type='fang'\n",
    "n_attackers=[10]\n",
    "\n",
    "arch='alexnet'\n",
    "chkpt='./'+aggregation\n",
    "\n",
    "for n_attacker in n_attackers:\n",
    "    epoch_num = 0\n",
    "    best_global_acc = 0\n",
    "    best_global_te_acc = 0\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    r=np.arange(user_tr_len)\n",
    "\n",
    "    fed_model, _ = return_model(arch, 0.1, 0.9, parallel=False)\n",
    "    optimizer_fed = SGD(fed_model.parameters(), lr=fed_lr)\n",
    "\n",
    "    while epoch_num <= nepochs:\n",
    "        user_grads=[]\n",
    "        if not epoch_num and epoch_num%nbatches == 0:\n",
    "            np.random.shuffle(r)\n",
    "            for i in range(nusers):\n",
    "                user_tr_data_tensors[i]=user_tr_data_tensors[i][r]\n",
    "                user_tr_label_tensors[i]=user_tr_label_tensors[i][r]\n",
    "\n",
    "        for i in range(nusers):\n",
    "\n",
    "            inputs = user_tr_data_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
    "            targets = user_tr_label_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
    "\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "            outputs = fed_model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            fed_model.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "\n",
    "            param_grad=[]\n",
    "            for param in fed_model.parameters():\n",
    "                param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
    "\n",
    "            user_grads=param_grad[None, :] if len(user_grads)==0 else torch.cat((user_grads,param_grad[None,:]), 0)\n",
    "\n",
    "        if epoch_num in schedule:\n",
    "            for param_group in optimizer_fed.param_groups:\n",
    "                param_group['lr'] *= gamma\n",
    "                print('New learnin rate ', param_group['lr'])\n",
    "\n",
    "        if n_attacker > 0:\n",
    "            n_attacker_ = max(1, n_attacker**2//nusers)\n",
    "            if at_type == 'lie':\n",
    "                mal_update = lie_attack(user_grads[:n_attacker], z_values[n_attacker])\n",
    "            elif at_type == 'fang':\n",
    "                agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "                deviation = torch.sign(agg_grads)\n",
    "                mal_update = get_malicious_updates_fang(user_grads[:n_attacker], agg_grads, deviation, n_attacker_)\n",
    "            elif at_type == 'our-agr':\n",
    "                agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "                mal_update = our_attack_median(user_grads[:n_attacker], agg_grads, n_attacker_, dev_type)\n",
    "            elif at_type == 'min-max':\n",
    "                agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "                mal_update = our_attack_dist(user_grads[:n_attacker], agg_grads, n_attacker_, dev_type)\n",
    "            elif at_type == 'min-sum':\n",
    "                agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "                mal_update = our_attack_score(user_grads[:n_attacker], agg_grads, n_attacker_, dev_type)\n",
    "\n",
    "            mal_updates = torch.stack([mal_update] * n_attacker)\n",
    "            malicious_grads = torch.cat((mal_updates, user_grads[n_attacker:]), 0)\n",
    "        \n",
    "        if not (malicious_grads.shape[0]==50):\n",
    "            print(malicious_grads.shape)\n",
    "            sys.exit()\n",
    "            \n",
    "        multi_k = True if aggregation == 'mkrum' else False\n",
    "        if epoch_num == 0: print('multi krum is ', multi_k)\n",
    "        agg_grads, krum_candidate = multi_krum(malicious_grads, n_attacker, multi_k=multi_k)\n",
    "\n",
    "        del user_grads\n",
    "\n",
    "        start_idx=0\n",
    "\n",
    "        optimizer_fed.zero_grad()\n",
    "\n",
    "        model_grads=[]\n",
    "\n",
    "        for i, param in enumerate(fed_model.parameters()):\n",
    "            param_=agg_grads[start_idx:start_idx+len(param.data.view(-1))].reshape(param.data.shape)\n",
    "            start_idx=start_idx+len(param.data.view(-1))\n",
    "            param_=param_.cuda()\n",
    "            model_grads.append(param_)\n",
    "\n",
    "        optimizer_fed.step(model_grads)\n",
    "\n",
    "        val_loss, val_acc = test(val_data_tensor,val_label_tensor,fed_model,criterion,use_cuda)\n",
    "        te_loss, te_acc = test(te_data_tensor,te_label_tensor, fed_model, criterion, use_cuda)\n",
    "\n",
    "        is_best = best_global_acc < val_acc\n",
    "\n",
    "        best_global_acc = max(best_global_acc, val_acc)\n",
    "\n",
    "        if is_best:\n",
    "            best_global_te_acc = te_acc\n",
    "\n",
    "        if epoch_num%25==0 or epoch_num==nepochs-1:\n",
    "            print('%s: at %s n_at %d n_mal_sel %d e %d val loss %.4f val acc %.4f best val_acc %f te_acc %f'%(aggregation, at_type, n_attacker, np.sum(krum_candidate < n_attacker), epoch_num, val_loss, val_acc, best_global_acc,best_global_te_acc))\n",
    "\n",
    "        epoch_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for LIE attack, followed by its execution on Multi-krum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lie_attack(all_updates, z):\n",
    "    avg = torch.mean(all_updates, dim=0)\n",
    "    std = torch.std(all_updates, dim=0)\n",
    "    return avg + z * std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi krum is  True\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 0 fed_model val loss 2.3027 val acc 9.5982 best val_acc 9.598214 te_acc 10.024351\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 25 fed_model val loss 2.1926 val acc 18.2224 best val_acc 20.941558 te_acc 21.895292\n",
      "mkrum: at lie n_at 10 n_mal_sel 9 e 50 fed_model val loss 2.2062 val acc 15.5438 best val_acc 21.063312 te_acc 21.692370\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 75 fed_model val loss 2.0783 val acc 21.7938 best val_acc 23.640422 te_acc 23.437500\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 100 fed_model val loss 2.1444 val acc 17.4716 best val_acc 25.547890 te_acc 25.710227\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 125 fed_model val loss 1.9082 val acc 28.9570 best val_acc 29.220779 te_acc 29.748377\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 150 fed_model val loss 1.9023 val acc 31.1485 best val_acc 31.757305 te_acc 31.574675\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 175 fed_model val loss 1.8286 val acc 31.8385 best val_acc 34.212662 te_acc 34.090909\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 200 fed_model val loss 1.9577 val acc 27.9018 best val_acc 35.227273 te_acc 34.496753\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 225 fed_model val loss 1.8673 val acc 28.3482 best val_acc 37.601461 te_acc 39.042208\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 250 fed_model val loss 1.6609 val acc 39.1640 best val_acc 39.163961 te_acc 39.306006\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 275 fed_model val loss 1.6088 val acc 41.4773 best val_acc 41.477273 te_acc 41.477273\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 300 fed_model val loss 1.6975 val acc 38.1696 best val_acc 41.700487 te_acc 41.761364\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 325 fed_model val loss 1.6049 val acc 42.0049 best val_acc 42.410714 te_acc 43.486201\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 350 fed_model val loss 1.5783 val acc 42.5528 best val_acc 43.486201 te_acc 43.405032\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 375 fed_model val loss 1.6227 val acc 41.2135 best val_acc 44.439935 te_acc 44.906656\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 400 fed_model val loss 1.5618 val acc 44.0544 best val_acc 44.439935 te_acc 44.906656\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 425 fed_model val loss 1.6898 val acc 37.8450 best val_acc 45.109578 te_acc 45.129870\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 450 fed_model val loss 1.6104 val acc 42.3295 best val_acc 45.109578 te_acc 45.129870\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 475 fed_model val loss 1.6375 val acc 42.2281 best val_acc 45.109578 te_acc 45.129870\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 500 fed_model val loss 1.5866 val acc 43.3239 best val_acc 45.109578 te_acc 45.129870\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 525 fed_model val loss 1.6444 val acc 43.5877 best val_acc 45.109578 te_acc 45.129870\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 550 fed_model val loss 1.6234 val acc 42.1266 best val_acc 45.109578 te_acc 45.129870\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 575 fed_model val loss 1.6086 val acc 43.3442 best val_acc 45.109578 te_acc 45.129870\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 600 fed_model val loss 1.5967 val acc 43.3239 best val_acc 45.109578 te_acc 45.129870\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 625 fed_model val loss 1.6293 val acc 42.1672 best val_acc 45.109578 te_acc 45.129870\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 650 fed_model val loss 1.6123 val acc 40.8888 best val_acc 45.109578 te_acc 45.129870\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 675 fed_model val loss 1.6663 val acc 39.9554 best val_acc 45.109578 te_acc 45.129870\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 700 fed_model val loss 1.6456 val acc 39.6713 best val_acc 45.109578 te_acc 45.129870\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 725 fed_model val loss 1.6326 val acc 40.3003 best val_acc 45.109578 te_acc 45.129870\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 750 fed_model val loss 1.7544 val acc 36.7086 best val_acc 45.109578 te_acc 45.129870\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 775 fed_model val loss 1.7302 val acc 37.8044 best val_acc 45.109578 te_acc 45.129870\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 800 fed_model val loss 1.7010 val acc 37.7841 best val_acc 45.109578 te_acc 45.129870\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 825 fed_model val loss 1.7117 val acc 38.4537 best val_acc 45.109578 te_acc 45.129870\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 850 fed_model val loss 1.7842 val acc 33.6851 best val_acc 45.109578 te_acc 45.129870\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 875 fed_model val loss 1.7054 val acc 38.1088 best val_acc 45.109578 te_acc 45.129870\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 900 fed_model val loss 1.6957 val acc 38.4740 best val_acc 45.109578 te_acc 45.129870\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 925 fed_model val loss 1.7303 val acc 35.7549 best val_acc 45.109578 te_acc 45.129870\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 950 fed_model val loss 1.7480 val acc 36.3839 best val_acc 45.109578 te_acc 45.129870\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 975 fed_model val loss 1.7918 val acc 35.7143 best val_acc 45.109578 te_acc 45.129870\n",
      "New learnin rate  0.25\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 1000 fed_model val loss 1.7750 val acc 36.0795 best val_acc 45.109578 te_acc 45.129870\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 1025 fed_model val loss 1.7367 val acc 38.3523 best val_acc 45.109578 te_acc 45.129870\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 1050 fed_model val loss 1.7609 val acc 37.1144 best val_acc 45.109578 te_acc 45.129870\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 1075 fed_model val loss 1.7486 val acc 36.6071 best val_acc 45.109578 te_acc 45.129870\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 1100 fed_model val loss 1.8008 val acc 34.1112 best val_acc 45.109578 te_acc 45.129870\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 1125 fed_model val loss 1.8397 val acc 32.9748 best val_acc 45.109578 te_acc 45.129870\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 1150 fed_model val loss 1.7821 val acc 35.7346 best val_acc 45.109578 te_acc 45.129870\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 1175 fed_model val loss 1.7890 val acc 35.2881 best val_acc 45.109578 te_acc 45.129870\n",
      "mkrum: at lie n_at 10 n_mal_sel 9 e 1199 fed_model val loss 1.7870 val acc 34.4359 best val_acc 45.109578 te_acc 45.129870\n",
      "mkrum: at lie n_at 10 n_mal_sel 10 e 1200 fed_model val loss 1.8327 val acc 32.3458 best val_acc 45.109578 te_acc 45.129870\n"
     ]
    }
   ],
   "source": [
    "batch_size=250\n",
    "resume=0\n",
    "nepochs=1200\n",
    "schedule=[1000]\n",
    "nbatches = user_tr_len//batch_size\n",
    "\n",
    "gamma=.5\n",
    "opt = 'sgd'\n",
    "fed_lr=0.5\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "aggregation='mkrum'\n",
    "multi_k = False\n",
    "candidates = []\n",
    "\n",
    "at_type='lie'\n",
    "z_values={3:0.69847, 5:0.7054, 8:0.71904, 10:0.72575, 12:0.73891}\n",
    "n_attackers=[10]\n",
    "\n",
    "arch='alexnet'\n",
    "chkpt='./'+aggregation\n",
    "\n",
    "for n_attacker in n_attackers:\n",
    "    epoch_num = 0\n",
    "    best_global_acc = 0\n",
    "    best_global_te_acc = 0\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    r=np.arange(user_tr_len)\n",
    "\n",
    "    fed_model, _ = return_model(arch, 0.1, 0.9, parallel=False)\n",
    "    optimizer_fed = SGD(fed_model.parameters(), lr=fed_lr)\n",
    "\n",
    "    while epoch_num <= nepochs:\n",
    "        user_grads=[]\n",
    "        if not epoch_num and epoch_num%nbatches == 0:\n",
    "            np.random.shuffle(r)\n",
    "            for i in range(nusers):\n",
    "                user_tr_data_tensors[i]=user_tr_data_tensors[i][r]\n",
    "                user_tr_label_tensors[i]=user_tr_label_tensors[i][r]\n",
    "\n",
    "        for i in range(nusers):\n",
    "\n",
    "            inputs = user_tr_data_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
    "            targets = user_tr_label_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
    "\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "            outputs = fed_model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            fed_model.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "\n",
    "            param_grad=[]\n",
    "            for param in fed_model.parameters():\n",
    "                param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
    "\n",
    "            user_grads=param_grad[None, :] if len(user_grads)==0 else torch.cat((user_grads,param_grad[None,:]), 0)\n",
    "\n",
    "        if epoch_num in schedule:\n",
    "            for param_group in optimizer_fed.param_groups:\n",
    "                param_group['lr'] *= gamma\n",
    "                print('New learnin rate ', param_group['lr'])\n",
    "\n",
    "        if n_attacker > 0:\n",
    "            n_attacker_ = max(1, n_attacker**2//nusers)\n",
    "            if at_type == 'lie':\n",
    "                mal_update = lie_attack(user_grads[:n_attacker], z_values[n_attacker])\n",
    "            elif at_type == 'fang':\n",
    "                agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "                deviation = torch.sign(agg_grads)\n",
    "                mal_update = get_malicious_updates_fang(user_grads[:n_attacker], agg_grads, deviation, n_attacker_)\n",
    "            elif at_type == 'our-agr':\n",
    "                agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "                mal_update = our_attack_mkrum(user_grads[:n_attacker], agg_grads, n_attacker_, dev_type)\n",
    "            elif at_type == 'min-max':\n",
    "                agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "                mal_update = our_attack_dist(user_grads[:n_attacker], agg_grads, n_attacker_, dev_type)\n",
    "            elif at_type == 'min-sum':\n",
    "                agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "                mal_update = our_attack_score(user_grads[:n_attacker], agg_grads, n_attacker_, dev_type)\n",
    "\n",
    "            mal_updates = torch.stack([mal_update] * n_attacker)\n",
    "            malicious_grads = torch.cat((mal_updates, user_grads[n_attacker:]), 0)\n",
    "\n",
    "        if not (malicious_grads.shape[0]==50):\n",
    "            print(malicious_grads.shape)\n",
    "            sys.exit()\n",
    "            \n",
    "        multi_k = True if aggregation == 'mkrum' else False\n",
    "        if epoch_num == 0: print('multi krum is ', multi_k)\n",
    "        agg_grads, krum_candidate = multi_krum(malicious_grads, n_attacker, multi_k=multi_k)\n",
    "\n",
    "        del user_grads\n",
    "\n",
    "        start_idx=0\n",
    "\n",
    "        optimizer_fed.zero_grad()\n",
    "\n",
    "        model_grads=[]\n",
    "\n",
    "        for i, param in enumerate(fed_model.parameters()):\n",
    "            param_=agg_grads[start_idx:start_idx+len(param.data.view(-1))].reshape(param.data.shape)\n",
    "            start_idx=start_idx+len(param.data.view(-1))\n",
    "            param_=param_.cuda()\n",
    "            model_grads.append(param_)\n",
    "\n",
    "        optimizer_fed.step(model_grads)\n",
    "\n",
    "        val_loss, val_acc = test(val_data_tensor,val_label_tensor,fed_model,criterion,use_cuda)\n",
    "        te_loss, te_acc = test(te_data_tensor,te_label_tensor, fed_model, criterion, use_cuda)\n",
    "\n",
    "        is_best = best_global_acc < val_acc\n",
    "\n",
    "        best_global_acc = max(best_global_acc, val_acc)\n",
    "\n",
    "        if is_best:\n",
    "            best_global_te_acc = te_acc\n",
    "\n",
    "        if epoch_num%25==0 or epoch_num==nepochs-1:\n",
    "            print('%s: at %s n_at %d n_mal_sel %d e %d fed_model val loss %.4f val acc %.4f best val_acc %f te_acc %f'%(aggregation, at_type, n_attacker, np.sum(krum_candidate < n_attacker), epoch_num, val_loss, val_acc, best_global_acc,best_global_te_acc))\n",
    "\n",
    "        if val_loss > 10:\n",
    "            print('val loss %f too high'%val_loss)\n",
    "            break\n",
    "\n",
    "        epoch_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for our AGR-tailored attack on Multi-krum\n",
    "* Note that our attacks on multi-krum and Bulyan aggregations are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def our_attack_mkrum(all_updates, model_re, n_attackers, dev_type='unit_vec'):\n",
    "\n",
    "    if dev_type == 'unit_vec':\n",
    "        deviation = model_re / torch.norm(model_re)\n",
    "    elif dev_type == 'sign':\n",
    "        deviation = torch.sign(model_re)\n",
    "    elif dev_type == 'std':\n",
    "        deviation = torch.std(all_updates, 0)\n",
    "\n",
    "    lamda = torch.Tensor([3.0]).cuda()\n",
    "\n",
    "    threshold_diff = 1e-5\n",
    "    lamda_fail = lamda\n",
    "    lamda_succ = 0\n",
    "\n",
    "    while torch.abs(lamda_succ - lamda) > threshold_diff:\n",
    "        mal_update = (model_re - lamda * deviation)\n",
    "        mal_updates = torch.stack([mal_update] * n_attackers)\n",
    "        mal_updates = torch.cat((mal_updates, all_updates), 0)\n",
    "\n",
    "        agg_grads, krum_candidate = multi_krum(mal_updates, n_attackers, multi_k=True)\n",
    "        if np.sum(krum_candidate < n_attackers) == n_attackers:\n",
    "            # print('successful lamda is ', lamda)\n",
    "            lamda_succ = lamda\n",
    "            lamda = lamda + lamda_fail / 2\n",
    "        else:\n",
    "            lamda = lamda - lamda_fail / 2\n",
    "\n",
    "        lamda_fail = lamda_fail / 2\n",
    "\n",
    "    mal_update = (model_re - lamda_succ * deviation)\n",
    "    return mal_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute our AGR-tailored attack on Multi-krum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi krum is  True\n",
      "mkrum: at our-agr n_at 10 n_mal_sel 7 e 0 | val loss 2.3031 val acc 11.0187 best val_acc 11.018669\n",
      "mkrum: at our-agr n_at 10 n_mal_sel 8 e 25 | val loss 2.2332 val acc 22.7273 best val_acc 22.727273\n",
      "mkrum: at our-agr n_at 10 n_mal_sel 8 e 50 | val loss 2.2936 val acc 12.0333 best val_acc 22.727273\n",
      "mkrum: at our-agr n_at 10 n_mal_sel 8 e 75 | val loss 2.2461 val acc 15.3409 best val_acc 22.727273\n",
      "mkrum: at our-agr n_at 10 n_mal_sel 9 e 100 | val loss 2.1540 val acc 19.0747 best val_acc 22.727273\n",
      "mkrum: at our-agr n_at 10 n_mal_sel 10 e 125 | val loss 2.1499 val acc 17.5528 best val_acc 22.727273\n",
      "mkrum: at our-agr n_at 10 n_mal_sel 8 e 150 | val loss 2.1849 val acc 20.6575 best val_acc 22.767857\n",
      "mkrum: at our-agr n_at 10 n_mal_sel 9 e 175 | val loss 2.0996 val acc 21.4286 best val_acc 23.092532\n",
      "mkrum: at our-agr n_at 10 n_mal_sel 10 e 200 | val loss 2.1745 val acc 18.3847 best val_acc 25.324675\n",
      "mkrum: at our-agr n_at 10 n_mal_sel 8 e 225 | val loss 2.0223 val acc 20.4951 best val_acc 25.324675\n",
      "mkrum: at our-agr n_at 10 n_mal_sel 9 e 250 | val loss 2.4527 val acc 17.4107 best val_acc 25.608766\n",
      "mkrum: at our-agr n_at 10 n_mal_sel 9 e 275 | val loss 2.1080 val acc 19.6226 best val_acc 25.608766\n",
      "mkrum: at our-agr n_at 10 n_mal_sel 9 e 300 | val loss 2.0884 val acc 19.0544 best val_acc 25.608766\n",
      "mkrum: at our-agr n_at 10 n_mal_sel 8 e 325 | val loss 2.0930 val acc 20.0487 best val_acc 25.608766\n",
      "mkrum: at our-agr n_at 10 n_mal_sel 9 e 350 | val loss 2.2409 val acc 12.5812 best val_acc 25.608766\n",
      "mkrum: at our-agr n_at 10 n_mal_sel 9 e 375 | val loss 1.9674 val acc 25.7711 best val_acc 26.379870\n",
      "mkrum: at our-agr n_at 10 n_mal_sel 9 e 400 | val loss 2.3701 val acc 9.8620 best val_acc 28.246753\n",
      "mkrum: at our-agr n_at 10 n_mal_sel 9 e 425 | val loss 2.1632 val acc 19.4602 best val_acc 29.322240\n",
      "mkrum: at our-agr n_at 10 n_mal_sel 9 e 450 | val loss 1.8886 val acc 30.7224 best val_acc 30.722403\n",
      "mkrum: at our-agr n_at 10 n_mal_sel 10 e 475 | val loss 4.0220 val acc 11.6680 best val_acc 31.229708\n",
      "mkrum: at our-agr n_at 10 n_mal_sel 9 e 500 | val loss 2.2185 val acc 17.8369 best val_acc 31.229708\n",
      "mkrum: at our-agr n_at 10 n_mal_sel 9 e 525 | val loss 1.9965 val acc 29.2817 best val_acc 31.229708\n",
      "mkrum: at our-agr n_at 10 n_mal_sel 8 e 550 | val loss 2.1198 val acc 20.4951 best val_acc 31.229708\n",
      "mkrum: at our-agr n_at 10 n_mal_sel 8 e 575 | val loss 2.1966 val acc 16.8019 best val_acc 31.229708\n",
      "val loss 1042.091837 too high\n"
     ]
    }
   ],
   "source": [
    "batch_size=250\n",
    "resume=0\n",
    "nepochs=1200\n",
    "schedule=[1000]\n",
    "nbatches = user_tr_len//batch_size\n",
    "\n",
    "gamma=.5\n",
    "opt = 'sgd'\n",
    "fed_lr=0.5\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "aggregation='mkrum'\n",
    "multi_k = False\n",
    "candidates = []\n",
    "\n",
    "at_type='our-agr'\n",
    "dev_type ='std'\n",
    "z=0\n",
    "n_attackers=[10]\n",
    "\n",
    "arch='alexnet'\n",
    "chkpt='./'+aggregation\n",
    "\n",
    "\n",
    "for n_attacker in n_attackers:\n",
    "    epoch_num = 0\n",
    "    best_global_acc = 0\n",
    "    best_global_te_acc = 0\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    r=np.arange(user_tr_len)\n",
    "\n",
    "    fed_model, _ = return_model(arch, 0.1, 0.9, parallel=False)\n",
    "    optimizer_fed = SGD(fed_model.parameters(), lr=fed_lr)\n",
    "\n",
    "    while epoch_num <= nepochs:\n",
    "        user_grads=[]\n",
    "        if not epoch_num and epoch_num%nbatches == 0:\n",
    "            np.random.shuffle(r)\n",
    "            for i in range(nusers):\n",
    "                user_tr_data_tensors[i]=user_tr_data_tensors[i][r]\n",
    "                user_tr_label_tensors[i]=user_tr_label_tensors[i][r]\n",
    "\n",
    "        for i in range(nusers):\n",
    "\n",
    "            inputs = user_tr_data_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
    "            targets = user_tr_label_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
    "\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "            outputs = fed_model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            fed_model.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "\n",
    "            param_grad=[]\n",
    "            for param in fed_model.parameters():\n",
    "                param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
    "\n",
    "            user_grads=param_grad[None, :] if len(user_grads)==0 else torch.cat((user_grads,param_grad[None,:]), 0)\n",
    "\n",
    "        if epoch_num in schedule:\n",
    "            for param_group in optimizer_fed.param_groups:\n",
    "                param_group['lr'] *= gamma\n",
    "                print('New learnin rate ', param_group['lr'])\n",
    "\n",
    "        if n_attacker > 0:\n",
    "            n_attacker_ = max(1, n_attacker**2//nusers)\n",
    "            if at_type == 'lie':\n",
    "                mal_update = lie_attack(user_grads[:n_attacker], z_values[n_attacker])\n",
    "            elif at_type == 'fang':\n",
    "                agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "                deviation = torch.sign(agg_grads)\n",
    "                mal_update = get_malicious_updates_fang(user_grads[:n_attacker], agg_grads, deviation, n_attacker_)\n",
    "            elif at_type == 'our-agr':\n",
    "                agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "                mal_update = our_attack_mkrum(user_grads[:n_attacker], agg_grads, n_attacker_, dev_type)\n",
    "            elif at_type == 'min-max':\n",
    "                agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "                mal_update = our_attack_dist(user_grads[:n_attacker], agg_grads, n_attacker_, dev_type)\n",
    "            elif at_type == 'min-sum':\n",
    "                agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "                mal_update = our_attack_score(user_grads[:n_attacker], agg_grads, n_attacker_, dev_type)\n",
    "\n",
    "            mal_updates = torch.stack([mal_update] * n_attacker)\n",
    "            malicious_grads = torch.cat((mal_updates, user_grads[n_attacker:]), 0)\n",
    "\n",
    "        if not (malicious_grads.shape[0]==50):\n",
    "            print(malicious_grads.shape)\n",
    "            sys.exit()\n",
    "            \n",
    "        multi_k = True if aggregation == 'mkrum' else False\n",
    "        if epoch_num == 0: print('multi krum is ', multi_k)\n",
    "        agg_grads, krum_candidate = multi_krum(malicious_grads, n_attacker, multi_k=multi_k)\n",
    "\n",
    "        del user_grads\n",
    "\n",
    "        start_idx=0\n",
    "\n",
    "        optimizer_fed.zero_grad()\n",
    "\n",
    "        model_grads=[]\n",
    "\n",
    "        for i, param in enumerate(fed_model.parameters()):\n",
    "            param_=agg_grads[start_idx:start_idx+len(param.data.view(-1))].reshape(param.data.shape)\n",
    "            start_idx=start_idx+len(param.data.view(-1))\n",
    "            param_=param_.cuda()\n",
    "            model_grads.append(param_)\n",
    "\n",
    "        optimizer_fed.step(model_grads)\n",
    "\n",
    "        val_loss, val_acc = test(val_data_tensor,val_label_tensor,fed_model,criterion,use_cuda)\n",
    "        te_loss, te_acc = test(te_data_tensor,te_label_tensor, fed_model, criterion, use_cuda)\n",
    "\n",
    "        is_best = best_global_acc < val_acc\n",
    "\n",
    "        best_global_acc = max(best_global_acc, val_acc)\n",
    "\n",
    "        if is_best:\n",
    "            best_global_te_acc = te_acc\n",
    "\n",
    "        if epoch_num%25==0 or epoch_num==nepochs-1:\n",
    "            print('%s: at %s n_at %d n_mal_sel %d e %d | val loss %.4f val acc %.4f best val_acc %f'%(aggregation, at_type, n_attacker, np.sum(krum_candidate < n_attacker), epoch_num, val_loss, val_acc, best_global_acc))\n",
    "\n",
    "        if val_loss > 1000:\n",
    "            print('val loss %f too high'%val_loss)\n",
    "            break\n",
    "            \n",
    "        epoch_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for our first AGR-agnostic attack called Min-Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "MIN-MAX attack\n",
    "'''\n",
    "def our_attack_dist(all_updates, model_re, n_attackers, dev_type='unit_vec'):\n",
    "\n",
    "    if dev_type == 'unit_vec':\n",
    "        deviation = model_re / torch.norm(model_re)  # unit vector, dir opp to good dir\n",
    "    elif dev_type == 'sign':\n",
    "        deviation = torch.sign(model_re)\n",
    "    elif dev_type == 'std':\n",
    "        deviation = torch.std(all_updates, 0)\n",
    "\n",
    "    lamda = torch.Tensor([10.0]).float().cuda()\n",
    "    # print(lamda)\n",
    "    threshold_diff = 1e-5\n",
    "    lamda_fail = lamda\n",
    "    lamda_succ = 0\n",
    "    \n",
    "    distances = []\n",
    "    for update in all_updates:\n",
    "        distance = torch.norm((all_updates - update), dim=1) ** 2\n",
    "        distances = distance[None, :] if not len(distances) else torch.cat((distances, distance[None, :]), 0)\n",
    "    \n",
    "    max_distance = torch.max(distances)\n",
    "    del distances\n",
    "\n",
    "    while torch.abs(lamda_succ - lamda) > threshold_diff:\n",
    "        mal_update = (model_re - lamda * deviation)\n",
    "        distance = torch.norm((all_updates - mal_update), dim=1) ** 2\n",
    "        max_d = torch.max(distance)\n",
    "        \n",
    "        if max_d <= max_distance:\n",
    "            # print('successful lamda is ', lamda)\n",
    "            lamda_succ = lamda\n",
    "            lamda = lamda + lamda_fail / 2\n",
    "        else:\n",
    "            lamda = lamda - lamda_fail / 2\n",
    "\n",
    "        lamda_fail = lamda_fail / 2\n",
    "\n",
    "    mal_update = (model_re - lamda_succ * deviation)\n",
    "    \n",
    "    return mal_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Min-max attack on Bulyan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi krum is  True\n",
      "mkrum: at min-max n_at 10 n_mal_sel 6 e 0 | val loss 2.3031 val acc 9.7606 best val_acc 9.760552\n",
      "mkrum: at min-max n_at 10 n_mal_sel 5 e 25 | val loss 2.3043 val acc 9.6185 best val_acc 22.118506\n",
      "mkrum: at min-max n_at 10 n_mal_sel 6 e 50 | val loss 2.3088 val acc 10.1055 best val_acc 22.118506\n",
      "mkrum: at min-max n_at 10 n_mal_sel 6 e 75 | val loss 2.3135 val acc 10.0041 best val_acc 22.118506\n",
      "mkrum: at min-max n_at 10 n_mal_sel 7 e 100 | val loss 2.0632 val acc 22.1794 best val_acc 22.280844\n",
      "mkrum: at min-max n_at 10 n_mal_sel 4 e 125 | val loss 2.0771 val acc 22.0576 best val_acc 22.301136\n",
      "mkrum: at min-max n_at 10 n_mal_sel 6 e 150 | val loss 2.0228 val acc 24.5739 best val_acc 24.573864\n",
      "mkrum: at min-max n_at 10 n_mal_sel 5 e 175 | val loss 2.0263 val acc 23.8231 best val_acc 26.237825\n",
      "mkrum: at min-max n_at 10 n_mal_sel 7 e 200 | val loss 2.2323 val acc 19.2370 best val_acc 26.846591\n",
      "mkrum: at min-max n_at 10 n_mal_sel 4 e 225 | val loss 1.9658 val acc 27.2524 best val_acc 27.881494\n",
      "mkrum: at min-max n_at 10 n_mal_sel 5 e 250 | val loss 1.9494 val acc 25.7914 best val_acc 28.672890\n",
      "mkrum: at min-max n_at 10 n_mal_sel 5 e 275 | val loss 1.9038 val acc 29.9513 best val_acc 29.951299\n",
      "mkrum: at min-max n_at 10 n_mal_sel 7 e 300 | val loss 1.8876 val acc 30.2151 best val_acc 30.215097\n",
      "mkrum: at min-max n_at 10 n_mal_sel 6 e 325 | val loss 2.2950 val acc 20.5560 best val_acc 30.418019\n",
      "mkrum: at min-max n_at 10 n_mal_sel 6 e 350 | val loss 2.0744 val acc 23.1534 best val_acc 30.418019\n",
      "mkrum: at min-max n_at 10 n_mal_sel 7 e 375 | val loss 2.1489 val acc 21.0227 best val_acc 30.418019\n",
      "mkrum: at min-max n_at 10 n_mal_sel 7 e 400 | val loss 2.1463 val acc 19.1761 best val_acc 30.418019\n",
      "mkrum: at min-max n_at 10 n_mal_sel 7 e 425 | val loss 2.4626 val acc 17.8977 best val_acc 32.467532\n",
      "mkrum: at min-max n_at 10 n_mal_sel 8 e 450 | val loss 1.9188 val acc 30.1948 best val_acc 32.467532\n",
      "mkrum: at min-max n_at 10 n_mal_sel 7 e 475 | val loss 2.0704 val acc 22.0373 best val_acc 33.116883\n",
      "mkrum: at min-max n_at 10 n_mal_sel 7 e 500 | val loss 1.9664 val acc 28.2873 best val_acc 33.116883\n",
      "mkrum: at min-max n_at 10 n_mal_sel 6 e 525 | val loss 2.5606 val acc 14.3466 best val_acc 33.116883\n",
      "mkrum: at min-max n_at 10 n_mal_sel 8 e 550 | val loss 2.0790 val acc 28.6932 best val_acc 33.116883\n",
      "mkrum: at min-max n_at 10 n_mal_sel 8 e 575 | val loss 2.4622 val acc 12.8247 best val_acc 33.116883\n",
      "mkrum: at min-max n_at 10 n_mal_sel 6 e 600 | val loss 43.6349 val acc 9.9635 best val_acc 33.116883\n",
      "val loss 14922967.649351 too high\n"
     ]
    }
   ],
   "source": [
    "batch_size=250\n",
    "resume=0\n",
    "nepochs=1200\n",
    "schedule=[1000]\n",
    "nbatches = user_tr_len//batch_size\n",
    "\n",
    "gamma=.5\n",
    "opt = 'sgd'\n",
    "fed_lr=0.5\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "aggregation='mkrum'\n",
    "multi_k = False\n",
    "candidates = []\n",
    "\n",
    "at_type='min-max'\n",
    "dev_type ='std'\n",
    "z=0\n",
    "n_attackers=[10]\n",
    "\n",
    "arch='alexnet'\n",
    "chkpt='./'+aggregation\n",
    "\n",
    "for n_attacker in n_attackers:\n",
    "    candidates = []\n",
    "\n",
    "    epoch_num = 0\n",
    "    best_global_acc = 0\n",
    "    best_global_te_acc = 0\n",
    "\n",
    "    fed_model, _ = return_model(arch, 0.1, 0.9, parallel=False)\n",
    "    optimizer_fed = SGD(fed_model.parameters(), lr=fed_lr)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    r=np.arange(user_tr_len)\n",
    "\n",
    "    while epoch_num <= nepochs:\n",
    "        user_grads=[]\n",
    "        if not epoch_num and epoch_num%nbatches == 0:\n",
    "            np.random.shuffle(r)\n",
    "            for i in range(nusers):\n",
    "                user_tr_data_tensors[i]=user_tr_data_tensors[i][r]\n",
    "                user_tr_label_tensors[i]=user_tr_label_tensors[i][r]\n",
    "\n",
    "        for i in range(nusers):\n",
    "\n",
    "            inputs = user_tr_data_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
    "            targets = user_tr_label_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
    "\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "            outputs = fed_model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            fed_model.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "\n",
    "            param_grad=[]\n",
    "            for param in fed_model.parameters():\n",
    "                param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
    "\n",
    "            user_grads=param_grad[None, :] if len(user_grads)==0 else torch.cat((user_grads,param_grad[None,:]), 0)\n",
    "\n",
    "        if epoch_num in schedule:\n",
    "            for param_group in optimizer_fed.param_groups:\n",
    "                param_group['lr'] *= gamma\n",
    "                print('New learnin rate ', param_group['lr'])\n",
    "\n",
    "        if n_attacker > 0:\n",
    "            n_attacker_ = max(1, n_attacker**2//nusers)\n",
    "            if at_type == 'lie':\n",
    "                mal_update = lie_attack(user_grads[:n_attacker], z_values[n_attacker])\n",
    "            elif at_type == 'fang':\n",
    "                agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "                deviation = torch.sign(agg_grads)\n",
    "                mal_update = get_malicious_updates_fang(user_grads[:n_attacker], agg_grads, deviation, n_attacker_)\n",
    "            elif at_type == 'our-agr':\n",
    "                agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "                mal_update = our_attack_median(user_grads[:n_attacker], agg_grads, n_attacker_, dev_type)\n",
    "            elif at_type == 'min-max':\n",
    "                agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "                mal_update = our_attack_dist(user_grads[:n_attacker], agg_grads, n_attacker_, dev_type)\n",
    "            elif at_type == 'min-sum':\n",
    "                agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "                mal_update = our_attack_score(user_grads[:n_attacker], agg_grads, n_attacker_, dev_type)\n",
    "\n",
    "            mal_updates = torch.stack([mal_update] * n_attacker)\n",
    "            malicious_grads = torch.cat((mal_updates, user_grads[n_attacker:]), 0)\n",
    "\n",
    "        if not (malicious_grads.shape[0]==50):\n",
    "            print(malicious_grads.shape)\n",
    "            sys.exit()\n",
    "\n",
    "        multi_k = True if aggregation == 'mkrum' else False\n",
    "        if epoch_num == 0: print('multi krum is ', multi_k)\n",
    "        agg_grads, krum_candidate = multi_krum(malicious_grads, n_attacker, multi_k=multi_k)\n",
    "\n",
    "        del user_grads\n",
    "\n",
    "        start_idx=0\n",
    "\n",
    "        optimizer_fed.zero_grad()\n",
    "\n",
    "        model_grads=[]\n",
    "\n",
    "        for i, param in enumerate(fed_model.parameters()):\n",
    "            param_=agg_grads[start_idx:start_idx+len(param.data.view(-1))].reshape(param.data.shape)\n",
    "            start_idx=start_idx+len(param.data.view(-1))\n",
    "            param_=param_.cuda()\n",
    "            model_grads.append(param_)\n",
    "\n",
    "        optimizer_fed.step(model_grads)\n",
    "\n",
    "        val_loss, val_acc = test(val_data_tensor,val_label_tensor,fed_model,criterion,use_cuda)\n",
    "        te_loss, te_acc = test(te_data_tensor,te_label_tensor, fed_model, criterion, use_cuda)\n",
    "\n",
    "        is_best = best_global_acc < val_acc\n",
    "\n",
    "        best_global_acc = max(best_global_acc, val_acc)\n",
    "\n",
    "        if is_best:\n",
    "            best_global_te_acc = te_acc\n",
    "\n",
    "        if epoch_num%25==0 or epoch_num==nepochs-1:\n",
    "            print('%s: at %s n_at %d n_mal_sel %d e %d | val loss %.4f val acc %.4f best val_acc %f'%(aggregation, at_type, n_attacker, np.sum(krum_candidate < n_attacker), epoch_num, val_loss, val_acc, best_global_acc))\n",
    "\n",
    "        if val_loss > 1000:\n",
    "            print('val loss %f too high'%val_loss)\n",
    "            break\n",
    "            \n",
    "        epoch_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for our second AGR-agnostic attack called Min-Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "MIN-SUM attack\n",
    "'''\n",
    "\n",
    "def our_attack_score(all_updates, model_re, n_attackers, dev_type='unit_vec'):\n",
    "\n",
    "    if dev_type == 'unit_vec':\n",
    "        deviation = model_re / torch.norm(model_re)  # unit vector, dir opp to good dir\n",
    "    elif dev_type == 'sign':\n",
    "        deviation = torch.sign(model_re)\n",
    "    elif dev_type == 'std':\n",
    "        deviation = torch.std(all_updates, 0)\n",
    "    \n",
    "    lamda = torch.Tensor([10.0]).float().cuda()\n",
    "    # print(lamda)\n",
    "    threshold_diff = 1e-5\n",
    "    lamda_fail = lamda\n",
    "    lamda_succ = 0\n",
    "    \n",
    "    distances = []\n",
    "    for update in all_updates:\n",
    "        distance = torch.norm((all_updates - update), dim=1) ** 2\n",
    "        distances = distance[None, :] if not len(distances) else torch.cat((distances, distance[None, :]), 0)\n",
    "    \n",
    "    scores = torch.sum(distances, dim=1)\n",
    "    min_score = torch.min(scores)\n",
    "    del distances\n",
    "\n",
    "    while torch.abs(lamda_succ - lamda) > threshold_diff:\n",
    "        mal_update = (model_re - lamda * deviation)\n",
    "        distance = torch.norm((all_updates - mal_update), dim=1) ** 2\n",
    "        score = torch.sum(distance)\n",
    "        \n",
    "        if score <= min_score:\n",
    "            # print('successful lamda is ', lamda)\n",
    "            lamda_succ = lamda\n",
    "            lamda = lamda + lamda_fail / 2\n",
    "        else:\n",
    "            lamda = lamda - lamda_fail / 2\n",
    "\n",
    "        lamda_fail = lamda_fail / 2\n",
    "\n",
    "    # print(lamda_succ)\n",
    "    mal_update = (model_re - lamda_succ * deviation)\n",
    "    \n",
    "    return mal_update\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Min-Sum attack on Bulyan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi krum is  True\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 0 | val loss 2.3027 val acc 9.6185 best val_acc 9.618506\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 25 | val loss 2.2607 val acc 18.7297 best val_acc 21.002435\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 50 | val loss 2.2546 val acc 10.5925 best val_acc 21.002435\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 75 | val loss 2.2835 val acc 12.7435 best val_acc 21.043019\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 100 | val loss 2.0725 val acc 22.9708 best val_acc 22.970779\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 125 | val loss 2.4084 val acc 9.0706 best val_acc 25.324675\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 150 | val loss 2.1561 val acc 20.6169 best val_acc 25.324675\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 175 | val loss 2.2800 val acc 12.4797 best val_acc 25.324675\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 200 | val loss 2.0703 val acc 25.7914 best val_acc 25.791396\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 225 | val loss 1.9495 val acc 28.9367 best val_acc 28.936688\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 250 | val loss 1.9287 val acc 28.0641 best val_acc 29.768669\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 275 | val loss 1.8410 val acc 32.4269 best val_acc 32.426948\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 300 | val loss 1.9574 val acc 24.3506 best val_acc 32.426948\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 325 | val loss 1.8852 val acc 26.8263 best val_acc 32.426948\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 350 | val loss 2.3575 val acc 16.8019 best val_acc 33.096591\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 375 | val loss 1.8398 val acc 31.3312 best val_acc 33.096591\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 400 | val loss 2.5326 val acc 9.3141 best val_acc 34.354708\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 425 | val loss 2.7165 val acc 10.8969 best val_acc 34.354708\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 450 | val loss 2.3148 val acc 11.3231 best val_acc 34.354708\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 475 | val loss 2.2524 val acc 16.7614 best val_acc 34.354708\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 500 | val loss 2.2949 val acc 11.0390 best val_acc 34.354708\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 525 | val loss 2.0892 val acc 20.0690 best val_acc 34.354708\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 550 | val loss 2.0457 val acc 23.7013 best val_acc 34.354708\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 575 | val loss 2.1127 val acc 19.0747 best val_acc 34.354708\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 600 | val loss 1.9937 val acc 23.9651 best val_acc 34.354708\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 625 | val loss 1.9100 val acc 26.6843 best val_acc 34.354708\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 9 e 650 | val loss 2.2132 val acc 17.5325 best val_acc 34.354708\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 675 | val loss 2.1883 val acc 17.6136 best val_acc 34.354708\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 700 | val loss 2.3378 val acc 10.0852 best val_acc 34.354708\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 725 | val loss 2.3083 val acc 11.5666 best val_acc 34.354708\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 750 | val loss 2.2045 val acc 18.3239 best val_acc 34.354708\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 775 | val loss 2.1411 val acc 18.4456 best val_acc 34.354708\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 800 | val loss 2.0622 val acc 24.6347 best val_acc 34.354708\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 825 | val loss 2.1736 val acc 18.8920 best val_acc 34.354708\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 850 | val loss 2.0820 val acc 21.1648 best val_acc 34.354708\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 875 | val loss 1.8858 val acc 30.2151 best val_acc 34.354708\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 900 | val loss 2.3177 val acc 10.2476 best val_acc 34.354708\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 925 | val loss 2.3033 val acc 9.8620 best val_acc 34.354708\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 950 | val loss 2.3029 val acc 9.6185 best val_acc 34.354708\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 975 | val loss 2.3028 val acc 9.6185 best val_acc 34.354708\n",
      "New learnin rate  0.25\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 1000 | val loss 2.3028 val acc 9.6185 best val_acc 34.354708\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 1025 | val loss 2.3028 val acc 9.6185 best val_acc 34.354708\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 1050 | val loss 2.3028 val acc 9.6185 best val_acc 34.354708\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 1075 | val loss 2.3028 val acc 9.6185 best val_acc 34.354708\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 1100 | val loss 2.3028 val acc 9.6185 best val_acc 34.354708\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 1125 | val loss 2.3028 val acc 9.6185 best val_acc 34.354708\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 1150 | val loss 2.3028 val acc 9.6185 best val_acc 34.354708\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 1175 | val loss 2.3028 val acc 9.6185 best val_acc 34.354708\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 1199 | val loss 2.3028 val acc 9.6185 best val_acc 34.354708\n",
      "mkrum: at min-sum n_at 10 n_mal_sel 10 e 1200 | val loss 2.3028 val acc 9.6185 best val_acc 34.354708\n"
     ]
    }
   ],
   "source": [
    "batch_size=250\n",
    "resume=0\n",
    "nepochs=1200\n",
    "schedule=[1000]\n",
    "nbatches = user_tr_len//batch_size\n",
    "\n",
    "gamma=.5\n",
    "opt = 'sgd'\n",
    "fed_lr=0.5\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "aggregation='mkrum'\n",
    "multi_k = False\n",
    "candidates = []\n",
    "\n",
    "at_type='min-sum'\n",
    "dev_type ='std'\n",
    "z=0\n",
    "n_attackers=[10]\n",
    "\n",
    "arch='alexnet'\n",
    "chkpt='./'+aggregation\n",
    "\n",
    "for n_attacker in n_attackers:\n",
    "    candidates = []\n",
    "\n",
    "    epoch_num = 0\n",
    "    best_global_acc = 0\n",
    "    best_global_te_acc = 0\n",
    "\n",
    "    fed_model, _ = return_model(arch, 0.1, 0.9, parallel=False)\n",
    "    optimizer_fed = SGD(fed_model.parameters(), lr=fed_lr)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    r=np.arange(user_tr_len)\n",
    "\n",
    "    while epoch_num <= nepochs:\n",
    "        user_grads=[]\n",
    "        if not epoch_num and epoch_num%nbatches == 0:\n",
    "            np.random.shuffle(r)\n",
    "            for i in range(nusers):\n",
    "                user_tr_data_tensors[i]=user_tr_data_tensors[i][r]\n",
    "                user_tr_label_tensors[i]=user_tr_label_tensors[i][r]\n",
    "\n",
    "        for i in range(nusers):\n",
    "\n",
    "            inputs = user_tr_data_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
    "            targets = user_tr_label_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
    "\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "            outputs = fed_model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            fed_model.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "\n",
    "            param_grad=[]\n",
    "            for param in fed_model.parameters():\n",
    "                param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
    "\n",
    "            user_grads=param_grad[None, :] if len(user_grads)==0 else torch.cat((user_grads,param_grad[None,:]), 0)\n",
    "\n",
    "        if epoch_num in schedule:\n",
    "            for param_group in optimizer_fed.param_groups:\n",
    "                param_group['lr'] *= gamma\n",
    "                print('New learnin rate ', param_group['lr'])\n",
    "\n",
    "        if n_attacker > 0:\n",
    "            n_attacker_ = max(1, n_attacker**2//nusers)\n",
    "            if at_type == 'lie':\n",
    "                mal_update = lie_attack(user_grads[:n_attacker], z_values[n_attacker])\n",
    "            elif at_type == 'fang':\n",
    "                agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "                deviation = torch.sign(agg_grads)\n",
    "                mal_update = get_malicious_updates_fang(user_grads[:n_attacker], agg_grads, deviation, n_attacker_)\n",
    "            elif at_type == 'our-agr':\n",
    "                agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "                mal_update = our_attack_median(user_grads[:n_attacker], agg_grads, n_attacker_, dev_type)\n",
    "            elif at_type == 'min-max':\n",
    "                agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "                mal_update = our_attack_dist(user_grads[:n_attacker], agg_grads, n_attacker_, dev_type)\n",
    "            elif at_type == 'min-sum':\n",
    "                agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "                mal_update = our_attack_score(user_grads[:n_attacker], agg_grads, n_attacker_, dev_type)\n",
    "\n",
    "            mal_updates = torch.stack([mal_update] * n_attacker)\n",
    "            malicious_grads = torch.cat((mal_updates, user_grads[n_attacker:]), 0)\n",
    "\n",
    "        if not (malicious_grads.shape[0]==50):\n",
    "            print(malicious_grads.shape)\n",
    "            sys.exit()\n",
    "\n",
    "        multi_k = True if aggregation == 'mkrum' else False\n",
    "        if epoch_num == 0: print('multi krum is ', multi_k)\n",
    "        agg_grads, krum_candidate = multi_krum(malicious_grads, n_attacker, multi_k=multi_k)\n",
    "\n",
    "        del user_grads\n",
    "\n",
    "        start_idx=0\n",
    "\n",
    "        optimizer_fed.zero_grad()\n",
    "\n",
    "        model_grads=[]\n",
    "\n",
    "        for i, param in enumerate(fed_model.parameters()):\n",
    "            param_=agg_grads[start_idx:start_idx+len(param.data.view(-1))].reshape(param.data.shape)\n",
    "            start_idx=start_idx+len(param.data.view(-1))\n",
    "            param_=param_.cuda()\n",
    "            model_grads.append(param_)\n",
    "\n",
    "        optimizer_fed.step(model_grads)\n",
    "\n",
    "        val_loss, val_acc = test(val_data_tensor,val_label_tensor,fed_model,criterion,use_cuda)\n",
    "        te_loss, te_acc = test(te_data_tensor,te_label_tensor, fed_model, criterion, use_cuda)\n",
    "\n",
    "        is_best = best_global_acc < val_acc\n",
    "\n",
    "        best_global_acc = max(best_global_acc, val_acc)\n",
    "\n",
    "        if is_best:\n",
    "            best_global_te_acc = te_acc\n",
    "\n",
    "        if epoch_num%25==0 or epoch_num==nepochs-1:\n",
    "            print('%s: at %s n_at %d n_mal_sel %d e %d | val loss %.4f val acc %.4f best val_acc %f'%(aggregation, at_type, n_attacker, np.sum(krum_candidate < n_attacker), epoch_num, val_loss, val_acc, best_global_acc))\n",
    "\n",
    "        if val_loss > 1000:\n",
    "            print('val loss %f too high'%val_loss)\n",
    "            break\n",
    "            \n",
    "        epoch_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
